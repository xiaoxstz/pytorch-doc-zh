
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/1.0/nn_functional/">
      
      
        <link rel="prev" href="../nn/">
      
      
        <link rel="next" href="../nn_init/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.0">
    
    
      
        <title>torch.nn.functional - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.45e1311d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torchnnfunctional" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              torch.nn.functional
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" >
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Modeling with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.compile Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial%23using-sdpa-with-torch-compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using SDPA with torch.compile
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial%23conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Mobile
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Mobile
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deeplabv3_on_ios/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on iOS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deeplabv3_on_android/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on Android
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.7 中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    学习 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            学习 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 深度学习：60 分钟的突击
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 深度学习：60 分钟的突击
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/02/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/03/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/04/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.autograd的简要介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/05/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/06/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_2" >
        
          
          <label class="md-nav__link" for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    通过示例学习 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_2">
            <span class="md-nav__icon md-icon"></span>
            通过示例学习 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/07/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/08/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    热身：NumPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/09/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：张量和 Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：定义新的 Autograd 函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/14/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：自定义nn模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/15/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：控制流 - 权重共享
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/16/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn到底是什么？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TensorBoard 可视化模型，数据和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图片/视频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            图片/视频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/19/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision对象检测微调教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉的迁移学习教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/21/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            音频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/24/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    音频 I/O 和torchaudio的预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/25/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用torchaudio的语音命令识别
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/27/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用nn.Transformer和torchtext的序列到序列建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/28/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用字符级 RNN 分类名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用字符级 RNN 生成名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用序列到序列网络和注意力的翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用torchtext的文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext语言翻译
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/34/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习（DQN）教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/35/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练玩马里奥的 RL 智能体
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
        
          
          <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    在生产中部署 PyTorch 模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            在生产中部署 PyTorch 模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/37/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过使用 Flask 的 REST API 在 Python 中部署 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/38/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/39/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中加载 TorchScript 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/40/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将模型从 PyTorch 导出到 ONNX 并使用 ONNX 运行时运行它（可选）
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
        
          
          <label class="md-nav__link" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    前端 API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_7">
            <span class="md-nav__icon md-icon"></span>
            前端 API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/42/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中的命名张量简介（原型）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/43/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中通道在最后的内存格式（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/44/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C++ 前端
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/45/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自定义 C++ 和 CUDA 扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/46/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C++ 运算符扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/47/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C++ 类扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/48/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 中的动态并行性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/49/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++ 前端中的 Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中注册调度运算符
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" >
        
          
          <label class="md-nav__link" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型优化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_8">
            <span class="md-nav__icon md-icon"></span>
            模型优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/52/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分析您的 PyTorch 模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/53/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Ray Tune 的超参数调整
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/54/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型剪裁教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/55/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM 单词语言模型上的动态量化（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/56/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERT 上的动态量化（Beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/57/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中使用 Eager 模式的静态量化（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/58/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉的量化迁移学习教程（beta）
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
        
          
          <label class="md-nav__link" for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    并行和分布式训练
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_9">
            <span class="md-nav__icon md-icon"></span>
            并行和分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/60/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 分布式概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/61/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    单机模型并行最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/62/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式数据并行入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/63/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 PyTorch 编写分布式应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/64/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/65/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用分布式 RPC 框架实现参数服务器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/66/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 RPC 的分布式管道并行化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/67/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用异步执行实现批量 RPC 处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/68/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将分布式DataParallel与分布式 RPC 框架相结合
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.4 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1_1" id="__nav_5_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    使用 PyTorch 进行深度学习：60 分钟的闪电战
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_1">
            <span class="md-nav__icon md-icon"></span>
            使用 PyTorch 进行深度学习：60 分钟的闪电战
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/tensor_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    什么是PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/autograd_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd：自动求导
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/neural_networks_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/cifar10_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/data_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    可选：数据并行
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    编写自定义数据集，数据加载器和转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TensorBoard 可视化模型，数据和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图片
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            图片
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision 对象检测微调教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    转移学习的计算机视觉教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空间变压器网络教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行神经传递
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            音频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/15/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 使用char-RNN对姓氏进行分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/18/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 生成名称与字符级RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/19/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TorchText 进行文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/21/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TorchText 进行语言翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 nn.Transformer 和 TorchText 进行序列到序列建模
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    命名为 Tensor(实验性）
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            命名为 Tensor(实验性）
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/24/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性)PyTorch 中的命名张量简介
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" >
        
          
          <label class="md-nav__link" for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/26/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习(DQN)教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          <label class="md-nav__link" for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    在生产中部署 PyTorch 模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            在生产中部署 PyTorch 模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/28/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过带有 Flask 的 REST API 在 Python 中部署 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C --中加载 TorchScript 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_8" >
        
          
          <label class="md-nav__link" for="__nav_5_8" id="__nav_5_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    并行和分布式训练
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_8">
            <span class="md-nav__icon md-icon"></span>
            并行和分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/33/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    单机模型并行最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/34/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式数据并行入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/35/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 PyTorch 编写分布式应用程序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/36/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/37/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" >
        
          
          <label class="md-nav__link" for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            扩展 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/39/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C --运算符扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/40/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C --类扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/41/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 numpy 和 scipy 创建扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/42/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自定义 C --和 CUDA 扩展
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_10" >
        
          
          <label class="md-nav__link" for="__nav_5_10" id="__nav_5_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型优化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_10">
            <span class="md-nav__icon md-icon"></span>
            模型优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/44/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM Word 语言模型上的(实验）动态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/45/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性）在 PyTorch 中使用 Eager 模式进行静态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/46/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性）计算机视觉教程的量化转移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/47/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验）BERT 上的动态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/48/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    修剪教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_11" >
        
          
          <label class="md-nav__link" for="__nav_5_11" id="__nav_5_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 用其他语言
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_11">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 用其他语言
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C --前端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_12" >
        
          
          <label class="md-nav__link" for="__nav_5_12" id="__nav_5_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 基础知识
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_12">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 基础知识
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/52/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过示例学习 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/53/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn 到底是什么？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_13" >
        
          
          <label class="md-nav__link" for="__nav_5_13" id="__nav_5_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_13">
            <span class="md-nav__icon md-icon"></span>
            笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/56/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动求导机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/57/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    广播语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/58/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 线程和 TorchScript 推断
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/59/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA 语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/60/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 Autograd 设计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/61/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/62/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    经常问的问题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/63/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模部署的功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/64/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    并行处理最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/65/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    重现性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/66/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    远程参考协议
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/67/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列化语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/68/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows 常见问题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/69/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XLA 设备上的 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_14" >
        
          
          <label class="md-nav__link" for="__nav_5_14" id="__nav_5_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    语言绑定
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_14">
            <span class="md-nav__icon md-icon"></span>
            语言绑定
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/71/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch C -- API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/72/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Java API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_15" >
        
          
          <label class="md-nav__link" for="__nav_5_15" id="__nav_5_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_15">
            <span class="md-nav__icon md-icon"></span>
            Python API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/74/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/75/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/76/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/77/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/78/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    张量属性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/79/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动差分包-Torch.Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/81/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式通讯包-Torch.Distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/82/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    概率分布-torch分布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/84/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch脚本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/86/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/87/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/88/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch随机
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/91/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch稀疏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/92/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch存储
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/93/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/94/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/96/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/98/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/99/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    类型信息
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/101/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/102/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名为 Tensors 操作员范围
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/103/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    糟糕！
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_16" >
        
          
          <label class="md-nav__link" for="__nav_5_16" id="__nav_5_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchvision参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_16">
            <span class="md-nav__icon md-icon"></span>
            torchvision参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/105/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_17" >
        
          
          <label class="md-nav__link" for="__nav_5_17" id="__nav_5_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_17">
            <span class="md-nav__icon md-icon"></span>
            音频参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/107/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_18" >
        
          
          <label class="md-nav__link" for="__nav_5_18" id="__nav_5_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchtext参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_18">
            <span class="md-nav__icon md-icon"></span>
            torchtext参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/109/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_19" >
        
          
          <label class="md-nav__link" for="__nav_5_19" id="__nav_5_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    社区
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_19">
            <span class="md-nav__icon md-icon"></span>
            社区
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/111/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 贡献指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/112/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 治理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/113/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 治理| 感兴趣的人
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.0 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1" id="__nav_6_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1">
            <span class="md-nav__icon md-icon"></span>
            入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1_1" id="__nav_6_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 深度学习: 60 分钟极速入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 深度学习: 60 分钟极速入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_tensor_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    什么是 PyTorch？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_autograd_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd：自动求导
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_neural_networks_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_cifar10_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_data_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    可选：数据并行处理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_loading_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据加载和处理教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用例子学习 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy_seq2seq_hybrid_frontend_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合前端的 seq2seq 模型部署
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../saving_loading_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and Loading Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2_2" id="__nav_6_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图像
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_2">
            <span class="md-nav__icon md-icon"></span>
            图像
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning_torchvision_models_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchvision 模型微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空间变换器网络教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../neural_style_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行图像风格转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗性示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../super_resolution_with_caffe2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3" id="__nav_6_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatbot_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天机器人教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用字符级别特征的 RNN 网络生成姓氏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用字符级别特征的 RNN 网络进行姓氏分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3_4" id="__nav_6_2_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deep Learning for NLP with Pytorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            Deep Learning for NLP with Pytorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_nlp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在深度学习和 NLP 中使用 Pytorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_pytorch_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_deep_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_word_embeddings_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Word Embeddings: Encoding Lexical Semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_sequence_models_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列模型和 LSTM 网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_advanced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于注意力机制的 seq2seq 神经网络翻译
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_4" id="__nav_6_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    生成
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_4">
            <span class="md-nav__icon md-icon"></span>
            生成
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_5" >
        
          
          <label class="md-nav__link" for="__nav_6_2_5" id="__nav_6_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_5">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_6" >
        
          
          <label class="md-nav__link" for="__nav_6_2_6" id="__nav_6_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_6">
            <span class="md-nav__icon md-icon"></span>
            扩展 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy_extensions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 numpy 和 scipy 创建扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_7" >
        
          
          <label class="md-nav__link" for="__nav_6_2_7" id="__nav_6_2_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    生产性使用
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_7">
            <span class="md-nav__icon md-icon"></span>
            生产性使用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aws_distributed_training_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Amazon AWS 进行分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ONNXLive/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ONNX 现场演示教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中加载 PYTORCH 模型
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_8" >
        
          
          <label class="md-nav__link" for="__nav_6_2_8" id="__nav_6_2_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其它语言中的 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_8">
            <span class="md-nav__icon md-icon"></span>
            其它语言中的 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C++ 前端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" checked>
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_1" >
        
          
          <label class="md-nav__link" for="__nav_6_3_1" id="__nav_6_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    注解
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_1">
            <span class="md-nav__icon md-icon"></span>
            注解
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动求导机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_broadcasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    广播语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA 语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_extending/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multiprocessing best practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_randomness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reproducibility
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_serialization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_windows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_6_3_2" id="__nav_6_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    包参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_3_2">
            <span class="md-nav__icon md-icon"></span>
            包参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2_1" id="__nav_6_3_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_3_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2_1">
            <span class="md-nav__icon md-icon"></span>
            torch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_tensors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_random_sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Random sampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_serialization_parallelism_utilities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization, Parallelism, Utilities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2_1_5" id="__nav_6_3_2_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Math operations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_6_3_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            Math operations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_pointwise_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pointwise Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_reduction_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reduction Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_comparison_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Comparison Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_spectral_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spectral Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_other_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Other Operations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_blas_lapack_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BLAS and LAPACK Operations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Tensor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensor_attributes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor Attributes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../type_info/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据类型信息
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sparse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    torch.nn.functional
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    torch.nn.functional
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      卷积函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="卷积函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conv1d" class="md-nav__link">
    <span class="md-ellipsis">
      conv1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv2d" class="md-nav__link">
    <span class="md-ellipsis">
      conv2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv3d" class="md-nav__link">
    <span class="md-ellipsis">
      conv3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv_transpose1d" class="md-nav__link">
    <span class="md-ellipsis">
      conv_transpose1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv_transpose2d" class="md-nav__link">
    <span class="md-ellipsis">
      conv_transpose2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv_transpose3d" class="md-nav__link">
    <span class="md-ellipsis">
      conv_transpose3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unfold" class="md-nav__link">
    <span class="md-ellipsis">
      unfold
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fold" class="md-nav__link">
    <span class="md-ellipsis">
      fold
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      池化函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="池化函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#avg_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      avg_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avg_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      avg_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avg_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      avg_pool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      max_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      max_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      max_pool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_unpool1d" class="md-nav__link">
    <span class="md-ellipsis">
      max_unpool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_unpool2d" class="md-nav__link">
    <span class="md-ellipsis">
      max_unpool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_unpool3d" class="md-nav__link">
    <span class="md-ellipsis">
      max_unpool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lp_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      lp_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lp_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      lp_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_max_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_max_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_max_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_max_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_max_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_max_pool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_avg_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_avg_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_avg_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_avg_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_avg_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_avg_pool3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      非线性激活函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="非线性激活函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#threshold" class="md-nav__link">
    <span class="md-ellipsis">
      threshold
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      relu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardtanh" class="md-nav__link">
    <span class="md-ellipsis">
      hardtanh
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu6" class="md-nav__link">
    <span class="md-ellipsis">
      relu6
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#elu" class="md-nav__link">
    <span class="md-ellipsis">
      elu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selu" class="md-nav__link">
    <span class="md-ellipsis">
      selu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#celu" class="md-nav__link">
    <span class="md-ellipsis">
      celu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#leaky_relu" class="md-nav__link">
    <span class="md-ellipsis">
      leaky_relu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prelu" class="md-nav__link">
    <span class="md-ellipsis">
      prelu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rrelu" class="md-nav__link">
    <span class="md-ellipsis">
      rrelu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#glu" class="md-nav__link">
    <span class="md-ellipsis">
      glu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logsigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      logsigmoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardshrink" class="md-nav__link">
    <span class="md-ellipsis">
      hardshrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanhshrink" class="md-nav__link">
    <span class="md-ellipsis">
      tanhshrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softsign" class="md-nav__link">
    <span class="md-ellipsis">
      softsign
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softplus" class="md-nav__link">
    <span class="md-ellipsis">
      softplus
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmin" class="md-nav__link">
    <span class="md-ellipsis">
      softmin
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax" class="md-nav__link">
    <span class="md-ellipsis">
      softmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softshrink" class="md-nav__link">
    <span class="md-ellipsis">
      softshrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gumbel_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      gumbel_softmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      log_softmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    <span class="md-ellipsis">
      tanh
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      sigmoid
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      规范化函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="规范化函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch_norm" class="md-nav__link">
    <span class="md-ellipsis">
      batch_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance_norm" class="md-nav__link">
    <span class="md-ellipsis">
      instance_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer_norm" class="md-nav__link">
    <span class="md-ellipsis">
      layer_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#local_response_norm" class="md-nav__link">
    <span class="md-ellipsis">
      local_response_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalize" class="md-nav__link">
    <span class="md-ellipsis">
      normalize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      线性函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="线性函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear" class="md-nav__link">
    <span class="md-ellipsis">
      linear
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bilinear" class="md-nav__link">
    <span class="md-ellipsis">
      bilinear
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout 函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dropout 函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dropout_1" class="md-nav__link">
    <span class="md-ellipsis">
      dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha_dropout" class="md-nav__link">
    <span class="md-ellipsis">
      alpha_dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout2d" class="md-nav__link">
    <span class="md-ellipsis">
      dropout2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout3d" class="md-nav__link">
    <span class="md-ellipsis">
      dropout3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      稀疏函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="稀疏函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embedding" class="md-nav__link">
    <span class="md-ellipsis">
      embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding_bag" class="md-nav__link">
    <span class="md-ellipsis">
      embedding_bag
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      距离函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="距离函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pairwise_distance" class="md-nav__link">
    <span class="md-ellipsis">
      pairwise_distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_similarity" class="md-nav__link">
    <span class="md-ellipsis">
      cosine_similarity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pdist" class="md-nav__link">
    <span class="md-ellipsis">
      pdist
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      损失函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="损失函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary_cross_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      binary_cross_entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary_cross_entropy_with_logits" class="md-nav__link">
    <span class="md-ellipsis">
      binary_cross_entropy_with_logits
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poisson_nll_loss" class="md-nav__link">
    <span class="md-ellipsis">
      poisson_nll_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_embedding_loss" class="md-nav__link">
    <span class="md-ellipsis">
      cosine_embedding_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      cross_entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ctc_loss" class="md-nav__link">
    <span class="md-ellipsis">
      ctc_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hinge_embedding_loss" class="md-nav__link">
    <span class="md-ellipsis">
      hinge_embedding_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kl_div" class="md-nav__link">
    <span class="md-ellipsis">
      kl_div
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_loss" class="md-nav__link">
    <span class="md-ellipsis">
      l1_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_loss" class="md-nav__link">
    <span class="md-ellipsis">
      mse_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#margin_ranking_loss" class="md-nav__link">
    <span class="md-ellipsis">
      margin_ranking_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multilabel_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      multilabel_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multilabel_soft_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      multilabel_soft_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      multi_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nll_loss" class="md-nav__link">
    <span class="md-ellipsis">
      nll_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smooth_l1_loss" class="md-nav__link">
    <span class="md-ellipsis">
      smooth_l1_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#soft_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      soft_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#triplet_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      triplet_margin_loss
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      视觉函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="视觉函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pixel_shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      pixel_shuffle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pad" class="md-nav__link">
    <span class="md-ellipsis">
      pad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interpolate" class="md-nav__link">
    <span class="md-ellipsis">
      interpolate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsample" class="md-nav__link">
    <span class="md-ellipsis">
      upsample
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsample_nearest" class="md-nav__link">
    <span class="md-ellipsis">
      upsample_nearest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsample_bilinear" class="md-nav__link">
    <span class="md-ellipsis">
      upsample_bilinear
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grid_sample" class="md-nav__link">
    <span class="md-ellipsis">
      grid_sample
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#affine_grid" class="md-nav__link">
    <span class="md-ellipsis">
      affine_grid
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-gpu-distributed" class="md-nav__link">
    <span class="md-ellipsis">
      数据并行函数 (multi-GPU, distributed)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="数据并行函数 (multi-GPU, distributed)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data_parallel" class="md-nav__link">
    <span class="md-ellipsis">
      data_parallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_init/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic differentiation package - torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed communication package - torch.distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability distributions - torch.distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torch Script
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多进程包 - torch.multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bottleneck/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../checkpoint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docs_cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dlpack/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_zoo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributed_deprecated/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed communication package (deprecated) - torch.distributed.deprecated
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3_3" id="__nav_6_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchvision 参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_3">
            <span class="md-nav__icon md-icon"></span>
            torchvision 参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docs_torchvision_ref/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      卷积函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="卷积函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#conv1d" class="md-nav__link">
    <span class="md-ellipsis">
      conv1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv2d" class="md-nav__link">
    <span class="md-ellipsis">
      conv2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv3d" class="md-nav__link">
    <span class="md-ellipsis">
      conv3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv_transpose1d" class="md-nav__link">
    <span class="md-ellipsis">
      conv_transpose1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv_transpose2d" class="md-nav__link">
    <span class="md-ellipsis">
      conv_transpose2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conv_transpose3d" class="md-nav__link">
    <span class="md-ellipsis">
      conv_transpose3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unfold" class="md-nav__link">
    <span class="md-ellipsis">
      unfold
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fold" class="md-nav__link">
    <span class="md-ellipsis">
      fold
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      池化函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="池化函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#avg_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      avg_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avg_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      avg_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avg_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      avg_pool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      max_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      max_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      max_pool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_unpool1d" class="md-nav__link">
    <span class="md-ellipsis">
      max_unpool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_unpool2d" class="md-nav__link">
    <span class="md-ellipsis">
      max_unpool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_unpool3d" class="md-nav__link">
    <span class="md-ellipsis">
      max_unpool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lp_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      lp_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lp_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      lp_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_max_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_max_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_max_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_max_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_max_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_max_pool3d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_avg_pool1d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_avg_pool1d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_avg_pool2d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_avg_pool2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive_avg_pool3d" class="md-nav__link">
    <span class="md-ellipsis">
      adaptive_avg_pool3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      非线性激活函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="非线性激活函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#threshold" class="md-nav__link">
    <span class="md-ellipsis">
      threshold
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu" class="md-nav__link">
    <span class="md-ellipsis">
      relu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardtanh" class="md-nav__link">
    <span class="md-ellipsis">
      hardtanh
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#relu6" class="md-nav__link">
    <span class="md-ellipsis">
      relu6
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#elu" class="md-nav__link">
    <span class="md-ellipsis">
      elu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selu" class="md-nav__link">
    <span class="md-ellipsis">
      selu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#celu" class="md-nav__link">
    <span class="md-ellipsis">
      celu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#leaky_relu" class="md-nav__link">
    <span class="md-ellipsis">
      leaky_relu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prelu" class="md-nav__link">
    <span class="md-ellipsis">
      prelu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rrelu" class="md-nav__link">
    <span class="md-ellipsis">
      rrelu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#glu" class="md-nav__link">
    <span class="md-ellipsis">
      glu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logsigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      logsigmoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardshrink" class="md-nav__link">
    <span class="md-ellipsis">
      hardshrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanhshrink" class="md-nav__link">
    <span class="md-ellipsis">
      tanhshrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softsign" class="md-nav__link">
    <span class="md-ellipsis">
      softsign
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softplus" class="md-nav__link">
    <span class="md-ellipsis">
      softplus
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmin" class="md-nav__link">
    <span class="md-ellipsis">
      softmin
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax" class="md-nav__link">
    <span class="md-ellipsis">
      softmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softshrink" class="md-nav__link">
    <span class="md-ellipsis">
      softshrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gumbel_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      gumbel_softmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_softmax" class="md-nav__link">
    <span class="md-ellipsis">
      log_softmax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tanh" class="md-nav__link">
    <span class="md-ellipsis">
      tanh
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" class="md-nav__link">
    <span class="md-ellipsis">
      sigmoid
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      规范化函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="规范化函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch_norm" class="md-nav__link">
    <span class="md-ellipsis">
      batch_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance_norm" class="md-nav__link">
    <span class="md-ellipsis">
      instance_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#layer_norm" class="md-nav__link">
    <span class="md-ellipsis">
      layer_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#local_response_norm" class="md-nav__link">
    <span class="md-ellipsis">
      local_response_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#normalize" class="md-nav__link">
    <span class="md-ellipsis">
      normalize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      线性函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="线性函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear" class="md-nav__link">
    <span class="md-ellipsis">
      linear
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bilinear" class="md-nav__link">
    <span class="md-ellipsis">
      bilinear
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout 函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dropout 函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dropout_1" class="md-nav__link">
    <span class="md-ellipsis">
      dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alpha_dropout" class="md-nav__link">
    <span class="md-ellipsis">
      alpha_dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout2d" class="md-nav__link">
    <span class="md-ellipsis">
      dropout2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout3d" class="md-nav__link">
    <span class="md-ellipsis">
      dropout3d
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      稀疏函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="稀疏函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embedding" class="md-nav__link">
    <span class="md-ellipsis">
      embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding_bag" class="md-nav__link">
    <span class="md-ellipsis">
      embedding_bag
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      距离函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="距离函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pairwise_distance" class="md-nav__link">
    <span class="md-ellipsis">
      pairwise_distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_similarity" class="md-nav__link">
    <span class="md-ellipsis">
      cosine_similarity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pdist" class="md-nav__link">
    <span class="md-ellipsis">
      pdist
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      损失函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="损失函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary_cross_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      binary_cross_entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary_cross_entropy_with_logits" class="md-nav__link">
    <span class="md-ellipsis">
      binary_cross_entropy_with_logits
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#poisson_nll_loss" class="md-nav__link">
    <span class="md-ellipsis">
      poisson_nll_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine_embedding_loss" class="md-nav__link">
    <span class="md-ellipsis">
      cosine_embedding_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      cross_entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ctc_loss" class="md-nav__link">
    <span class="md-ellipsis">
      ctc_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hinge_embedding_loss" class="md-nav__link">
    <span class="md-ellipsis">
      hinge_embedding_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kl_div" class="md-nav__link">
    <span class="md-ellipsis">
      kl_div
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1_loss" class="md-nav__link">
    <span class="md-ellipsis">
      l1_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mse_loss" class="md-nav__link">
    <span class="md-ellipsis">
      mse_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#margin_ranking_loss" class="md-nav__link">
    <span class="md-ellipsis">
      margin_ranking_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multilabel_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      multilabel_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multilabel_soft_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      multilabel_soft_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      multi_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nll_loss" class="md-nav__link">
    <span class="md-ellipsis">
      nll_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smooth_l1_loss" class="md-nav__link">
    <span class="md-ellipsis">
      smooth_l1_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#soft_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      soft_margin_loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#triplet_margin_loss" class="md-nav__link">
    <span class="md-ellipsis">
      triplet_margin_loss
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      视觉函数
    </span>
  </a>
  
    <nav class="md-nav" aria-label="视觉函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pixel_shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      pixel_shuffle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pad" class="md-nav__link">
    <span class="md-ellipsis">
      pad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interpolate" class="md-nav__link">
    <span class="md-ellipsis">
      interpolate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsample" class="md-nav__link">
    <span class="md-ellipsis">
      upsample
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsample_nearest" class="md-nav__link">
    <span class="md-ellipsis">
      upsample_nearest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#upsample_bilinear" class="md-nav__link">
    <span class="md-ellipsis">
      upsample_bilinear
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#grid_sample" class="md-nav__link">
    <span class="md-ellipsis">
      grid_sample
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#affine_grid" class="md-nav__link">
    <span class="md-ellipsis">
      affine_grid
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-gpu-distributed" class="md-nav__link">
    <span class="md-ellipsis">
      数据并行函数 (multi-GPU, distributed)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="数据并行函数 (multi-GPU, distributed)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data_parallel" class="md-nav__link">
    <span class="md-ellipsis">
      data_parallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/1.0/nn_functional.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/1.0/nn_functional.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<h1 id="torchnnfunctional">torch.nn.functional</h1>
<blockquote>
<p>译者：<a href="https://github.com/hijkzzz">hijkzzz</a></p>
</blockquote>
<h2 id="_1">卷积函数</h2>
<h3 id="conv1d">conv1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号进行一维卷积. </p>
<p>有关详细信息和输出形状, 请参见<a href="#torch.nn.Conv1d" title="torch.nn.Conv1d"><code>Conv1d</code></a>. </p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iW)" />
*   <strong>weight</strong> – 卷积核, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D%20%5Ctimes%20%5Cfrac%7B%5Ctext%7Bin%5C_channels%7D%7D%7B%5Ctext%7Bgroups%7D%7D%20%5Ctimes%20kW)" />
*   <strong>bias</strong> – 可选的偏置, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D)" />. 默认值: <code>None</code>
*   <strong>stride</strong> – 卷积核的步幅, 可以是单个数字或一个元素元组<code>(sW,)</code>. 默认值: 1
*   <strong>padding</strong> – 在输入的两边隐式加零. 可以是单个数字或一个元素元组<code>(padW, )</code>. 默认值:  0
*   <strong>dilation</strong> – 核元素之间的空洞. 可以是单个数字或单元素元组<code>(dW,)</code>. 默认值:  1
*   <strong>groups</strong> – 将输入分组, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Bin%5C_channels%7D" /> 应该可以被组的数目整除. 默认值:  1</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">filters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">filters</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="conv2d">conv2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入图像应用二维卷积.</p>
<p>有关详细信息和输出形状, 请参见<a href="#torch.nn.Conv2d" title="torch.nn.Conv2d"><code>Conv2d</code></a>.</p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iH%20%5Ctimes%20iW)" />
*   <strong>weight</strong> – 卷积核, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D%20%5Ctimes%20%5Cfrac%7B%5Ctext%7Bin%5C_channels%7D%7D%7B%5Ctext%7Bgroups%7D%7D%20%5Ctimes%20kH%20%5Ctimes%20kW)" />
*   <strong>bias</strong> – 可选的偏置, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D)" />. 默认值:  <code>None</code>
*   <strong>stride</strong> – 卷积核的步幅, 可以是单个数字或一个元素元组 <code>(sH, sW)</code>. 默认值:  1
*   <strong>padding</strong> – 在输入的两边隐式加零. 可以是单个数字或一个元素元组 <code>(padH, padW)</code>. 默认值:  0
*   <strong>dilation</strong> – 核元素之间的空洞. 可以是单个数字或单元素元组 <code>(dH, dW)</code>. 默认值:  1
*   <strong>groups</strong> – 将输入分组, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Bin%5C_channels%7D" /> 应该可以被组的数目整除. 默认值:  1</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># With square kernels and equal stride</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">filters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="conv3d">conv3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入图像应用三维卷积.</p>
<p>有关详细信息和输出形状, 请参见 <a href="#torch.nn.Conv3d" title="torch.nn.Conv3d"><code>Conv3d</code></a>.</p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iT%20%5Ctimes%20iH%20%5Ctimes%20iW)" />
*   <strong>weight</strong> – 卷积核, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D%20%5Ctimes%20%5Cfrac%7B%5Ctext%7Bin%5C_channels%7D%7D%7B%5Ctext%7Bgroups%7D%7D%20%5Ctimes%20kT%20%5Ctimes%20kH%20%5Ctimes%20kW)" />
*   <strong>bias</strong> – 可选的偏置, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D)" />. 默认值:  None
*   <strong>stride</strong> – 卷积核的步幅, 可以是单个数字或一个元素元组 <code>(sT, sH, sW)</code>. 默认值:  1
*   <strong>padding</strong> – 在输入的两边隐式加零. 可以是单个数字或一个元素元组 <code>(padT, padH, padW)</code>. 默认值:  0
*   <strong>dilation</strong> – 核元素之间的空洞. 可以是单个数字或单元素元组 <code>(dT, dH, dW)</code>. 默认值:  1
*   <strong>groups</strong> – 将输入分组, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Bin%5C_channels%7D" /> 应该可以被组的数目整除. 默认值:  1</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">filters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">filters</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="conv_transpose1d">conv_transpose1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv_transpose1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号应用一维转置卷积操作, 有时也称为反卷积. </p>
<p>有关详细信息和输出形状, 请参见 <a href="#torch.nn.ConvTranspose1d" title="torch.nn.ConvTranspose1d"><code>ConvTranspose1d</code></a> </p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iW)" />
*   <strong>weight</strong> – 卷积核, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20%5Cfrac%7B%5Ctext%7Bout%5C_channels%7D%7D%7B%5Ctext%7Bgroups%7D%7D%20%5Ctimes%20kW)" />
*   <strong>bias</strong> – 可选的偏置, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D)" />. 默认值:  None
*   <strong>stride</strong> – 卷积核的步幅, 可以是单个数字或一个元素元组 <code>(sW,)</code>. 默认值:  1
*   <strong>padding</strong> – 输入中的每个维度的两边都将添加零填充<code>kernel_size - 1 - padding</code>. 可以是单个数字或元组 <code>(padW,)</code>. 默认值:  0
*   <strong>output_padding</strong> – 添加到输出形状中每个维度的一侧的额外大小. 可以是单个数字或元组 <code>(out_padW)</code>. 默认值:  0
*   <strong>groups</strong> – 将输入分组, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Bin%5C_channels%7D" /> 应该可以被组的数目整除. 默认值:  1
*   <strong>dilation</strong> – 核元素之间的空洞. 可以是单个数字或单元素元组 <code>(dW,)</code>. 默认值:  1</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">conv_transpose1d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="conv_transpose2d">conv_transpose2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv_transpose2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入图像应用二维转置卷积操作, 有时也称为反卷积.</p>
<p>有关详细信息和输出形状, 请参见 <a href="#torch.nn.ConvTranspose2d" title="torch.nn.ConvTranspose2d"><code>ConvTranspose2d</code></a>.</p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iH%20%5Ctimes%20iW)" />
*   <strong>weight</strong> – 卷积核, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20%5Cfrac%7B%5Ctext%7Bout%5C_channels%7D%7D%7B%5Ctext%7Bgroups%7D%7D%20%5Ctimes%20kH%20%5Ctimes%20kW)" />
*   <strong>bias</strong> –可选的偏置, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D)" />. 默认值:  None
*   <strong>stride</strong> – 卷积核的步幅, 可以是单个数字或一个元素元组 <code>(sH, sW)</code>. 默认值:  1
*   <strong>padding</strong> – 输入中的每个维度的两边都将添加零填充<code>kernel_size - 1 - padding</code>. 可以是单个数字或元组 <code>(padH, padW)</code>. 默认值:  0
*   <strong>output_padding</strong> – 添加到输出形状中每个维度的一侧的额外大小. 可以是单个数字或元组 <code>(out_padH, out_padW)</code>. 默认值:  0
*   <strong>groups</strong> – 将输入分组, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Bin%5C_channels%7D" /> 应该可以被组的数目整除. 默认值:  1
*   <strong>dilation</strong> – 核元素之间的空洞. 可以是单个数字或单元素元组 <code>(dH, dW)</code>. 默认值:  1</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># With square kernels and equal stride</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">conv_transpose2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="conv_transpose3d">conv_transpose3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv_transpose3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入图像应用一个三维转置卷积操作, 有时也称为反卷积</p>
<p>有关详细信息和输出形状, 请参见 <a href="#torch.nn.ConvTranspose3d" title="torch.nn.ConvTranspose3d"><code>ConvTranspose3d</code></a>.</p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iT%20%5Ctimes%20iH%20%5Ctimes%20iW)" />
*   <strong>weight</strong> – 卷积核, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20%5Cfrac%7B%5Ctext%7Bout%5C_channels%7D%7D%7B%5Ctext%7Bgroups%7D%7D%20%5Ctimes%20kT%20%5Ctimes%20kH%20%5Ctimes%20kW)" />
*   <strong>bias</strong> –可选的偏置, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bout%5C_channels%7D)" />. 默认值:  None
*   <strong>stride</strong> – 卷积核的步幅, 可以是单个数字或一个元素元组 <code>(sT, sH, sW)</code>. 默认值:  1
*   <strong>padding</strong> – 输入中的每个维度的两边都将添加零填充<code>kernel_size - 1 - padding</code>. 可以是单个数字或元组 <code>(padT, padH, padW)</code>. 默认值:  0
*   <strong>output_padding</strong> – 添加到输出形状中每个维度的一侧的额外大小. 可以是单个数字或元组 <code>(out_padT, out_padH, out_padW)</code>. 默认值:  0
*   <strong>groups</strong> – 将输入分组, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Bin%5C_channels%7D" /> 应该可以被组的数目整除. 默认值:  1
*   <strong>dilation</strong> – 核元素之间的空洞. 可以是单个数字或单元素元组 <code>(dT, dH, dW)</code>. 默认值:  1</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">conv_transpose3d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="unfold">unfold</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>从批量的输入张量中提取滑动局部块.</p>
<p>警告</p>
<p>目前, 仅支持四维(4D）的输入张量(批量的类似图像的张量).</p>
<p>细节请参阅 <a href="#torch.nn.Unfold" title="torch.nn.Unfold"><code>torch.nn.Unfold</code></a></p>
<h3 id="fold">fold</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fold</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>将一组滑动局部块数组合成一个大的张量.</p>
<p>警告</p>
<p>目前, 仅支持四维(4D）的输入张量(批量的类似图像的张量).</p>
<p>细节请参阅 <a href="#torch.nn.Fold" title="torch.nn.Fold"><code>torch.nn.Fold</code></a> </p>
<h2 id="_2">池化函数</h2>
<h3 id="avg_pool1d">avg_pool1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号应用一维平均池化.</p>
<p>有关详细信息和输出形状, 请参见 <a href="#torch.nn.AvgPool1d" title="torch.nn.AvgPool1d"><code>AvgPool1d</code></a>.</p>
<p>参数:
*   <strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iW)" />
*   <strong>kernel_size</strong> – 窗口的大小. 可以是单个数字或元组 <img alt="" src="http://latex.codecogs.com/gif.latex?(kW%2C)" />
*   <strong>stride</strong> – 窗户的步幅. 可以是单个数字或元组 <code>(sW,)</code>. 默认值:  <code>kernel_size</code>
*   <strong>padding</strong> – 在输入的两边隐式加零. 可以是单个数字或一个元素元组 <code>(padW,)</code>. 默认值:  0
*   <strong>ceil_mode</strong> – 如果 <code>True</code>, 将用 <code>ceil</code> 代替 <code>floor</code>计算输出形状. 默认值:  <code>False</code>
*   <strong>count_include_pad</strong> – 如果 <code>True</code>, 将在平均计算中包括零填充. 默认值:  <code>True</code></p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># pool of square window of size=3, stride=2</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]]])</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="n">tensor</span><span class="p">([[[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]])</span>
</code></pre></div></p>
<h3 id="avg_pool2d">avg_pool2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>在<img alt="" src="http://latex.codecogs.com/gif.latex?kH%20%5Ctimes%20kW" /> 区域应用二维平均池化, 步幅为 <img alt="" src="http://latex.codecogs.com/gif.latex?sH%20%5Ctimes%20sW" /> . 输出特征的数量等于输入平面的数量.</p>
<p>有关详细信息和输出形状, 请参见 <a href="#torch.nn.AvgPool2d" title="torch.nn.AvgPool2d"><code>AvgPool2d</code></a>.</p>
<p>参数:
*   <strong>input</strong> – input tensor <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iH%20%5Ctimes%20iW)" />
*   <strong>kernel_size</strong> – 池化区域的大小, 可以是一个数字或者元组 <img alt="" src="http://latex.codecogs.com/gif.latex?(kH%20%5Ctimes%20kW)" />
*   <strong>stride</strong> – 池化步幅, 可以是一个数字或者元组 <code>(sH, sW)</code>. 默认值:  <code>kernel_size</code>
*   <strong>padding</strong> – 在输入的两边隐式加零. 可以是单个数字或一个元素元组 <code>(padH, padW)</code>. 默认值:  0
*   <strong>ceil_mode</strong> – 如果 <code>True</code>, 将用 <code>ceil</code> 代替 <code>floor</code>计算输出形状. 默认值:  <code>False</code>
*   <strong>count_include_pad</strong> – 如果 <code>True</code>, 将在平均计算中包括零填充. 默认值:  <code>True</code></p>
<h3 id="avg_pool3d">avg_pool3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>应<img alt="" src="http://latex.codecogs.com/gif.latex?kT%20%5Ctimes%20kH%20%5Ctimes%20kW" /> 区域应用三维平均池化, 步幅为 <img alt="" src="http://latex.codecogs.com/gif.latex?sT%20%5Ctimes%20sH%20%5Ctimes%20sW" /> . 输出特征的数量等于 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Clfloor%5Cfrac%7B%5Ctext%7Binput%20planes%7D%7D%7BsT%7D%5Crfloor" />.</p>
<p>有关详细信息和输出形状, 请参见  <a href="#torch.nn.AvgPool3d" title="torch.nn.AvgPool3d"><code>AvgPool3d</code></a>.</p>
<p>参数:
*   <strong>input</strong> – 输入张量 <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Ctext%7Bminibatch%7D%20%5Ctimes%20%5Ctext%7Bin%5C_channels%7D%20%5Ctimes%20iT%20%5Ctimes%20iH%20%5Ctimes%20iW)" />
*   <strong>kernel_size</strong> – 池化区域的大小, 可以是一个数字或者元组 <img alt="" src="http://latex.codecogs.com/gif.latex?(kT%20%5Ctimes%20kH%20%5Ctimes%20kW)" />
*   <strong>stride</strong> – 池化步幅, 可以是一个数字或者元组 <code>(sT, sH, sW)</code>. 默认值:  <code>kernel_size</code>
*   <strong>padding</strong> – 在输入的两边隐式加零. 可以是单个数字或一个元素元组 <code>(padT, padH, padW)</code>, 默认值:  0
*   <strong>ceil_mode</strong> – 如果 <code>True</code>, 将用 <code>ceil</code> 代替 <code>floor</code>计算输出形状. 默认值:  <code>False</code>
*   <strong>count_include_pad</strong> – 如果 <code>True</code>, 将在平均计算中包括零填充. 默认值:  <code>True</code></p>
<h3 id="max_pool1d">max_pool1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool1d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号应用一维最大池化.</p>
<p>详情见 <a href="#torch.nn.MaxPool1d" title="torch.nn.MaxPool1d"><code>MaxPool1d</code></a>.</p>
<h3 id="max_pool2d">max_pool2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号应用二维最大池化.</p>
<p>详情见 <a href="#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code>MaxPool2d</code></a>.</p>
<h3 id="max_pool3d">max_pool3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool3d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号上应用三维最大池化.</p>
<p>详情见 <a href="#torch.nn.MaxPool3d" title="torch.nn.MaxPool3d"><code>MaxPool3d</code></a>.</p>
<h3 id="max_unpool1d">max_unpool1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>计算<code>MaxPool1d</code>的偏逆.</p>
<p>请参见 <a href="#torch.nn.MaxUnpool1d" title="torch.nn.MaxUnpool1d"><code>MaxUnpool1d</code></a>.</p>
<h3 id="max_unpool2d">max_unpool2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>计算<code>MaxPool2d</code>的偏逆.</p>
<p>详情见 <a href="#torch.nn.MaxUnpool2d" title="torch.nn.MaxUnpool2d"><code>MaxUnpool2d</code></a>.</p>
<h3 id="max_unpool3d">max_unpool3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>计算的<code>MaxPool3d</code>偏逆.</p>
<p>详情见 <a href="#torch.nn.MaxUnpool3d" title="torch.nn.MaxUnpool3d"><code>MaxUnpool3d</code></a>.</p>
<h3 id="lp_pool1d">lp_pool1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">lp_pool1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用一维幂平均池化. 如果所有输入的p次方的和为零, 梯度也为零. </p>
<p>详情见 <a href="#torch.nn.LPPool1d" title="torch.nn.LPPool1d"><code>LPPool1d</code></a>.</p>
<h3 id="lp_pool2d">lp_pool2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">lp_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用二维幂平均池化. 如果所有输入的p次方的和为零, 梯度也为零. </p>
<p>详情见 <a href="#torch.nn.LPPool2d" title="torch.nn.LPPool2d"><code>LPPool2d</code></a>.</p>
<h3 id="adaptive_max_pool1d">adaptive_max_pool1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool1d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用一维自适应最大池化.</p>
<p>请参见 <a href="#torch.nn.AdaptiveMaxPool1d" title="torch.nn.AdaptiveMaxPool1d"><code>AdaptiveMaxPool1d</code></a>和输出形状.</p>
<p>参数:
*   <strong>output_size</strong> – 目标输出的大小(单个整数)
*   <strong>return_indices</strong> – 是否返回池化索引. 默认值:  <code>False</code></p>
<h3 id="adaptive_max_pool2d">adaptive_max_pool2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool2d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用二维自适应最大池.</p>
<p>请参见 <a href="#torch.nn.AdaptiveMaxPool2d" title="torch.nn.AdaptiveMaxPool2d"><code>AdaptiveMaxPool2d</code></a> 和输出形状.</p>
<p>参数:
*   <strong>output_size</strong> – 目标输出的大小(单个整数 或者 双整数元组)
*   <strong>return_indices</strong> – 是否返回池化索引. 默认值:  <code>False</code></p>
<h3 id="adaptive_max_pool3d">adaptive_max_pool3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool3d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用三维自适应最大池.</p>
<p>请参见 <a href="#torch.nn.AdaptiveMaxPool3d" title="torch.nn.AdaptiveMaxPool3d"><code>AdaptiveMaxPool3d</code></a>和输出形状.</p>
<p>参数:
*   <strong>output_size</strong> – 目标输出的大小(单个整数 或者 三整数元组)
*   <strong>return_indices</strong> – 是否返回池化索引. 默认值:  <code>False</code></p>
<h3 id="adaptive_avg_pool1d">adaptive_avg_pool1d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool1d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用一维自适应平均池化.</p>
<p>请参见 <a href="#torch.nn.AdaptiveAvgPool1d" title="torch.nn.AdaptiveAvgPool1d"><code>AdaptiveAvgPool1d</code></a>  了解详情和输出的形状.</p>
<p>参数:
* <strong>output_size</strong> – 输出目标大小(单个整数) </p>
<h3 id="adaptive_avg_pool2d">adaptive_avg_pool2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用二维自适应平均池化.</p>
<p>请参见 <a href="#torch.nn.AdaptiveAvgPool2d" title="torch.nn.AdaptiveAvgPool2d"><code>AdaptiveAvgPool2d</code></a>  了解详情和输出的形状.</p>
<p>参数:
* <strong>output_size</strong> – 输出目标大小(单个整数 或者 双整数元组) </p>
<h3 id="adaptive_avg_pool3d">adaptive_avg_pool3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
</code></pre></div>
<p>在由多个输入平面组成的输入信号上应用三维自适应平均池化.</p>
<p>请参见 <a href="#torch.nn.AdaptiveAvgPool3d" title="torch.nn.AdaptiveAvgPool3d"><code>AdaptiveAvgPool3d</code></a>  了解详情和输出的形状.</p>
<p>参数:
* <strong>output_size</strong> – 输出目标大小(单个整数 或者 三整数元组) </p>
<h2 id="_3">非线性激活函数</h2>
<h3 id="threshold">threshold</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>为输入元素的每个元素设置阈值.</p>
<p>请参见 <a href="#torch.nn.Threshold" title="torch.nn.Threshold"><code>Threshold</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">threshold_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>就地版的 <a href="#torch.nn.functional.threshold" title="torch.nn.functional.threshold"><code>threshold()</code></a>.</p>
<h3 id="relu">relu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用整流线性单元函数. 请参见 <a href="#torch.nn.ReLU" title="torch.nn.ReLU"><code>ReLU</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu_</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>就地版的 <a href="#torch.nn.functional.relu" title="torch.nn.functional.relu"><code>relu()</code></a>.</p>
<h3 id="hardtanh">hardtanh</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardtanh</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_val</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用hardtanh函数. 请参见 <a href="#torch.nn.Hardtanh" title="torch.nn.Hardtanh"><code>Hardtanh</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardtanh_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_val</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版的 <a href="#torch.nn.functional.hardtanh" title="torch.nn.functional.hardtanh"><code>hardtanh()</code></a>.</p>
<h3 id="relu6">relu6</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu6</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用函数 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BReLU6%7D(x)%20%3D%20%5Cmin(%5Cmax(0%2Cx)%2C%206)" />.</p>
<p>请参见 <a href="#torch.nn.ReLU6" title="torch.nn.ReLU6"><code>ReLU6</code></a>.</p>
<h3 id="elu">elu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>逐元素应用 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BELU%7D(x)%20%3D%20%5Cmax(0%2Cx)%20%2B%20%5Cmin(0%2C%20%5Calpha%20*%20(%5Cexp(x)%20-%201))" />.</p>
<p>请参见 <a href="#torch.nn.ELU" title="torch.nn.ELU"><code>ELU</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">elu_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>就地版的 <a href="#torch.nn.functional.elu" title="torch.nn.functional.elu"><code>elu()</code></a>.</p>
<h3 id="selu">selu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">selu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BSELU%7D(x)%20%3D%20scale%20*%20(%5Cmax(0%2Cx)%20%2B%20%5Cmin(0%2C%20%5Calpha%20*%20(%5Cexp(x)%20-%201)))" />, 其中<img alt="" src="http://latex.codecogs.com/gif.latex?%5Calpha%3D1.6732632423543772848170429916717" /> 并且 <img alt="" src="http://latex.codecogs.com/gif.latex?scale%3D1.0507009873554804934193349852946" />.</p>
<p>请参见 <a href="#torch.nn.SELU" title="torch.nn.SELU"><code>SELU</code></a>.</p>
<h3 id="celu">celu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">celu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BCELU%7D(x)%20%3D%20%5Cmax(0%2Cx)%20%2B%20%5Cmin(0%2C%20%5Calpha%20*%20(%5Cexp(x%2F%5Calpha)%20-%201))" />.</p>
<p>请参见 <a href="#torch.nn.CELU" title="torch.nn.CELU"><code>CELU</code></a>.</p>
<h3 id="leaky_relu">leaky_relu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BLeakyReLU%7D(x)%20%3D%20%5Cmax(0%2C%20x)%20%2B%20%5Ctext%7Bnegative%5C_slope%7D%20*%20%5Cmin(0%2C%20x)" /></p>
<p>请参见 <a href="#torch.nn.LeakyReLU" title="torch.nn.LeakyReLU"><code>LeakyReLU</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">leaky_relu_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>就地版的 <a href="#torch.nn.functional.leaky_relu" title="torch.nn.functional.leaky_relu"><code>leaky_relu()</code></a>.</p>
<h3 id="prelu">prelu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">prelu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用函数 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BPReLU%7D(x)%20%3D%20%5Cmax(0%2Cx)%20%2B%20%5Ctext%7Bweight%7D%20*%20%5Cmin(0%2Cx)" /> 其中，权重是可学习的参数.</p>
<p>请参见 <a href="#torch.nn.PReLU" title="torch.nn.PReLU"><code>PReLU</code></a>.</p>
<h3 id="rrelu">rrelu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">rrelu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>随机的 leaky ReLU.</p>
<p>请参见 <a href="#torch.nn.RReLU" title="torch.nn.RReLU"><code>RReLU</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">rrelu_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>就地版的 <a href="#torch.nn.functional.rrelu" title="torch.nn.functional.rrelu"><code>rrelu()</code></a>.</p>
<h3 id="glu">glu</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">glu</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>门控线性单元. 计算:
<img alt="" src="http://latex.codecogs.com/gif.latex?%0D%0AH%20%3D%20A%20%5Ctimes%20%5Csigma(B)" /></p>
<p>其中<code>inpuy</code>沿<code>dim</code>分成两半, 形成<code>A</code>和<code>B</code>. </p>
<p>见 <a href="https://arxiv.org/abs/1612.08083">Language Modeling with Gated Convolutional Networks</a>.</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入张量
*   <strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 用于分割输入的维度</p>
<h3 id="logsigmoid">logsigmoid</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BLogSigmoid%7D(x)%20%3D%20%5Clog%20%5Cleft(%5Cfrac%7B1%7D%7B1%20%2B%20%5Cexp(-x_i)%7D%5Cright)" /></p>
<p>请参见 <a href="#torch.nn.LogSigmoid" title="torch.nn.LogSigmoid"><code>LogSigmoid</code></a>.</p>
<h3 id="hardshrink">hardshrink</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardshrink</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用hardshrink函数</p>
<p>请参见 <a href="#torch.nn.Hardshrink" title="torch.nn.Hardshrink"><code>Hardshrink</code></a>.</p>
<h3 id="tanhshrink">tanhshrink</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanhshrink</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用, <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BTanhshrink%7D(x)%20%3D%20x%20-%20%5Ctext%7BTanh%7D(x)" /></p>
<p>请参见 <a href="#torch.nn.Tanhshrink" title="torch.nn.Tanhshrink"><code>Tanhshrink</code></a>.</p>
<h3 id="softsign">softsign</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softsign</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用, the function <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BSoftSign%7D(x)%20%3D%20%5Cfrac%7Bx%7D%7B1%20%2B%20%7Cx%7C%7D" /></p>
<p>请参见 <a href="#torch.nn.Softsign" title="torch.nn.Softsign"><code>Softsign</code></a>.</p>
<h3 id="softplus">softplus</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<h3 id="softmin">softmin</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmin</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>应用 softmin 函数.</p>
<p>注意 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BSoftmin%7D(x)%20%3D%20%5Ctext%7BSoftmax%7D(-x)" />. 数学公式见softmax定义</p>
<p>请参见 <a href="#torch.nn.Softmin" title="torch.nn.Softmin"><code>Softmin</code></a>.</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入
*   <strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 计算softmin的维度(因此dim上每个切片的和为1).
*   <strong>dtype</strong> (<code>torch.dtype</code>, 可选的) – 返回tenosr的期望数据类型.</p>
<p>如果指定了参数, 输入张量在执行::param操作之前被转换为<code>dtype</code>. 这对于防止数据类型溢出非常有用. 默认值:  None.</p>
<h3 id="softmax">softmax</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>应用 softmax 函数.</p>
<p>Softmax定义为:
<img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BSoftmax%7D(x_%7Bi%7D)%20%3D%20%5Cfrac%7Bexp(x_i)%7D%7B%5Csum_j%20exp(x_j)%7D" /></p>
<p>它应用于dim上的所有切片, 并将对它们进行重新缩放, 使元素位于<code>(0,1)</code>范围内, 和为1.</p>
<p>请参见 <a href="#torch.nn.Softmax" title="torch.nn.Softmax"><code>Softmax</code></a>.</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入
*   <strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 将计算softmax的维度.
*   <strong>dtype</strong> (<code>torch.dtype</code>, 可选的) – 返回tenosr的期望数据类型.</p>
<p>:如果指定了参数, 输入张量在执行::param操作之前被转换为<code>dtype</code>. 这对于防止数据类型溢出非常有用. 默认值:  None.</p>
<p>注意</p>
<p>这个函数不能直接处理NLLLoss, NLLLoss要求日志在Softmax和它自己之间计算. 使用log_softmax来代替(它更快，并且具有更好的数值属性).</p>
<h3 id="softshrink">softshrink</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softshrink</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用 soft shrinkage 函数</p>
<p>请参见 <a href="#torch.nn.Softshrink" title="torch.nn.Softshrink"><code>Softshrink</code></a>.</p>
<h3 id="gumbel_softmax">gumbel_softmax</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">hard</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
</code></pre></div>
<p>采样自Gumbel-Softmax分布, 并可选择离散化.</p>
<p>参数:
*   <strong>logits</strong> – <code>[batch_size, num_features]</code> 非规范化对数概率
*   <strong>tau</strong> – 非负的对抗强度
*   <strong>hard</strong> – 如果 <code>True</code>, 返回的样本将会离散为 one-hot 向量, 但将会是可微分的，就像是在自动求导的soft样本一样</p>
<p>返回值:
* 从 Gumbel-Softmax 分布采样的 tensor, 形状为 <code>batch_size x num_features</code> . 如果 <code>hard=True</code>, 返回值是 one-hot 编码, 否则, 它们就是特征和为1的概率分布 </p>
<p>约束:
*   目前仅支持二维的 <code>logits</code> 输入张量, 形状为 <code>batch_size x num_features</code></p>
<p>基于 <a href="https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb">https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb</a> , (MIT license)</p>
<h3 id="log_softmax">log_softmax</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>应用 softmax 和对数运算.</p>
<p>虽然在数学上等价于log(softmax(x)), 但分开执行这两个操作比较慢, 而且在数值上不稳定. 这个函数使用另一种公式来正确计算输出和梯度.</p>
<p>请参见 <a href="#torch.nn.LogSoftmax" title="torch.nn.LogSoftmax"><code>LogSoftmax</code></a>.</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入
*   <strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 计算log_softmax的维度.
*   <strong>dtype</strong> (<code>torch.dtype</code>, 可选的) – 返回张量的期望数据类型.</p>
<p>:如果指定了参数, 输入张量在执行::param操作之前被转换为<code>dtype</code>. 这对于防止数据类型溢出非常有用. 默认值:  None.</p>
<h3 id="tanh">tanh</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BTanh%7D(x)%20%3D%20%5Ctanh(x)%20%3D%20%5Cfrac%7B%5Cexp(x)%20-%20%5Cexp(-x)%7D%7B%5Cexp(x)%20%2B%20%5Cexp(-x)%7D" /></p>
<p>请参见 <a href="#torch.nn.Tanh" title="torch.nn.Tanh"><code>Tanh</code></a>.</p>
<h3 id="sigmoid">sigmoid</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>逐元素应用函数 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7BSigmoid%7D(x)%20%3D%20%5Cfrac%7B1%7D%7B1%20%2B%20%5Cexp(-x)%7D" /></p>
<p>请参见 <a href="#torch.nn.Sigmoid" title="torch.nn.Sigmoid"><code>Sigmoid</code></a>.</p>
<h2 id="_4">规范化函数</h2>
<h3 id="batch_norm">batch_norm</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span>
</code></pre></div>
<p>对一批数据中的每个通道应用批量标准化.</p>
<p>请参见 <a href="#torch.nn.BatchNorm1d" title="torch.nn.BatchNorm1d"><code>BatchNorm1d</code></a>, <a href="#torch.nn.BatchNorm2d" title="torch.nn.BatchNorm2d"><code>BatchNorm2d</code></a>, <a href="#torch.nn.BatchNorm3d" title="torch.nn.BatchNorm3d"><code>BatchNorm3d</code></a>.</p>
<h3 id="instance_norm">instance_norm</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">instance_norm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">running_var</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_input_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span>
</code></pre></div>
<p>对批中每个数据样本中的每个通道应用实例规范化.</p>
<p>请参见 <a href="#torch.nn.InstanceNorm1d" title="torch.nn.InstanceNorm1d"><code>InstanceNorm1d</code></a>, <a href="#torch.nn.InstanceNorm2d" title="torch.nn.InstanceNorm2d"><code>InstanceNorm2d</code></a>, <a href="#torch.nn.InstanceNorm3d" title="torch.nn.InstanceNorm3d"><code>InstanceNorm3d</code></a>.</p>
<h3 id="layer_norm">layer_norm</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span>
</code></pre></div>
<p>对最后特定数量的维度应用layer规范化.</p>
<p>请参见 <a href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code>LayerNorm</code></a>.</p>
<h3 id="local_response_norm">local_response_norm</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">local_response_norm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>
<p>对由多个输入平面组成的输入信号进行局部响应归一化, 其中通道占据第二维. 跨通道应用标准化.</p>
<p>请参见 <a href="#torch.nn.LocalResponseNorm" title="torch.nn.LocalResponseNorm"><code>LocalResponseNorm</code></a>.</p>
<h3 id="normalize">normalize</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>对指定维度执行 <img alt="" src="http://latex.codecogs.com/gif.latex?L_p" /> 规范化.</p>
<p>对于一个尺寸为 <img alt="" src="http://latex.codecogs.com/gif.latex?(n_0%2C%20...%2C%20n_%7Bdim%7D%2C%20...%2C%20n_k)" />的输入张量, 每一 <img alt="" src="http://latex.codecogs.com/gif.latex?n_%7Bdim%7D" /> -元素向量<img alt="" src="http://latex.codecogs.com/gif.latex?v" /> 沿着维度 <code>dim</code> 被转换为
<img alt="" src="http://latex.codecogs.com/gif.latex?%0D%0Av%20%3D%20%5Cfrac%7Bv%7D%7B%5Cmax(%5ClVert%20v%20%5CrVert_p%2C%20%5Cepsilon)%7D.%0D%0A%0D%0A" /></p>
<p>对于默认参数, 它使用沿维度<img alt="" src="http://latex.codecogs.com/gif.latex?1" />的欧几里得范数进行标准化.</p>
<p>参数:
*   <strong>input</strong> – 任意形状的输入张量
*   <strong>p</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – 范数公式中的指数值. 默认值:  2
*   <strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 进行规约的维度. 默认值:  1
*   <strong>eps</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – 避免除以零的小值. 默认值:  1e-12
*   <strong>out</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – 输出张量. 如果 <code>out</code> 被设置, 此操作不可微分.</p>
<h2 id="_5">线性函数</h2>
<h3 id="linear">linear</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>对传入数据应用线性转换: <img alt="" src="http://latex.codecogs.com/gif.latex?y%20%3D%20xA%5ET%20%2B%20b" />.</p>
<p>形状:</p>
<blockquote>
<ul>
<li>Input: <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20*%2C%20in%5C_features)" />  <code>*</code> 表示任意数量的附加维度</li>
<li>Weight: <img alt="" src="http://latex.codecogs.com/gif.latex?(out%5C_features%2C%20in%5C_features)" /></li>
<li>Bias: <img alt="" src="http://latex.codecogs.com/gif.latex?(out%5C_features)" /></li>
<li>Output: <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20*%2C%20out%5C_features)" /></li>
</ul>
</blockquote>
<h3 id="bilinear">bilinear</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">bilinear</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<h2 id="dropout">Dropout 函数</h2>
<h3 id="dropout_1">dropout</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-68-1" name="__codelineno-68-1" href="#__codelineno-68-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>在训练过程中, 使用伯努利分布的样本, 随机地用概率<code>p</code>将输入张量的一些元素归零.</p>
<p>请参见 <a href="#torch.nn.Dropout" title="torch.nn.Dropout"><code>Dropout</code></a>.</p>
<p>参数:
*   <strong>p</strong> – 清零概率. 默认值:  0.5
*   <strong>training</strong> – 如果 <code>True</code> 使用 dropout. 默认值:  <code>True</code>
*   <strong>inplace</strong> – 如果设置为 <code>True</code>, 将会原地操作. 默认值:  <code>False</code></p>
<h3 id="alpha_dropout">alpha_dropout</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-69-1" name="__codelineno-69-1" href="#__codelineno-69-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">alpha_dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>对输入应用 alpha dropout.</p>
<p>请参见 <a href="#torch.nn.AlphaDropout" title="torch.nn.AlphaDropout"><code>AlphaDropout</code></a>.</p>
<h3 id="dropout2d">dropout2d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-70-1" name="__codelineno-70-1" href="#__codelineno-70-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>随机归零输入张量的整个通道 (一个通道是一个二维特征图, 例如, 在批量输入中第j个通道的第i个样本是一个二维张量的输入[i,j]). 每次前向传递时, 每个信道都将被独立清零. 用概率 <code>p</code> 从 Bernoulli 分布采样.</p>
<p>请参见 <a href="#torch.nn.Dropout2d" title="torch.nn.Dropout2d"><code>Dropout2d</code></a>.</p>
<p>参数:
*   <strong>p</strong> – 通道清零的概率. 默认值:  0.5
*   <strong>training</strong> – 使用 dropout 如果设为 <code>True</code>. 默认值:  <code>True</code>
*   <strong>inplace</strong> – 如果设置为 <code>True</code>, 将会做原地操作. 默认值:  <code>False</code></p>
<h3 id="dropout3d">dropout3d</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-71-1" name="__codelineno-71-1" href="#__codelineno-71-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout3d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>随机归零输入张量的整个通道 (一个通道是一个三维特征图, 例如, 在批量输入中第j个通道的第i个样本是一个三维张量的输入[i,j]). 每次前向传递时, 每个信道都将被独立清零. 用概率 <code>p</code> 从 Bernoulli 分布采样.</p>
<p>请参见 <a href="#torch.nn.Dropout3d" title="torch.nn.Dropout3d"><code>Dropout3d</code></a>.</p>
<p>参数:
*   <strong>p</strong> – 通道清零的概率. 默认值:  0.5
*   <strong>training</strong> – 使用 dropout 如果设为 <code>True</code>. 默认值:  <code>True</code>
*   <strong>inplace</strong> – 如果设置为 <code>True</code>, 将会做原地操作. 默认值:  <code>False</code></p>
<h2 id="_6">稀疏函数</h2>
<h3 id="embedding">embedding</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-72-1" name="__codelineno-72-1" href="#__codelineno-72-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>一个简单的查找表, 查找固定字典中的embedding(嵌入)内容和大小.</p>
<p>这个模块通常用于使用索引检索单词嵌入. 模块的输入是索引列表和嵌入矩阵, 输出是相应的单词嵌入.</p>
<p>请参见 <a href="#torch.nn.Embedding" title="torch.nn.Embedding"><code>torch.nn.Embedding</code></a>.</p>
<p>参数:
*   <strong>input</strong> (<em>LongTensor</em>) –  包含嵌入矩阵中的索引的张量
*   <strong>weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 嵌入矩阵的行数等于可能的最大索引数+ 1, 列数等于嵌入大小
*   <strong>padding_idx</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>可选的</em>) –  如果给定, 每当遇到索引时, 在<code>padding_idx</code> (初始化为零)用嵌入向量填充输出.
*   <strong>max_norm</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>,</em> <em>可选的</em>) – 如果给定, 则将范数大于<code>max_norm</code>的每个嵌入向量重新规范化, 得到范数<code>max_norm</code>. 注意:这将修改适当的<code>weight</code>.
*   <strong>norm_type</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>,</em> <em>可选的</em>) – 用于计算<code>max_norm</code>选项的p范数的p. 默认 <code>2</code>.
*   <strong>scale_grad_by_freq</strong> (<em>boolean__,</em> <em>可选的</em>) – 如果给定, 这将通过小批处理中单词频率的倒数来缩放梯度. 默认 <code>False</code>.
*   <strong>sparse</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 如果值为 <code>True</code>, 梯度 w.r.t. <code>weight</code> 将会是一个稀疏 tensor. 请看 <a href="#torch.nn.Embedding" title="torch.nn.Embedding"><code>torch.nn.Embedding</code></a>有关稀疏梯度的更多详细信息.</p>
<p>形状:</p>
<blockquote>
<ul>
<li>Input:  包含要提取的索引的任意形状的长张量</li>
<li>Weight: 浮点型嵌入矩阵, 形状为 (V, embedding_dim),
   V = maximum index + 1 并且 embedding_dim = the embedding size</li>
<li>Output: <code>(*, embedding_dim)</code>,  <code>*</code> 是输入形状</li>
</ul>
</blockquote>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-73-1" name="__codelineno-73-1" href="#__codelineno-73-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># a batch of 2 samples of 4 indices each</span>
<a id="__codelineno-73-2" name="__codelineno-73-2" href="#__codelineno-73-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-73-3" name="__codelineno-73-3" href="#__codelineno-73-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># an embedding matrix containing 10 tensors of size 3</span>
<a id="__codelineno-73-4" name="__codelineno-73-4" href="#__codelineno-73-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-73-5" name="__codelineno-73-5" href="#__codelineno-73-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">embedding_matrix</span><span class="p">)</span>
<a id="__codelineno-73-6" name="__codelineno-73-6" href="#__codelineno-73-6"></a><span class="n">tensor</span><span class="p">([[[</span> <span class="mf">0.8490</span><span class="p">,</span>  <span class="mf">0.9625</span><span class="p">,</span>  <span class="mf">0.6753</span><span class="p">],</span>
<a id="__codelineno-73-7" name="__codelineno-73-7" href="#__codelineno-73-7"></a> <span class="p">[</span> <span class="mf">0.9666</span><span class="p">,</span>  <span class="mf">0.7761</span><span class="p">,</span>  <span class="mf">0.6108</span><span class="p">],</span>
<a id="__codelineno-73-8" name="__codelineno-73-8" href="#__codelineno-73-8"></a> <span class="p">[</span> <span class="mf">0.6246</span><span class="p">,</span>  <span class="mf">0.9751</span><span class="p">,</span>  <span class="mf">0.3618</span><span class="p">],</span>
<a id="__codelineno-73-9" name="__codelineno-73-9" href="#__codelineno-73-9"></a> <span class="p">[</span> <span class="mf">0.4161</span><span class="p">,</span>  <span class="mf">0.2419</span><span class="p">,</span>  <span class="mf">0.7383</span><span class="p">]],</span>
<a id="__codelineno-73-10" name="__codelineno-73-10" href="#__codelineno-73-10"></a>
<a id="__codelineno-73-11" name="__codelineno-73-11" href="#__codelineno-73-11"></a> <span class="p">[[</span> <span class="mf">0.6246</span><span class="p">,</span>  <span class="mf">0.9751</span><span class="p">,</span>  <span class="mf">0.3618</span><span class="p">],</span>
<a id="__codelineno-73-12" name="__codelineno-73-12" href="#__codelineno-73-12"></a> <span class="p">[</span> <span class="mf">0.0237</span><span class="p">,</span>  <span class="mf">0.7794</span><span class="p">,</span>  <span class="mf">0.0528</span><span class="p">],</span>
<a id="__codelineno-73-13" name="__codelineno-73-13" href="#__codelineno-73-13"></a> <span class="p">[</span> <span class="mf">0.9666</span><span class="p">,</span>  <span class="mf">0.7761</span><span class="p">,</span>  <span class="mf">0.6108</span><span class="p">],</span>
<a id="__codelineno-73-14" name="__codelineno-73-14" href="#__codelineno-73-14"></a> <span class="p">[</span> <span class="mf">0.3385</span><span class="p">,</span>  <span class="mf">0.8612</span><span class="p">,</span>  <span class="mf">0.1867</span><span class="p">]]])</span>
<a id="__codelineno-73-15" name="__codelineno-73-15" href="#__codelineno-73-15"></a>
<a id="__codelineno-73-16" name="__codelineno-73-16" href="#__codelineno-73-16"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># example with padding_idx</span>
<a id="__codelineno-73-17" name="__codelineno-73-17" href="#__codelineno-73-17"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-73-18" name="__codelineno-73-18" href="#__codelineno-73-18"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<a id="__codelineno-73-19" name="__codelineno-73-19" href="#__codelineno-73-19"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">weights</span>
<a id="__codelineno-73-20" name="__codelineno-73-20" href="#__codelineno-73-20"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
<a id="__codelineno-73-21" name="__codelineno-73-21" href="#__codelineno-73-21"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-73-22" name="__codelineno-73-22" href="#__codelineno-73-22"></a><span class="n">tensor</span><span class="p">([[[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
<a id="__codelineno-73-23" name="__codelineno-73-23" href="#__codelineno-73-23"></a> <span class="p">[</span> <span class="mf">0.5609</span><span class="p">,</span>  <span class="mf">0.5384</span><span class="p">,</span>  <span class="mf">0.8720</span><span class="p">],</span>
<a id="__codelineno-73-24" name="__codelineno-73-24" href="#__codelineno-73-24"></a> <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
<a id="__codelineno-73-25" name="__codelineno-73-25" href="#__codelineno-73-25"></a> <span class="p">[</span> <span class="mf">0.6262</span><span class="p">,</span>  <span class="mf">0.2438</span><span class="p">,</span>  <span class="mf">0.7471</span><span class="p">]]])</span>
</code></pre></div></p>
<h3 id="embedding_bag">embedding_bag</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-74-1" name="__codelineno-74-1" href="#__codelineno-74-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">embedding_bag</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>计算嵌入<code>bags</code>的和、平均值或最大值, 而不实例化中间嵌入.</p>
<p>请参见 <a href="#torch.nn.EmbeddingBag" title="torch.nn.EmbeddingBag"><code>torch.nn.EmbeddingBag</code></a></p>
<p>参数:</p>
<ul>
<li><strong>input</strong> (<em>LongTensor</em>) – 包含嵌入矩阵的索引的<code>bags</code>张量</li>
<li><strong>weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 嵌入矩阵的行数等于可能的最大索引数+ 1, 列数等于嵌入大小</li>
<li><strong>offsets</strong> (<em>LongTensor__,</em> <em>可选的</em>) – 仅当<code>input</code>为一维时使用. <code>offsets</code>确定输入中每个<code>bag</code>(序列)的起始索引位置</li>
<li><strong>max_norm</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>,</em> <em>可选的</em>) –  如果给定此参数, 范数大于<code>max_norm</code>的每个嵌入向量将被重新规格化为范数<code>max_norm</code>. 注意:这将就地修改<code>weight</code></li>
<li><strong>norm_type</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>,</em> <em>可选的</em>) – The <code>p</code> in the <code>p</code>-norm to compute for the <code>max_norm</code> option. 默认 <code>2</code>.</li>
<li><strong>scale_grad_by_freq</strong> (<em>boolean__,</em> <em>可选的</em>) – 如果给定此参数, 这将通过小批处理中单词频率的倒数来缩放梯度. 默认值 False. 注意:当<code>mode="max"</code>时不支持此选项.</li>
<li><strong>mode</strong> (<em>string__,</em> <em>可选的</em>) – <code>"sum"</code>, <code>"mean"</code> or <code>"max"</code>. 指定减少<code>bag</code>的方法. 默认值: <code>"mean"</code></li>
<li><strong>sparse</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 如果<code>True</code>, 梯度w.r.t.权值就是一个稀疏张量.请参见 <a href="#torch.nn.Embedding" title="torch.nn.Embedding"><code>torch.nn.Embedding</code></a> 关于稀疏梯度. 注意: 此选项不支持 <code>mode="max"</code>.</li>
</ul>
<p>形状:</p>
<blockquote>
<ul>
<li><code>input</code> (LongTensor) 和 <code>offsets</code> (LongTensor, 可选的)  <ul>
<li>如果 <code>input</code> 是二维的, 形状为 <code>B x N</code>,   <br />
    它将被视为每个固定长度<code>N</code>的<code>B</code>个bag(序列), 这将根据模式以某种方式返回<code>B</code>个聚合值. 在本例中, <code>offsets</code>被忽略, 并且要求为<code>None</code>      </li>
<li>如果 <code>input</code> 是一维的, 形状为 <code>N</code>
    它将被视为多个<code>bag</code>(序列)的串联. <code>offsets</code>必须是一个一维tensor, 其中包含<code>input</code>中每个<code>bag</code>的起始索引位置. 因此, 对于形状<code>B</code>的偏移量, 输入将被视为有<code>B</code>个bag. 空bags( 即, 具有0长度)将返回由0填充的向量</li>
</ul>
</li>
<li><code>weight</code> (Tensor): 模块的可学习权重, 形状 <code>(num_embeddings x embedding_dim)</code></li>
<li><code>output</code>: 聚合的嵌入值, 形状 <code>B x embedding_dim</code></li>
</ul>
</blockquote>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-75-1" name="__codelineno-75-1" href="#__codelineno-75-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># an Embedding module containing 10 tensors of size 3</span>
<a id="__codelineno-75-2" name="__codelineno-75-2" href="#__codelineno-75-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-75-3" name="__codelineno-75-3" href="#__codelineno-75-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># a batch of 2 samples of 4 indices each</span>
<a id="__codelineno-75-4" name="__codelineno-75-4" href="#__codelineno-75-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>
<a id="__codelineno-75-5" name="__codelineno-75-5" href="#__codelineno-75-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-75-6" name="__codelineno-75-6" href="#__codelineno-75-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding_bag</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
<a id="__codelineno-75-7" name="__codelineno-75-7" href="#__codelineno-75-7"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.3397</span><span class="p">,</span>  <span class="mf">0.3552</span><span class="p">,</span>  <span class="mf">0.5545</span><span class="p">],</span>
<a id="__codelineno-75-8" name="__codelineno-75-8" href="#__codelineno-75-8"></a> <span class="p">[</span> <span class="mf">0.5893</span><span class="p">,</span>  <span class="mf">0.4386</span><span class="p">,</span>  <span class="mf">0.5882</span><span class="p">]])</span>
</code></pre></div></p>
<h2 id="_7">距离函数</h2>
<h3 id="pairwise_distance">pairwise_distance</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-76-1" name="__codelineno-76-1" href="#__codelineno-76-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pairwise_distance</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.PairwiseDistance" title="torch.nn.PairwiseDistance"><code>torch.nn.PairwiseDistance</code></a></p>
<h3 id="cosine_similarity">cosine_similarity</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-77-1" name="__codelineno-77-1" href="#__codelineno-77-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回x1和x2之间的余弦相似度, 沿dim计算
<img alt="" src="http://latex.codecogs.com/gif.latex?%0D%0A%5Ctext%7Bsimilarity%7D%20%3D%20%5Cdfrac%7Bx_1%20%5Ccdot%20x_2%7D%7B%5Cmax(%5CVert%20x_1%20%5CVert%20_2%20%5Ccdot%20%5CVert%20x_2%20%5CVert%20_2%2C%20%5Cepsilon)%7D%0D%0A%0D%0A" /></p>
<p>参数:
*   <strong>x1</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 第一个输入.
*   <strong>x2</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 第二个输入(大小和 x1 匹配).
*   <strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>可选的</em>) – 维度. 默认值:  1
*   <strong>eps</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>,</em> <em>可选的</em>) – 非常小的值避免除以0. 默认值:  1e-8</p>
<p>形状:
*   Input: <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Cast_1%2C%20D%2C%20%5Cast_2)" /> 其中D在<code>dim</code>位置.
*   Output: <img alt="" src="http://latex.codecogs.com/gif.latex?(%5Cast_1%2C%20%5Cast_2)" /> 其中1在<code>dim</code>位置.</p>
<p>例子: 
<div class="highlight"><pre><span></span><code><a id="__codelineno-78-1" name="__codelineno-78-1" href="#__codelineno-78-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<a id="__codelineno-78-2" name="__codelineno-78-2" href="#__codelineno-78-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<a id="__codelineno-78-3" name="__codelineno-78-3" href="#__codelineno-78-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
<a id="__codelineno-78-4" name="__codelineno-78-4" href="#__codelineno-78-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="pdist">pdist</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-79-1" name="__codelineno-79-1" href="#__codelineno-79-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pdist</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>计算输入中每对行向量之间的p范数距离.  这与<code>torch.norm(input[:, None] - input, dim=2, p=p)</code>的上三角形部分(不包括对角线）相同.  如果行是连续的, 则此函数将更快</p>
<p>如果输入具有形状 <img alt="" src="http://latex.codecogs.com/gif.latex?N%20%5Ctimes%20M" /> 则输出将具有形状 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B1%7D%7B2%7D%20N%20(N%20-%201)" />.</p>
<p>这个函数相当于 <code>scipy.spatial.distance.pdist(input, 'minkowski', p=p)</code> 如果 <img alt="" src="http://latex.codecogs.com/gif.latex?p%20%5Cin%20(0%2C%20%5Cinfty)" />. 当 <img alt="" src="http://latex.codecogs.com/gif.latex?p%20%3D%200" /> 它等价于 <code>scipy.spatial.distance.pdist(input, 'hamming') * M</code>. 当 <img alt="" src="http://latex.codecogs.com/gif.latex?p%20%3D%20%5Cinfty" />, 最相近的scipy函数是 <code>scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max())</code>.</p>
<p>参数:</p>
<ul>
<li><strong>input</strong> – 输入张量, 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?N%20%5Ctimes%20M" />.</li>
<li><strong>p</strong> – 计算每个向量对之间的p范数距离的p值 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Cin%20%5B0%2C%20%5Cinfty%5D" />.</li>
</ul>
<h2 id="_8">损失函数</h2>
<h3 id="binary_cross_entropy">binary_cross_entropy</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-80-1" name="__codelineno-80-1" href="#__codelineno-80-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p>计算目标和输出之间二进制交叉熵的函数.</p>
<p>请参见 <a href="#torch.nn.BCELoss" title="torch.nn.BCELoss"><code>BCELoss</code></a>.</p>
<p>参数:
*   <strong>input</strong> – 任意形状的张量
*   <strong>target</strong> – 与输入形状相同的张量
*   <strong>weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – 手动重新调整权重, 如果提供, 它重复来匹配输入张量的形状
*   <strong>size_average</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 批处理中的每个损失元素的平均损失. 注意, 对于某些损失, 每个样本有多个元素. 如果<code>size_average</code>设置为<code>False</code>, 则对每个小批的损失进行汇总. reduce为False时忽略. 默认值:  <code>True</code>
*   <strong>reduce</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 根据size_average, 对每个小批量的观察结果的损失进行平均或求和.  当reduce为False时, 返回每批元素的损失并忽略<code>size_average</code>. 默认值:  <code>True</code>
*   <strong>reduction</strong> (<em>string__,</em> <em>可选的</em>) – 指定要应用于输出的<code>reduction</code>：'none'| 'mean'| 'sum'.  'none'：没有reduction, 'mean'：输出的总和将除以输出中的元素数量 'sum'：输出将被求和.  注意：<code>size_average</code>和<code>reduce</code>正在被弃用, 同时, 指定这两个args中的任何一个都将覆盖reduce.  默认值：'mean', 默认值:  'mean'</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-81-1" name="__codelineno-81-1" href="#__codelineno-81-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-81-2" name="__codelineno-81-2" href="#__codelineno-81-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-81-3" name="__codelineno-81-3" href="#__codelineno-81-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
<a id="__codelineno-81-4" name="__codelineno-81-4" href="#__codelineno-81-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="binary_cross_entropy_with_logits">binary_cross_entropy_with_logits</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-82-1" name="__codelineno-82-1" href="#__codelineno-82-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>计算目标和输出logits之间的二进制交叉熵的函数.</p>
<p>请参见 <a href="#torch.nn.BCEWithLogitsLoss" title="torch.nn.BCEWithLogitsLoss"><code>BCEWithLogitsLoss</code></a>.</p>
<p>参数:
*   <strong>input</strong> – 任意形状的张量
*   <strong>target</strong> – 与输入形状相同的张量
*   <strong>weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – 手动重新调整权重, 如果提供, 它重复来匹配输入张量的形状
*   <strong>size_average</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 批处理中的每个损失元素的平均损失. 注意, 对于某些损失, 每个样本有多个元素. 如果<code>size_average</code>设置为<code>False</code>, 则对每个小批的损失进行汇总. reduce为False时忽略. 默认值:  <code>True</code>
*   <strong>reduce</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 根据size_average, 对每个小批量的观察结果的损失进行平均或求和.  当reduce为False时, 返回每批元素的损失并忽略<code>size_average</code>. 默认值:  <code>True</code>
*   <strong>reduction</strong> (<em>string__,</em> <em>可选的</em>) – 指定要应用于输出的<code>reduction</code>：'none'| 'mean'| 'sum'.  'none'：没有reduction, 'mean'：输出的总和将除以输出中的元素数量 'sum'：输出将被求和.  注意：<code>size_average</code>和<code>reduce</code>正在被弃用, 同时, 指定这两个args中的任何一个都将覆盖reduce.  默认值：'mean', 默认值:  'mean'
*   <strong>pos_weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – 正例样本的权重. 必须是长度等于类数的向量.</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-83-1" name="__codelineno-83-1" href="#__codelineno-83-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-83-2" name="__codelineno-83-2" href="#__codelineno-83-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-83-3" name="__codelineno-83-3" href="#__codelineno-83-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<a id="__codelineno-83-4" name="__codelineno-83-4" href="#__codelineno-83-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="poisson_nll_loss">poisson_nll_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-84-1" name="__codelineno-84-1" href="#__codelineno-84-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">poisson_nll_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">log_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p>泊松负对数似然损失.</p>
<p>请参见 <a href="#torch.nn.PoissonNLLLoss" title="torch.nn.PoissonNLLLoss"><code>PoissonNLLLoss</code></a>.</p>
<p>参数:
*   <strong>input</strong> – 潜在泊松分布的期望.
*   <strong>target</strong> – 随机抽样 <img alt="" src="http://latex.codecogs.com/gif.latex?target%20%5Csim%20%5Ctext%7BPoisson%7D(input)" />.
*   <strong>log_input</strong> – 如果为<code>True</code>, 则损失计算为 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Cexp(%5Ctext%7Binput%7D)%20-%20%5Ctext%7Btarget%7D%20*%20%5Ctext%7Binput%7D" />, 如果为<code>False</code>, 则损失计算为 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Binput%7D%20-%20%5Ctext%7Btarget%7D%20*%20%5Clog(%5Ctext%7Binput%7D%2B%5Ctext%7Beps%7D)" />. 默认值:  <code>True</code>
*   <strong>full</strong> – 是否计算全部损失, 即. 加入Stirling近似项. 默认值:  <code>False</code> <img alt="" src="http://latex.codecogs.com/gif.latex?%5Ctext%7Btarget%7D%20*%20%5Clog(%5Ctext%7Btarget%7D)%20-%20%5Ctext%7Btarget%7D%20%2B%200.5%20*%20%5Clog(2%20*%20%5Cpi%20*%20%5Ctext%7Btarget%7D)" />.
*   <strong>size_average</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 批处理中的每个损失元素的平均损失. 注意, 对于某些损失, 每个样本有多个元素. 如果<code>size_average</code>设置为<code>False</code>, 则对每个小批的损失进行汇总. reduce为False时忽略. 默认值:  <code>True</code>
*   <strong>eps</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>,</em> <em>可选的</em>) – 一个小值避免求值 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Clog(0)" /> 当 <code>log_input</code>=<code>False</code>. 默认值:  1e-8
*   <strong>reduce</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 根据size_average, 对每个小批量的观察结果的损失进行平均或求和.  当reduce为False时, 返回每批元素的损失并忽略<code>size_average</code>. 默认值:  <code>True</code>
*   <strong>reduction</strong> (<em>string__,</em> <em>可选的</em>) – 指定要应用于输出的<code>reduction</code>：'none'| 'mean'| 'sum'.  'none'：没有reduction, 'mean'：输出的总和将除以输出中的元素数量 'sum'：输出将被求和.  注意：<code>size_average</code>和<code>reduce</code>正在被弃用, 同时, 指定这两个args中的任何一个都将覆盖reduce.  默认值：'mean', 默认值:  'mean'</p>
<h3 id="cosine_embedding_loss">cosine_embedding_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-85-1" name="__codelineno-85-1" href="#__codelineno-85-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cosine_embedding_loss</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.CosineEmbeddingLoss" title="torch.nn.CosineEmbeddingLoss"><code>CosineEmbeddingLoss</code></a>.</p>
<h3 id="cross_entropy">cross_entropy</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-86-1" name="__codelineno-86-1" href="#__codelineno-86-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p>此函数结合了 <code>log_softmax</code> 和 <code>nll_loss</code>.</p>
<p>请参见 <a href="#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><code>CrossEntropyLoss</code></a>.</p>
<p>参数:</p>
<ul>
<li><strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C)" /> 其中 <code>C = 类别数</code> 或者在二维损失的情况下为 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20H%2C%20W)" />, 或者 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20d_1%2C%20d_2%2C%20...%2C%20d_K)" /> 当 <img alt="" src="http://latex.codecogs.com/gif.latex?K%20%3E%201" /> 在k维损失的情况下</li>
<li><strong>target</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – <img alt="" src="http://latex.codecogs.com/gif.latex?(N)" /> 其中每个值都在 <img alt="" src="http://latex.codecogs.com/gif.latex?0%20%5Cleq%20%5Ctext%7Btargets%7D%5Bi%5D%20%5Cleq%20C-1" />范围内, 或者 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20d_1%2C%20d_2%2C%20...%2C%20d_K)" /> 其中 <img alt="" src="http://latex.codecogs.com/gif.latex?K%20%5Cgeq%201" /> 在k维损失情况下.</li>
<li><strong>weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – 给每个类别的手动重定权重. 如果给定, 必须是大小为<code>C</code>的张量</li>
<li><strong>size_average</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 批处理中的每个损失元素的平均损失. 注意, 对于某些损失, 每个样本有多个元素. 如果<code>size_average</code>设置为<code>False</code>, 则对每个小批的损失进行汇总. reduce为False时忽略. 默认值:  <code>True</code></li>
<li><strong>ignore_index</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>可选的</em>) – 指定一个被忽略的目标值，该目标值不影响输入梯度。当 <code>size_average</code> 取值为 <code>True</code>, 损失平均在不可忽略的目标上. 默认值:  -100</li>
<li><strong>reduce</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 根据size_average, 对每个小批量的观察结果的损失进行平均或求和.  当reduce为False时, 返回每批元素的损失并忽略<code>size_average</code>. 默认值:  <code>True</code></li>
<li><strong>reduction</strong> (<em>string__,</em> <em>可选的</em>) – 指定要应用于输出的<code>reduction</code>：'none'| 'mean'| 'sum'.  'none'：没有reduction, 'mean'：输出的总和将除以输出中的元素数量 'sum'：输出将被求和.  注意：<code>size_average</code>和<code>reduce</code>正在被弃用, 同时, 指定这两个args中的任何一个都将覆盖reduce.  默认值：'mean', 默认值:  'mean'</li>
</ul>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-87-1" name="__codelineno-87-1" href="#__codelineno-87-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-87-2" name="__codelineno-87-2" href="#__codelineno-87-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<a id="__codelineno-87-3" name="__codelineno-87-3" href="#__codelineno-87-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<a id="__codelineno-87-4" name="__codelineno-87-4" href="#__codelineno-87-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="ctc_loss">ctc_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-88-1" name="__codelineno-88-1" href="#__codelineno-88-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p>联结主义时间分类损失.</p>
<p>请参见 <a href="#torch.nn.CTCLoss" title="torch.nn.CTCLoss"><code>CTCLoss</code></a>.</p>
<p>注意</p>
<p>在某些情况下, 当使用CUDA后端与CuDNN时, 该操作符可能会选择不确定性算法来提高性能. 如果这不是您希望的, 您可以通过设置<code>torch.backends.cudn .deterministic = True</code>来尝试使操作具有确定性(可能会以性能为代价). 请参阅关于 <a href="notes/randomness.html">Reproducibility</a> 了解背景.</p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<p>参数:</p>
<ul>
<li><strong>log_probs</strong> – <img alt="" src="http://latex.codecogs.com/gif.latex?(T%2C%20N%2C%20C)" /> 其中 <code>C = 字母表中包括空格在内的字符数</code>, <code>T = 输入长度</code>, and <code>N = 批次数量</code>. 输出的对数概率(e.g. 获得于<a href="#torch.nn.functional.log_softmax" title="torch.nn.functional.log_softmax"><code>torch.nn.functional.log_softmax()</code></a>).</li>
<li><strong>targets</strong> – <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20S)" /> or <code>(sum(target_lengths))</code>. 目标(不能为空）. 在第二种形式中，假定目标是串联的。</li>
<li><strong>input_lengths</strong> – <img alt="" src="http://latex.codecogs.com/gif.latex?(N)" />. 输入的长度 (必须 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Cleq%20T" />)</li>
<li><strong>target_lengths</strong> – <img alt="" src="http://latex.codecogs.com/gif.latex?(N)" />. 目标的长度</li>
<li><strong>blank</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>可选的</em>) – 空白的标签. 默认 <img alt="" src="http://latex.codecogs.com/gif.latex?0" />.</li>
<li><strong>reduction</strong> (<em>string__,</em> <em>可选的</em>)  - 指定要应用于输出的<code>reduction</code>：'none'| 'mean'| 'sum'.  'none'：不会应用<code>reduce</code>, 'mean'：输出损失将除以目标长度, 然后得到批次的平均值.  默认值：'mean'</li>
</ul>
<p>例子: 
<div class="highlight"><pre><span></span><code><a id="__codelineno-89-1" name="__codelineno-89-1" href="#__codelineno-89-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<a id="__codelineno-89-2" name="__codelineno-89-2" href="#__codelineno-89-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<a id="__codelineno-89-3" name="__codelineno-89-3" href="#__codelineno-89-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">16</span><span class="p">,),</span> <span class="mi">50</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<a id="__codelineno-89-4" name="__codelineno-89-4" href="#__codelineno-89-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">target_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">,(</span><span class="mi">16</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<a id="__codelineno-89-5" name="__codelineno-89-5" href="#__codelineno-89-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">)</span>
<a id="__codelineno-89-6" name="__codelineno-89-6" href="#__codelineno-89-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="hinge_embedding_loss">hinge_embedding_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-90-1" name="__codelineno-90-1" href="#__codelineno-90-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hinge_embedding_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.HingeEmbeddingLoss" title="torch.nn.HingeEmbeddingLoss"><code>HingeEmbeddingLoss</code></a>.</p>
<h3 id="kl_div">kl_div</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-91-1" name="__codelineno-91-1" href="#__codelineno-91-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p><a href="https://en.wikipedia.org/wiki/Kullback-Leibler_divergence">Kullback-Leibler divergence</a> 损失.</p>
<p>请参见 <a href="#torch.nn.KLDivLoss" title="torch.nn.KLDivLoss"><code>KLDivLoss</code></a></p>
<p>参数:</p>
<ul>
<li><strong>input</strong> – 任意形状的张量</li>
<li><strong>target</strong> – 和输入形状相同的张量</li>
<li><strong>size_average</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 批处理中的每个损失元素的平均损失. 注意, 对于某些损失, 每个样本有多个元素. 如果<code>size_average</code>设置为<code>False</code>, 则对每个小批的损失进行汇总. reduce为False时忽略. 默认值:  <code>True</code></li>
<li><strong>reduce</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 根据size_average, 对每个小批量的观察结果的损失进行平均或求和.  当reduce为False时, 返回每批元素的损失并忽略<code>size_average</code>. 默认值:  <code>True</code></li>
<li><strong>reduction</strong> (<em>string__,</em> <em>可选的</em>) – 指定要应用于输出的缩减：'none'| 'batchmean'| 'sum'| 'mean'.  'none'：不会应用<code>reduction</code> 'batchmean'：输出的总和将除以batchsize 'sum'：输出将被加总 'mean'：输出将除以输出中的元素数 默认值：'mean'</li>
</ul>
<p>:param  注::<code>size average</code>和<code>reduce</code>正在被弃用, 同时, 指定这两个arg中的一个将覆盖reduce. 
:param  注::<code>reduce = mean</code>不返回真实的kl散度值, 请使用:<code>reduce = batchmean</code>, 它符合kl的数学定义. </p>
<blockquote>
<p>在下一个主要版本中, “mean”将被修改为与“batchmean”相同.</p>
</blockquote>
<h3 id="l1_loss">l1_loss</h3>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-92-1" name="__codelineno-92-1" href="#__codelineno-92-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
该函数取元素的绝对值差的平均值。</p>
<p>请参见 <a href="#torch.nn.L1Loss" title="torch.nn.L1Loss"><code>L1Loss</code></a>.</p>
<h3 id="mse_loss">mse_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-93-1" name="__codelineno-93-1" href="#__codelineno-93-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>计算元素的均方误差.</p>
<p>请参见 <a href="#torch.nn.MSELoss" title="torch.nn.MSELoss"><code>MSELoss</code></a>.</p>
<h3 id="margin_ranking_loss">margin_ranking_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-94-1" name="__codelineno-94-1" href="#__codelineno-94-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">margin_ranking_loss</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.MarginRankingLoss" title="torch.nn.MarginRankingLoss"><code>MarginRankingLoss</code></a>.</p>
<h3 id="multilabel_margin_loss">multilabel_margin_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-95-1" name="__codelineno-95-1" href="#__codelineno-95-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multilabel_margin_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.MultiLabelMarginLoss" title="torch.nn.MultiLabelMarginLoss"><code>MultiLabelMarginLoss</code></a>.</p>
<h3 id="multilabel_soft_margin_loss">multilabel_soft_margin_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-96-1" name="__codelineno-96-1" href="#__codelineno-96-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multilabel_soft_margin_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.MultiLabelSoftMarginLoss" title="torch.nn.MultiLabelSoftMarginLoss"><code>MultiLabelSoftMarginLoss</code></a>.</p>
<h3 id="multi_margin_loss">multi_margin_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-97-1" name="__codelineno-97-1" href="#__codelineno-97-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multi_margin_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-98-1" name="__codelineno-98-1" href="#__codelineno-98-1"></a><span class="n">multi_margin_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.MultiMarginLoss" title="torch.nn.MultiMarginLoss"><code>MultiMarginLoss</code></a>.</p>
<h3 id="nll_loss">nll_loss</h3>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-99-1" name="__codelineno-99-1" href="#__codelineno-99-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
负的对数似然函数.</p>
<p>请参见 <a href="#torch.nn.NLLLoss" title="torch.nn.NLLLoss"><code>NLLLoss</code></a>.</p>
<p>参数:</p>
<ul>
<li><strong>input</strong> – <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C)" />  <code>C = 类别的数量</code> 或者 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20H%2C%20W)" /> 在二维损失的情况下, 或者 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20d_1%2C%20d_2%2C%20...%2C%20d_K)" />  <img alt="" src="http://latex.codecogs.com/gif.latex?K%20%3E%201" /> 在K维损失的情况下.</li>
<li><strong>target</strong> – <img alt="" src="http://latex.codecogs.com/gif.latex?(N)" /> 每个值是 <img alt="" src="http://latex.codecogs.com/gif.latex?0%20%5Cleq%20%5Ctext%7Btargets%7D%5Bi%5D%20%5Cleq%20C-1" />, 或者 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20d_1%2C%20d_2%2C%20...%2C%20d_K)" /> <img alt="" src="http://latex.codecogs.com/gif.latex?K%20%5Cgeq%201" /> K维损失.</li>
<li><strong>weight</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) –  给每个类别的手动重定权重. 如果给定, 必须是大小为<code>C</code>的张量</li>
<li><strong>size_average</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 批处理中的每个损失元素的平均损失. 注意, 对于某些损失, 每个样本有多个元素. 如果<code>size_average</code>设置为<code>False</code>, 则对每个小批的损失进行汇总. reduce为False时忽略. 默认值:  <code>True</code></li>
<li><strong>ignore_index</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>可选的</em>) – 指定一个被忽略的目标值, 该值不会影响输入梯度. 当<code>size_average</code>为<code>True</code>时, 损耗在未忽略的目标上平均. 默认值: -100</li>
<li><strong>reduce</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 废弃的 (见 <code>reduction</code>). 默认情况下, 根据size_average, 对每个小批量的观察结果的损失进行平均或求和.  当reduce为False时, 返回每批元素的损失并忽略<code>size_average</code>. 默认值:  <code>True</code></li>
<li><strong>reduction</strong> (<em>string__,</em> <em>可选的</em>) – 指定要应用于输出的<code>reduction</code>：'none'| 'mean'| 'sum'.  'none'：没有reduction, 'mean'：输出的总和将除以输出中的元素数量 'sum'：输出将被求和.  注意：<code>size_average</code>和<code>reduce</code>正在被弃用, 同时, 指定这两个args中的任何一个都将覆盖reduce.  默认值：'mean', 默认值:  'mean'</li>
</ul>
<p>例子: 
<div class="highlight"><pre><span></span><code><a id="__codelineno-100-1" name="__codelineno-100-1" href="#__codelineno-100-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># input is of size N x C = 3 x 5</span>
<a id="__codelineno-100-2" name="__codelineno-100-2" href="#__codelineno-100-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-100-3" name="__codelineno-100-3" href="#__codelineno-100-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># each element in target has to have 0 &lt;= value &lt; C</span>
<a id="__codelineno-100-4" name="__codelineno-100-4" href="#__codelineno-100-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-100-5" name="__codelineno-100-5" href="#__codelineno-100-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
<a id="__codelineno-100-6" name="__codelineno-100-6" href="#__codelineno-100-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></p>
<h3 id="smooth_l1_loss">smooth_l1_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-101-1" name="__codelineno-101-1" href="#__codelineno-101-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">smooth_l1_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p>如果绝对元素误差低于1, 则使用平方项, 否则使用L1项的函数.</p>
<p>请参见 <a href="#torch.nn.SmoothL1Loss" title="torch.nn.SmoothL1Loss"><code>SmoothL1Loss</code></a>.</p>
<h3 id="soft_margin_loss">soft_margin_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-102-1" name="__codelineno-102-1" href="#__codelineno-102-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">soft_margin_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.SoftMarginLoss" title="torch.nn.SoftMarginLoss"><code>SoftMarginLoss</code></a>.</p>
<h3 id="triplet_margin_loss">triplet_margin_loss</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-103-1" name="__codelineno-103-1" href="#__codelineno-103-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">triplet_margin_loss</span><span class="p">(</span><span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.TripletMarginLoss" title="torch.nn.TripletMarginLoss"><code>TripletMarginLoss</code></a></p>
<h2 id="_9">视觉函数</h2>
<h3 id="pixel_shuffle">pixel_shuffle</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-104-1" name="__codelineno-104-1" href="#__codelineno-104-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pixel_shuffle</span><span class="p">()</span>
</code></pre></div>
<p>重新排列张量中的元素, 从形状 <img alt="" src="http://latex.codecogs.com/gif.latex?(*%2C%20C%20%5Ctimes%20r%5E2%2C%20H%2C%20W)" /> 到 <img alt="" src="http://latex.codecogs.com/gif.latex?(C%2C%20H%20%5Ctimes%20r%2C%20W%20%5Ctimes%20r)" />.</p>
<p>请参见 <a href="#torch.nn.PixelShuffle" title="torch.nn.PixelShuffle"><code>PixelShuffle</code></a>.</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入张量
*   <strong>upscale_factor</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 提高空间解析度的参数</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-105-1" name="__codelineno-105-1" href="#__codelineno-105-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-105-2" name="__codelineno-105-2" href="#__codelineno-105-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pixel_shuffle</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-105-3" name="__codelineno-105-3" href="#__codelineno-105-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<a id="__codelineno-105-4" name="__codelineno-105-4" href="#__codelineno-105-4"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
</code></pre></div></p>
<h3 id="pad">pad</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-106-1" name="__codelineno-106-1" href="#__codelineno-106-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>用于填充张量.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-107-1" name="__codelineno-107-1" href="#__codelineno-107-1"></a><span class="n">Pading</span> <span class="n">size</span><span class="p">:</span>
</code></pre></div>
<p>要填充的维度数为 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Cleft%5Clfloor%5Cfrac%7B%5Ctext%7Blen(pad)%7D%7D%7B2%7D%5Cright%5Crfloor" />填充的维度从最后一个维度开始向前移动. 例如,  填充输入tensor的最后一个维度, 所以 <cite>pad</cite> 形如 <cite>(padLeft, padRight)</cite>; 填充最后 2 个维度, 使用 <cite>(padLeft, padRight, padTop, padBottom)</cite>; 填充最后 3 个维度, 使用 <cite>(padLeft, padRight, padTop, padBottom, padFront, padBack)</cite>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-108-1" name="__codelineno-108-1" href="#__codelineno-108-1"></a><span class="n">Padding</span> <span class="n">mode</span><span class="p">:</span>
</code></pre></div>
<p>请参见 <a href="#torch.nn.ConstantPad2d" title="torch.nn.ConstantPad2d"><code>torch.nn.ConstantPad2d</code></a>, <a href="#torch.nn.ReflectionPad2d" title="torch.nn.ReflectionPad2d"><code>torch.nn.ReflectionPad2d</code></a>, and <a href="#torch.nn.ReplicationPad2d" title="torch.nn.ReplicationPad2d"><code>torch.nn.ReplicationPad2d</code></a> 有关每个填充模式如何工作的具体示例. Constant padding 已经实现于任意维度. 复制填充用于填充5D输入张量的最后3个维度, 或4D输入张量的最后2个维度, 或3D输入张量的最后一个维度. 反射填充仅用于填充4D输入张量的最后两个维度, 或者3D输入张量的最后一个维度.</p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – N维张量
*   <strong>pad</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – m个元素的元组, 其中 <img alt="" src="http://latex.codecogs.com/gif.latex?%5Cfrac%7Bm%7D%7B2%7D%20%5Cleq" /> 输入维数，且m是偶数
*   <strong>mode</strong> – 'constant', 'reflect' or 'replicate'. 默认值:  'constant'
*   <strong>value</strong> – 用“常量”填充来填充值. 默认值:  0</p>
<p>例子:
<div class="highlight"><pre><span></span><code><a id="__codelineno-109-1" name="__codelineno-109-1" href="#__codelineno-109-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">t4d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-109-2" name="__codelineno-109-2" href="#__codelineno-109-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">p1d</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># pad last dim by 1 on each side</span>
<a id="__codelineno-109-3" name="__codelineno-109-3" href="#__codelineno-109-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">t4d</span><span class="p">,</span> <span class="n">p1d</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># effectively zero padding</span>
<a id="__codelineno-109-4" name="__codelineno-109-4" href="#__codelineno-109-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<a id="__codelineno-109-5" name="__codelineno-109-5" href="#__codelineno-109-5"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-109-6" name="__codelineno-109-6" href="#__codelineno-109-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">p2d</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># pad last dim by (1, 1) and 2nd to last by (2, 2)</span>
<a id="__codelineno-109-7" name="__codelineno-109-7" href="#__codelineno-109-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">t4d</span><span class="p">,</span> <span class="n">p2d</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-109-8" name="__codelineno-109-8" href="#__codelineno-109-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<a id="__codelineno-109-9" name="__codelineno-109-9" href="#__codelineno-109-9"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-109-10" name="__codelineno-109-10" href="#__codelineno-109-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">t4d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-109-11" name="__codelineno-109-11" href="#__codelineno-109-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">p3d</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># pad by (0, 1), (2, 1), and (3, 3)</span>
<a id="__codelineno-109-12" name="__codelineno-109-12" href="#__codelineno-109-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">t4d</span><span class="p">,</span> <span class="n">p3d</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-109-13" name="__codelineno-109-13" href="#__codelineno-109-13"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<a id="__codelineno-109-14" name="__codelineno-109-14" href="#__codelineno-109-14"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div></p>
<h3 id="interpolate">interpolate</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-110-1" name="__codelineno-110-1" href="#__codelineno-110-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>向下/向上采样输入到给定的<code>size</code>或给定的<code>scale_factor</code></p>
<p>由 <code>mode</code> 指定插值的算法.</p>
<p>目前支持时间, 空间和体积上采样, 即预期输入为三维、四维或五维形状.</p>
<p>输入维度形式: <code>mini-batch x channels x [可选的 depth] x [可选的 height] x width</code>.</p>
<p>可用于上采样的模式是: <code>nearest</code>, <code>linear</code> (仅三维), <code>bilinear</code> (仅四维), <code>trilinear</code> (仅五维), <code>area</code></p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入张量
*   <strong>size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a> <em>or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em>) – 输出尺寸.
*   <strong>scale_factor</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a> <em>or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>]</em>) –  空间大小的乘数. 如果是元组, 则必须匹配输入大小.
*   <strong>mode</strong> (<em>string</em>) – 上采样算法: 'nearest' &#124; 'linear' &#124; 'bilinear' &#124; 'trilinear' &#124; 'area'. 默认值:  'nearest'
*   <strong>align_corners</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 如果为True, 则输入和输出张量的角像素对齐, 从而保留这些像素的值. 仅在 <code>mode</code> 是 <code>linear</code>, <code>bilinear</code>, 或者 <code>trilinear</code> 时生效. 默认值:  False</p>
<p>警告</p>
<p><code>align_corners = True</code>时, 线性插值模式(<code>linear</code>, <code>bilinear</code>, and <code>trilinear</code>)不会按比例对齐输出和输入像素, 因此输出值可能取决于输入大小. 这是0.3.1版之前这些模式的默认行为.此后, 默认行为为<code>align_corners = False</code>. 有关这如何影响输出的具体示例, 请参见上例. </p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<h3 id="upsample">upsample</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-111-1" name="__codelineno-111-1" href="#__codelineno-111-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>将输入采样到给定<code>size</code>或给定的<code>scale_factor</code></p>
<p>警告</p>
<p>此函数已被弃用, 取而代之的是 <a href="#torch.nn.functional.interpolate" title="torch.nn.functional.interpolate"><code>torch.nn.functional.interpolate()</code></a>. 等价于 <code>nn.functional.interpolate(...)</code>.</p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<p>用于上采样的算法由 <code>mode</code> 确定.</p>
<p>目前支持时间, 空间和体积上采样, 即预期输入为三维、四维或五维形状.</p>
<p>输入维度形式: <code>mini-batch x channels x [可选的 depth] x [可选的 height] x width</code>.</p>
<p>可用于上采样的模式是: <code>nearest</code>, <code>linear</code> (仅三维), <code>bilinear</code> (仅四维), <code>trilinear</code> (仅五维), <code>area</code></p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入张量
*   <strong>size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a> <em>or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em>) – 输出尺寸.
*   <strong>scale_factor</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 空间大小的乘数. 必须是整数.
*   <strong>mode</strong> (<em>string</em>) – 上采样算法: 'nearest' &#124; 'linear'&#124; 'bilinear' &#124; 'trilinear'. 默认值:  'nearest'
*   <strong>align_corners</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> <em>可选的</em>) – 如果为True, 则输入和输出张量的角像素对齐, 从而保留这些像素的值. 仅在 <code>mode</code> 是 <code>linear</code>, <code>bilinear</code>, 或者 <code>trilinear</code> 时生效. 默认值:  False</p>
<p>警告</p>
<p><code>align_corners = True</code>时, 线性插值模式(<code>linear</code>, <code>bilinear</code>, and <code>trilinear</code>)不会按比例对齐输出和输入像素, 因此输出值可能取决于输入大小. 这是0.3.1版之前这些模式的默认行为.此后, 默认行为为<code>align_corners = False</code>. 有关这如何影响输出的具体示例, 请参见 <a href="#torch.nn.Upsample" title="torch.nn.Upsample"><code>Upsample</code></a> </p>
<h3 id="upsample_nearest">upsample_nearest</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-112-1" name="__codelineno-112-1" href="#__codelineno-112-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_nearest</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>使用最近邻的像素值对输入进行上采样.</p>
<p>警告</p>
<p>不推荐使用此函数, 而使用 <a href="#torch.nn.functional.interpolate" title="torch.nn.functional.interpolate"><code>torch.nn.functional.interpolate()</code></a>. 等价于h <code>nn.functional.interpolate(..., mode='nearest')</code>.</p>
<p>目前支持空间和体积上采样 (即 inputs 是 4 或者 5 维的).</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入
*   <strong>size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a> <em>or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em>) – 输出空间大小.
*   <strong>scale_factor</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 空间大小乘法器。必须是整数。</p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<h3 id="upsample_bilinear">upsample_bilinear</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-113-1" name="__codelineno-113-1" href="#__codelineno-113-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_bilinear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>使用双线性上采样对输入进行上采样.</p>
<p>警告</p>
<p>不推荐使用此函数, 而使用 <a href="#torch.nn.functional.interpolate" title="torch.nn.functional.interpolate"><code>torch.nn.functional.interpolate()</code></a>. 等价于 <code>nn.functional.interpolate(..., mode='bilinear', align_corners=True)</code>.</p>
<p>期望输入是空间的 (四维). 用 <code>upsample_trilinear</code> 对体积 (五维) 输入.</p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入
*   <strong>size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a> <em>or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or</em> <em>Tuple__[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em>) – 输出空间大小.
*   <strong>scale_factor</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 空间大小乘法器。</p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<h3 id="grid_sample">grid_sample</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-114-1" name="__codelineno-114-1" href="#__codelineno-114-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">)</span>
</code></pre></div>
<p>给定<code>input</code> 和流场 <code>grid</code>, 使用 <code>input</code> 和 <code>grid</code> 中的像素位置计算<code>output</code>.</p>
<p>目前, 仅支持 spatial (四维) 和 volumetric (五维) <code>input</code>.</p>
<p>在 spatial (4四维) 的情况下, 对于 <code>input</code> 形如 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20H_%5Ctext%7Bin%7D%2C%20W_%5Ctext%7Bin%7D)" /> 和 <code>grid</code> 形如 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20H_%5Ctext%7Bout%7D%2C%20W_%5Ctext%7Bout%7D%2C%202)" />, 输出的形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20H_%5Ctext%7Bout%7D%2C%20W_%5Ctext%7Bout%7D)" />.</p>
<p>对于每个输出位置 <code>output[n, :, h, w]</code>, 大小为2的向量 <code>grid[n, h, w]</code> 指定 <code>input</code> 的像素位置 <code>x</code> 和 <code>y</code>, 用于插值输出值 <code>output[n, :, h, w]</code>. 对于 5D 的 inputs, <code>grid[n, d, h, w]</code> 指定 <code>x</code>, <code>y</code>, <code>z</code> 像素位置用于插值 <code>output[n, :, d, h, w]</code>. <code>mode</code> 参数指定 <code>nearest</code> or <code>bilinear</code> 插值方法.</p>
<p><code>grid</code> 大多数值应该处于 <code>[-1, 1]</code>.  这是因为像素位置由<code>input</code> 空间维度标准化.例如, 值 <code>x = -1, y = -1</code> 是 <code>input</code> 的左上角, 值 <code>x = 1, y = 1</code> 是 <code>input</code> 的右下角.</p>
<p>如果 <code>grid</code> 有 <code>[-1, 1]</code> 之外的值, 那些坐标将由 <code>padding_mode</code> 定义. 选项如下</p>
<blockquote>
<ul>
<li><code>padding_mode="zeros"</code>: 用 <code>0</code> 代替边界外的值,</li>
<li><code>padding_mode="border"</code>: 用 border 值代替,</li>
<li><code>padding_mode="reflection"</code>: 对于超出边界的值, 用反射的值. 对于距离边界较远的位置, 它会一直被反射, 直到到达边界, 例如(归一化)像素位置<code>x = -3.5</code>被<code>-1</code>反射, 变成<code>x' = 2.5</code>, 然后被边界1反射, 变成<code>x'' = -0.5</code>.</li>
</ul>
</blockquote>
<p>注意</p>
<p>该功能常用于空间变换网络的构建.</p>
<p>注意</p>
<p>当使用CUDA后端时, 此操作可能会导致不确定的向后行为, 并且不容易关闭. 请参阅关于<a href="notes/randomness.html">Reproducibility</a>的注释. </p>
<p>参数:
*   <strong>input</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 形状为 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20H_%5Ctext%7Bin%7D%2C%20W_%5Ctext%7Bin%7D)" />的输入 (四维情形) 或形状为<img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20C%2C%20D_%5Ctext%7Bin%7D%2C%20H_%5Ctext%7Bin%7D%2C%20W_%5Ctext%7Bin%7D)" /> 的输入(五维情形）
*   <strong>grid</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 形状为<img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20H_%5Ctext%7Bout%7D%2C%20W_%5Ctext%7Bout%7D%2C%202)" /> 的流场(四维情形) 或者 <img alt="" src="http://latex.codecogs.com/gif.latex?(N%2C%20D_%5Ctext%7Bout%7D%2C%20H_%5Ctext%7Bout%7D%2C%20W_%5Ctext%7Bout%7D%2C%203)" /> (五维情形）
*   <strong>mode</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – 插值模式计算输出值'双线性' | '最接近'. 默认值:  'bilinear'
*   <strong>padding_mode</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – 外部网格值' zeros ' | ' border ' | ' reflection '的填充模式. 默认值:  'zeros'</p>
<p>返回值:
*   输出张量</p>
<p>返回类型:
*   输出 (<a href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) </p>
<h3 id="affine_grid">affine_grid</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-115-1" name="__codelineno-115-1" href="#__codelineno-115-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">affine_grid</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
</code></pre></div>
<p>在给定一批仿射矩阵<code>theta</code>的情况下生成二维流场. 通常与<a href="#torch.nn.functional.grid_sample" title="torch.nn.functional.grid_sample"><code>grid_sample()</code></a>一起使用以实现<code>空间变换器网络</code>. </p>
<p>参数:
*   <strong>theta</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入的仿射矩阵 (<img alt="" src="http://latex.codecogs.com/gif.latex?N%20%5Ctimes%202%20%5Ctimes%203" />)
*   <strong>size</strong> (<em>torch.Size</em>) – 目标图像输出的大小 (<img alt="" src="http://latex.codecogs.com/gif.latex?N%20%5Ctimes%20C%20%5Ctimes%20H%20%5Ctimes%20W" />) 例子:  torch.Size((32, 3, 24, 24))</p>
<p>返回值:
*   输出tensor, 形状为 (<img alt="" src="http://latex.codecogs.com/gif.latex?N%20%5Ctimes%20H%20%5Ctimes%20W%20%5Ctimes%202" />) </p>
<p>返回类型: 
*   output (<a href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>) </p>
<h2 id="multi-gpu-distributed">数据并行函数 (multi-GPU, distributed)</h2>
<h3 id="data_parallel">data_parallel</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-116-1" name="__codelineno-116-1" href="#__codelineno-116-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">data_parallel</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">module_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>在设备id中给定的gpu上并行计算模块(输入).</p>
<p>这是DataParallel模块的函数版本.</p>
<p>参数:
*   <strong>module</strong> (<a href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – 要并行评估的模块
*   <strong>inputs</strong> (<em>tensor</em>) –  模块的输入
*   <strong>device_ids</strong> (<em>list of python:int</em> <em>or</em> <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><em>torch.device</em></a>) – 用于复制模块的GPU id
*   <strong>output_device</strong> (<em>list of python:int</em> <em>or</em> <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><em>torch.device</em></a>) –  输出的GPU位置使用 -1表示CPU. (默认值:  device_ids[0])</p>
<p>返回值:
*   一个张量, 包含位于输出设备上的模块(输入)的结果</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../nn/" class="md-footer__link md-footer__link--prev" aria-label="Previous: torch.nn">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                torch.nn
              </div>
            </div>
          </a>
        
        
          
          <a href="../nn_init/" class="md-footer__link md-footer__link--next" aria-label="Next: torch.nn.init">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                torch.nn.init
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>