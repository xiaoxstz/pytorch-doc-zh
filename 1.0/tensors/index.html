
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/1.0/tensors/">
      
      
        <link rel="prev" href="../torch_math_operations_blas_lapack_ops/">
      
      
        <link rel="next" href="../tensor_attributes/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.0">
    
    
      
        <title>torch.Tensor - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.45e1311d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torchtensor" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              torch.Tensor
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" >
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Modeling with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.compile Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial%23using-sdpa-with-torch-compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using SDPA with torch.compile
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial%23conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Mobile
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Mobile
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deeplabv3_on_ios/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on iOS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deeplabv3_on_android/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on Android
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.7 中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    学习 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            学习 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 深度学习：60 分钟的突击
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 深度学习：60 分钟的突击
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/02/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/03/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/04/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.autograd的简要介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/05/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/06/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_2" >
        
          
          <label class="md-nav__link" for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    通过示例学习 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_2">
            <span class="md-nav__icon md-icon"></span>
            通过示例学习 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/07/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/08/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    热身：NumPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/09/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：张量和 Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：定义新的 Autograd 函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/14/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：自定义nn模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/15/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：控制流 - 权重共享
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/16/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn到底是什么？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TensorBoard 可视化模型，数据和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图片/视频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            图片/视频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/19/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision对象检测微调教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉的迁移学习教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/21/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            音频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/24/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    音频 I/O 和torchaudio的预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/25/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用torchaudio的语音命令识别
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/27/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用nn.Transformer和torchtext的序列到序列建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/28/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用字符级 RNN 分类名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用字符级 RNN 生成名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用序列到序列网络和注意力的翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用torchtext的文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext语言翻译
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/34/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习（DQN）教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/35/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练玩马里奥的 RL 智能体
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
        
          
          <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    在生产中部署 PyTorch 模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            在生产中部署 PyTorch 模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/37/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过使用 Flask 的 REST API 在 Python 中部署 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/38/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/39/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中加载 TorchScript 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/40/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将模型从 PyTorch 导出到 ONNX 并使用 ONNX 运行时运行它（可选）
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
        
          
          <label class="md-nav__link" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    前端 API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_7">
            <span class="md-nav__icon md-icon"></span>
            前端 API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/42/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中的命名张量简介（原型）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/43/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中通道在最后的内存格式（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/44/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C++ 前端
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/45/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自定义 C++ 和 CUDA 扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/46/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C++ 运算符扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/47/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C++ 类扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/48/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 中的动态并行性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/49/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++ 前端中的 Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中注册调度运算符
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" >
        
          
          <label class="md-nav__link" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型优化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_8">
            <span class="md-nav__icon md-icon"></span>
            模型优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/52/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分析您的 PyTorch 模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/53/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Ray Tune 的超参数调整
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/54/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型剪裁教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/55/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM 单词语言模型上的动态量化（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/56/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERT 上的动态量化（Beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/57/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中使用 Eager 模式的静态量化（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/58/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉的量化迁移学习教程（beta）
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
        
          
          <label class="md-nav__link" for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    并行和分布式训练
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_9">
            <span class="md-nav__icon md-icon"></span>
            并行和分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/60/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 分布式概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/61/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    单机模型并行最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/62/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式数据并行入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/63/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 PyTorch 编写分布式应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/64/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/65/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用分布式 RPC 框架实现参数服务器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/66/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 RPC 的分布式管道并行化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/67/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用异步执行实现批量 RPC 处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/68/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将分布式DataParallel与分布式 RPC 框架相结合
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.4 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1_1" id="__nav_5_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    使用 PyTorch 进行深度学习：60 分钟的闪电战
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_1">
            <span class="md-nav__icon md-icon"></span>
            使用 PyTorch 进行深度学习：60 分钟的闪电战
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/tensor_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    什么是PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/autograd_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd：自动求导
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/neural_networks_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/cifar10_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/blitz/data_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    可选：数据并行
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    编写自定义数据集，数据加载器和转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TensorBoard 可视化模型，数据和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图片
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            图片
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision 对象检测微调教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    转移学习的计算机视觉教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空间变压器网络教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行神经传递
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            音频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/15/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 使用char-RNN对姓氏进行分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/18/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 生成名称与字符级RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/19/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TorchText 进行文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/21/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TorchText 进行语言翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 nn.Transformer 和 TorchText 进行序列到序列建模
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    命名为 Tensor(实验性）
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            命名为 Tensor(实验性）
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/24/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性)PyTorch 中的命名张量简介
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" >
        
          
          <label class="md-nav__link" for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/26/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习(DQN)教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          <label class="md-nav__link" for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    在生产中部署 PyTorch 模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            在生产中部署 PyTorch 模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/28/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过带有 Flask 的 REST API 在 Python 中部署 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C --中加载 TorchScript 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_8" >
        
          
          <label class="md-nav__link" for="__nav_5_8" id="__nav_5_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    并行和分布式训练
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_8">
            <span class="md-nav__icon md-icon"></span>
            并行和分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/33/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    单机模型并行最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/34/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式数据并行入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/35/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 PyTorch 编写分布式应用程序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/36/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/37/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" >
        
          
          <label class="md-nav__link" for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            扩展 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/39/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C --运算符扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/40/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C --类扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/41/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 numpy 和 scipy 创建扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/42/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自定义 C --和 CUDA 扩展
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_10" >
        
          
          <label class="md-nav__link" for="__nav_5_10" id="__nav_5_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型优化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_10">
            <span class="md-nav__icon md-icon"></span>
            模型优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/44/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM Word 语言模型上的(实验）动态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/45/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性）在 PyTorch 中使用 Eager 模式进行静态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/46/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性）计算机视觉教程的量化转移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/47/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验）BERT 上的动态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/48/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    修剪教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_11" >
        
          
          <label class="md-nav__link" for="__nav_5_11" id="__nav_5_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 用其他语言
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_11">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 用其他语言
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C --前端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_12" >
        
          
          <label class="md-nav__link" for="__nav_5_12" id="__nav_5_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 基础知识
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_12">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 基础知识
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/52/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过示例学习 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/53/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn 到底是什么？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_13" >
        
          
          <label class="md-nav__link" for="__nav_5_13" id="__nav_5_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_13">
            <span class="md-nav__icon md-icon"></span>
            笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/56/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动求导机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/57/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    广播语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/58/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 线程和 TorchScript 推断
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/59/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA 语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/60/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 Autograd 设计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/61/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/62/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    经常问的问题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/63/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模部署的功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/64/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    并行处理最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/65/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    重现性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/66/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    远程参考协议
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/67/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列化语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/68/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows 常见问题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/69/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XLA 设备上的 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_14" >
        
          
          <label class="md-nav__link" for="__nav_5_14" id="__nav_5_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    语言绑定
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_14">
            <span class="md-nav__icon md-icon"></span>
            语言绑定
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/71/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch C -- API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/72/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Java API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_15" >
        
          
          <label class="md-nav__link" for="__nav_5_15" id="__nav_5_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_15">
            <span class="md-nav__icon md-icon"></span>
            Python API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/74/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/75/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/76/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/77/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/78/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    张量属性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/79/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动差分包-Torch.Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/81/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式通讯包-Torch.Distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/82/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    概率分布-torch分布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/84/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch脚本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/86/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/87/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/88/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch随机
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/91/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch稀疏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/92/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch存储
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/93/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/94/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/96/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/98/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/99/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    类型信息
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/101/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/102/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名为 Tensors 操作员范围
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/103/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    糟糕！
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_16" >
        
          
          <label class="md-nav__link" for="__nav_5_16" id="__nav_5_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchvision参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_16">
            <span class="md-nav__icon md-icon"></span>
            torchvision参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/105/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_17" >
        
          
          <label class="md-nav__link" for="__nav_5_17" id="__nav_5_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_17">
            <span class="md-nav__icon md-icon"></span>
            音频参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/107/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_18" >
        
          
          <label class="md-nav__link" for="__nav_5_18" id="__nav_5_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchtext参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_18">
            <span class="md-nav__icon md-icon"></span>
            torchtext参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/109/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_19" >
        
          
          <label class="md-nav__link" for="__nav_5_19" id="__nav_5_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    社区
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_19">
            <span class="md-nav__icon md-icon"></span>
            社区
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/111/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 贡献指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/112/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 治理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.4/113/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 治理| 感兴趣的人
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.0 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1" id="__nav_6_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1">
            <span class="md-nav__icon md-icon"></span>
            入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1_1" id="__nav_6_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 深度学习: 60 分钟极速入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 深度学习: 60 分钟极速入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_tensor_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    什么是 PyTorch？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_autograd_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd：自动求导
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_neural_networks_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_cifar10_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz_data_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    可选：数据并行处理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_loading_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据加载和处理教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用例子学习 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy_seq2seq_hybrid_frontend_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合前端的 seq2seq 模型部署
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../saving_loading_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and Loading Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2_2" id="__nav_6_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图像
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_2">
            <span class="md-nav__icon md-icon"></span>
            图像
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning_torchvision_models_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchvision 模型微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空间变换器网络教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../neural_style_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行图像风格转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗性示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../super_resolution_with_caffe2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3" id="__nav_6_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatbot_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天机器人教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用字符级别特征的 RNN 网络生成姓氏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用字符级别特征的 RNN 网络进行姓氏分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3_4" id="__nav_6_2_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deep Learning for NLP with Pytorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            Deep Learning for NLP with Pytorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning_nlp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在深度学习和 NLP 中使用 Pytorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_pytorch_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_deep_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_word_embeddings_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Word Embeddings: Encoding Lexical Semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_sequence_models_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列模型和 LSTM 网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nlp_advanced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于注意力机制的 seq2seq 神经网络翻译
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_4" id="__nav_6_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    生成
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_4">
            <span class="md-nav__icon md-icon"></span>
            生成
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_5" >
        
          
          <label class="md-nav__link" for="__nav_6_2_5" id="__nav_6_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_5">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_6" >
        
          
          <label class="md-nav__link" for="__nav_6_2_6" id="__nav_6_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_6">
            <span class="md-nav__icon md-icon"></span>
            扩展 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy_extensions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 numpy 和 scipy 创建扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_7" >
        
          
          <label class="md-nav__link" for="__nav_6_2_7" id="__nav_6_2_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    生产性使用
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_7">
            <span class="md-nav__icon md-icon"></span>
            生产性使用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aws_distributed_training_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Amazon AWS 进行分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ONNXLive/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ONNX 现场演示教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中加载 PYTORCH 模型
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_8" >
        
          
          <label class="md-nav__link" for="__nav_6_2_8" id="__nav_6_2_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其它语言中的 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_8">
            <span class="md-nav__icon md-icon"></span>
            其它语言中的 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C++ 前端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" checked>
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_1" >
        
          
          <label class="md-nav__link" for="__nav_6_3_1" id="__nav_6_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    注解
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_1">
            <span class="md-nav__icon md-icon"></span>
            注解
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动求导机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_broadcasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    广播语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA 语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_extending/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multiprocessing best practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_randomness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reproducibility
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_serialization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notes_windows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_6_3_2" id="__nav_6_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    包参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_3_2">
            <span class="md-nav__icon md-icon"></span>
            包参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2_1" id="__nav_6_3_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_3_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2_1">
            <span class="md-nav__icon md-icon"></span>
            torch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_tensors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_random_sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Random sampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_serialization_parallelism_utilities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization, Parallelism, Utilities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2_1_5" id="__nav_6_3_2_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Math operations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_6_3_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            Math operations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_pointwise_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pointwise Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_reduction_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reduction Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_comparison_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Comparison Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_spectral_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spectral Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_other_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Other Operations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torch_math_operations_blas_lapack_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BLAS and LAPACK Operations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    torch.Tensor
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensor_attributes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor Attributes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../type_info/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据类型信息
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sparse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_functional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_init/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic differentiation package - torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed communication package - torch.distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability distributions - torch.distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torch Script
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多进程包 - torch.multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bottleneck/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../checkpoint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docs_cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dlpack/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_zoo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distributed_deprecated/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed communication package (deprecated) - torch.distributed.deprecated
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3_3" id="__nav_6_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchvision 参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_3">
            <span class="md-nav__icon md-icon"></span>
            torchvision 参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docs_torchvision_ref/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/1.0/tensors.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/1.0/tensors.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<h1 id="torchtensor">torch.Tensor</h1>
<blockquote>
<p>译者：<a href="https://github.com/hijkzzz">hijkzzz</a></p>
</blockquote>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是一种包含单一数据类型元素的多维矩阵.</p>
<p>Torch定义了八种CPU张量类型和八种GPU张量类型：</p>
<table>
<thead>
<tr>
<th>Data type</th>
<th>dtype</th>
<th>CPU tensor</th>
<th>GPU tensor</th>
</tr>
</thead>
<tbody>
<tr>
<td>32-bit floating point</td>
<td><code>torch.float32</code> or <code>torch.float</code></td>
<td><code>torch.FloatTensor</code></td>
<td><code>torch.cuda.FloatTensor</code></td>
</tr>
<tr>
<td>64-bit floating point</td>
<td><code>torch.float64</code> or <code>torch.double</code></td>
<td><code>torch.DoubleTensor</code></td>
<td><code>torch.cuda.DoubleTensor</code></td>
</tr>
<tr>
<td>16-bit floating point</td>
<td><code>torch.float16</code> or <code>torch.half</code></td>
<td><code>torch.HalfTensor</code></td>
<td><code>torch.cuda.HalfTensor</code></td>
</tr>
<tr>
<td>8-bit integer (unsigned)</td>
<td><code>torch.uint8</code></td>
<td><a href="#torch.ByteTensor" title="torch.ByteTensor"><code>torch.ByteTensor</code></a></td>
<td><code>torch.cuda.ByteTensor</code></td>
</tr>
<tr>
<td>8-bit integer (signed)</td>
<td><code>torch.int8</code></td>
<td><code>torch.CharTensor</code></td>
<td><code>torch.cuda.CharTensor</code></td>
</tr>
<tr>
<td>16-bit integer (signed)</td>
<td><code>torch.int16</code> or <code>torch.short</code></td>
<td><code>torch.ShortTensor</code></td>
<td><code>torch.cuda.ShortTensor</code></td>
</tr>
<tr>
<td>32-bit integer (signed)</td>
<td><code>torch.int32</code> or <code>torch.int</code></td>
<td><code>torch.IntTensor</code></td>
<td><code>torch.cuda.IntTensor</code></td>
</tr>
<tr>
<td>64-bit integer (signed)</td>
<td><code>torch.int64</code> or <code>torch.long</code></td>
<td><code>torch.LongTensor</code></td>
<td><code>torch.cuda.LongTensor</code></td>
</tr>
</tbody>
</table>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是默认的tensor类型 (<code>torch.FloatTensor</code>) 的简称.</p>
<p>Tensor 可以用<a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a>转换Python的 <a href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><code>list</code></a> 或序列​​生成：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0000</span><span class="p">],</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a> <span class="p">[</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0000</span><span class="p">]])</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]))</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a> <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">]])</span>
</code></pre></div>
<p>警告</p>
<p><a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 总是拷贝 <code>data</code>. 如果你有一个 Tensor <code>data</code> 并且仅仅想改变它的 <code>requires_grad</code> 属性, 可用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> or <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>detach()</code></a> 来避免拷贝. 如果你有一个 numpy 数组并且想避免拷贝, 请使用 <a href="torch.html#torch.as_tensor" title="torch.as_tensor"><code>torch.as_tensor()</code></a>.</p>
<p>指定数据类型的Tensor可以通过传递参数 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和/或者  <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 到构造函数生成：</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a> <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">cuda0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda0</span><span class="p">)</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">],</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a> <span class="p">[</span> <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.0000</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
</code></pre></div>
Tensor的内容可以通过Python索引或者切片访问以及修改：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">tensor</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a> <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">]])</span>
</code></pre></div>
<p>使用 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>torch.Tensor.item()</code></a> 从只有一个值的Tensor中获取Python Number：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="mi">1</span>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.5</span><span class="p">)</span>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="n">tensor</span><span class="p">(</span><span class="mf">2.5000</span><span class="p">)</span>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a><span class="mf">2.5</span>
</code></pre></div>
<p>Tensor可以通过参数 <code>requires_grad=True</code> 创建, 这样 <a href="autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> 会记录相关的运算实现自动求导.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">2.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0000</span><span class="p">],</span>
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a> <span class="p">[</span> <span class="mf">2.0000</span><span class="p">,</span>  <span class="mf">2.0000</span><span class="p">]])</span>
</code></pre></div>
<p>每一个tensor都有一个相应的 <code>torch.Storage</code> 保存其数据. tensor 类提供了一个多维的、<a href="https://en.wikipedia.org/wiki/Stride_of_an_array">strided</a>视图, 并定义了数值操作.</p>
<p>注意</p>
<p>更多关于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 和 <a href="tensor_attributes.html#torch.torch.layout" title="torch.torch.layout"><code>torch.layout</code></a>  等 <a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>的属性, 见 <a href="tensor_attributes.html#tensor-attributes-doc">Tensor Attributes</a>.</p>
<p>注意</p>
<p>注意：修改tensor的方法可以用一个下划线后缀来标示.比如, <code>torch.FloatTensor.abs_()</code> 会在原地计算绝对值并返回修改的张量, 而 <code>torch.FloatTensor.abs()</code> 将会在新张量中计算结果.</p>
<p>注意</p>
<p>为了改变已有的 tensor 的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 和/或者 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 考虑使用 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 方法.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<p>这里有少数几种生成Tensor的方法, 取决于你的实际情况.</p>
<ul>
<li>从已经存在的数据生成, 用 <a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a>.</li>
<li>生成特殊尺寸的Tensor, 用 <code>torch.*</code> creation ops (见 <a href="torch.html#tensor-creation-ops">Creation Ops</a>).</li>
<li>生成与其它Tensor尺寸相同的Tensor (并且数据类型相同), 用 <code>torch.*_like</code> creation ops (见 <a href="torch.html#tensor-creation-ops">Creation Ops</a>).</li>
<li>生成与其它Tesor数据类型相同但是尺寸不同的Tensor, 用 <code>tensor.new_*</code> creation ops.</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">new_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个新的Tensor用 <code>data</code> 作为tensor data.默认情况下, 返回的Tensor有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> .</p>
<p>警告</p>
<p><a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 总是拷贝 <code>data</code>. 如果 你有一个 Tensor <code>data</code> 并且想避免拷贝, 使用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>torch.Tensor.requires_grad_()</code></a> 或者 <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>torch.Tensor.detach()</code></a>. 如果你有一个 numpy 数组并且想避免拷贝, 使用 <a href="torch.html#torch.from_numpy" title="torch.from_numpy"><code>torch.from_numpy()</code></a>.</p>
<p>警告</p>
<p>当 data 是一个 tensor <code>x</code>, <a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 读取 x 的 'data' 并且创建一个叶子变量. 因此 <code>tensor.new_tensor(x)</code> 等价于 <code>x.clone().detach()</code> 并且 <code>tensor.new_tensor(x, requires_grad=True)</code> 等价于 <code>x.clone().detach().requires_grad_(True)</code>. 推荐使用 <code>clone()</code> 和 <code>detach()</code>.</p>
<p>参数: </p>
<ul>
<li><strong>data</strong> (<em>array_like</em>) – 返回的 Tensor 拷贝 <code>data</code>.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">new_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a> <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="n">new_full</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>fill_value</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>参数: </p>
<ul>
<li><strong>fill_value</strong> (<em>scalar</em>) – 用于填充的数值.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">new_full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="mf">3.141592</span><span class="p">)</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">],</span>
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a> <span class="p">[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">],</span>
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a> <span class="p">[</span> <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">,</span>  <span class="mf">3.1416</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="n">new_empty</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>未初始化的值</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>Parameters: </p>
<ul>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(())</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">new_empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">5.8182e-18</span><span class="p">,</span>  <span class="mf">4.5765e-41</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0545e+30</span><span class="p">],</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a> <span class="p">[</span> <span class="mf">3.0949e-41</span><span class="p">,</span>  <span class="mf">4.4842e-44</span><span class="p">,</span>  <span class="mf">0.0000e+00</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">new_ones</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>1</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>Parameters: </p>
<ul>
<li><strong>size</strong> (<em>int...</em>) – list, tuple, 或者 <code>torch.Size</code> 定义了输出Tensor的形状.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">new_ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a> <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="n">new_zeros</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个Tesnor的尺寸等于 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 用 <code>0</code>填充. 默认情况下, 返回的 Tensor 具有与此Tensor相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>参数: </p>
<ul>
<li><strong>size</strong> (<em>int...</em>) – list, tuple, 或者 <code>torch.Size</code> 定义了输出Tensor的形状.</li>
<li><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, 可选) – 期望返回的Tensor的数据类型. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</li>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 可选) – 期望返回的Tesor所在设备. 默认值: 如果是 None, 等于 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</li>
<li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>,</em> 可选) – 是否为自动求导记录相关的运算. 默认值: <code>False</code>.</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a> <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="n">is_cuda</span>
</code></pre></div>
<p><code>True</code> 如果 Tensor 在 GPU 上, 否则 <code>False</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="n">device</span>
</code></pre></div>
<p><a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> Tensor 所在的设备.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="nb">abs</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="n">abs_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.abs" title="torch.Tensor.abs"><code>abs()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="n">acos</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.acos" title="torch.acos"><code>torch.acos()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">acos_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.acos" title="torch.Tensor.acos"><code>acos()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">add</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>add(value=1, other) -&gt; Tensor</p>
<p>见 <a href="torch.html#torch.add" title="torch.add"><code>torch.add()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="n">add_</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>add_(value=1, other) -&gt; Tensor</p>
<p>原地版本的 <a href="#torch.Tensor.add" title="torch.Tensor.add"><code>add()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="n">addbmm</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.addbmm" title="torch.addbmm"><code>torch.addbmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="n">addbmm_</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>addbmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="n">addcdiv</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.addcdiv" title="torch.addcdiv"><code>torch.addcdiv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="n">addcdiv_</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>addcdiv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="n">addcmul</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.addcmul" title="torch.addcmul"><code>torch.addcmul()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="n">addcmul_</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>addcmul()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="n">addmm</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.addmm" title="torch.addmm"><code>torch.addmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="n">addmm_</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>addmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="n">addmv</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.addmv" title="torch.addmv"><code>torch.addmv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="n">addmv_</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>addmv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="n">addr</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.addr" title="torch.addr"><code>torch.addr()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="n">addr_</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.addr" title="torch.Tensor.addr"><code>addr()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="n">allclose</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">equal_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.allclose" title="torch.allclose"><code>torch.allclose()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="n">apply_</span><span class="p">(</span><span class="nb">callable</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>应用函数 <code>callable</code> 到Tensor中的每一个元素, 用 <code>callable</code>的返回值替换每一个元素.</p>
<p>注意</p>
<p>这个函数仅仅能在CPU上工作, 并且不要用于需要高性能的代码区域.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.argmax" title="torch.argmax"><code>torch.argmax()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="n">argmin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.argmin" title="torch.argmin"><code>torch.argmin()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="n">asin</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.asin" title="torch.asin"><code>torch.asin()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="n">asin_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.asin" title="torch.Tensor.asin"><code>asin()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="n">atan</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.atan" title="torch.atan"><code>torch.atan()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="n">atan2</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.atan2" title="torch.atan2"><code>torch.atan2()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="n">atan2_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>atan2()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="n">atan_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.atan" title="torch.Tensor.atan"><code>atan()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="n">baddbmm</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.baddbmm" title="torch.baddbmm"><code>torch.baddbmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a><span class="n">baddbmm_</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>baddbmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="n">bernoulli</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个Tensor, 每一个 <img alt="" src="../img/dc666b1cb085659ba80fe7af990d3fa4.jpg" /> 都是独立采样于 <img alt="" src="../img/0fafd43e45fa221cf2d8f0b6f69e5685.jpg" />. <code>self</code> 必须是浮点型 <code>dtype</code>, 并且返回值有相同的 <code>dtype</code>.</p>
<p>见 <a href="torch.html#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a><span class="n">bernoulli_</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a><span class="n">bernoulli_</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>从 <img alt="" src="../img/25fd7267b85a9ee01d9c4b60beb89dc0.jpg" /> 独立采样填充 <code>self</code> 的每一个位置.<code>self</code> 可以是整型 <code>dtype</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="n">bernoulli_</span><span class="p">(</span><span class="n">p_tensor</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>p_tensor</code> 必须是一个包含概率的 Tensor 用于取得二元随机数.</p>
<p><code>self</code> tensor 的 <img alt="" src="../img/511f5a204e4e69e0f1c374e9a5738214.jpg" /> 元素将会被设置为采样于 <img alt="" src="../img/403a44ffd5b7d1285b96a8270b00e335.jpg" /> 的值.</p>
<p><code>self</code> 可以有整型 <code>dtype</code>, 但是 :attr<code>p_tensor</code> 必须有浮点型 <code>dtype</code>.</p>
<p>可参考 <a href="#torch.Tensor.bernoulli" title="torch.Tensor.bernoulli"><code>bernoulli()</code></a> and <a href="torch.html#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a><span class="n">bmm</span><span class="p">(</span><span class="n">batch2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.bmm" title="torch.bmm"><code>torch.bmm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="n">byte</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.byte()</code> is equivalent to <code>self.to(torch.uint8)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a><span class="n">btrifact</span><span class="p">(</span><span class="n">info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.btrifact" title="torch.btrifact"><code>torch.btrifact()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="n">btrifact_with_info</span><span class="p">(</span><span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.btrifact_with_info" title="torch.btrifact_with_info"><code>torch.btrifact_with_info()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a><span class="n">btrisolve</span><span class="p">(</span><span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.btrisolve" title="torch.btrisolve"><code>torch.btrisolve()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a><span class="n">cauchy_</span><span class="p">(</span><span class="n">median</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用取自 Cauchy 分布得值填充Tensor:</p>
<p><img alt="" src="../img/3d4f188d97734e88873d6fe218ea4aa3.jpg" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="n">ceil</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.ceil" title="torch.ceil"><code>torch.ceil()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a><span class="n">ceil_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>ceil()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="n">char</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.char()</code> 等价于 <code>self.to(torch.int8)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="n">cholesky</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a><span class="n">chunk</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">List</span> <span class="n">of</span> <span class="n">Tensors</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.chunk" title="torch.chunk"><code>torch.chunk()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a><span class="n">clamp_</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a><span class="n">clone</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一份拷贝的 <code>self</code> tensor. 这份拷贝有 <code>self</code> 相同的数据和类型.</p>
<p>注意</p>
<p>与<code>copy_()</code>不同, 此函数会被记录在计算图中. 传给克隆tensor的梯度将传播到原始tensor.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a><span class="n">contiguous</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个连续的得Tensor, 其data与 <code>self</code> 相同. 如果 <code>self</code> tensor 是连续的, 此函数返回 <code>self</code> tensor 自身.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a><span class="n">copy_</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>从 <code>src</code> 拷贝元素到 <code>self</code> tensor 然后返回 <code>self</code>.</p>
<p><code>src</code> tensor 必须与 <code>self</code> tensor 是 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>. 但数据类型可以不同, 所在的设备也可以不同.</p>
<p>参数: </p>
<ul>
<li><strong>src</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 源 tensor</li>
<li><strong>non_blocking</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 如果是 <code>True</code> 并且这次复制在 CPU 和 GPU 之间进行, 这次复制将会是异步的. 其他情况则没有影响.</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-68-1" name="__codelineno-68-1" href="#__codelineno-68-1"></a><span class="n">cos</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cos" title="torch.cos"><code>torch.cos()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-69-1" name="__codelineno-69-1" href="#__codelineno-69-1"></a><span class="n">cos_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.cos" title="torch.Tensor.cos"><code>cos()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-70-1" name="__codelineno-70-1" href="#__codelineno-70-1"></a><span class="n">cosh</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cosh" title="torch.cosh"><code>torch.cosh()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-71-1" name="__codelineno-71-1" href="#__codelineno-71-1"></a><span class="n">cosh_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>cosh()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-72-1" name="__codelineno-72-1" href="#__codelineno-72-1"></a><span class="n">cpu</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个拷贝对象于 CPU 内存中.</p>
<p>如果这个对象已经在 CPU 内存中, 并且在者正确的设备上, 那么将会返回其本身.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-73-1" name="__codelineno-73-1" href="#__codelineno-73-1"></a><span class="n">cross</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cross" title="torch.cross"><code>torch.cross()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-74-1" name="__codelineno-74-1" href="#__codelineno-74-1"></a><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个拷贝对象于 CUDA 内存中.</p>
<p>如果这个对象已经在 CUDA 内存中, 并且在者正确的设备上, 那么将会返回其本身.</p>
<p>参数: </p>
<ul>
<li><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>) –目标GPU设备. 默认值是当前GPU.</li>
<li><strong>non_blocking</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 如果是 <code>True</code> 并且源在pinned memory中, 这次拷贝将是异步的.否则此参数没有影响. 默认值: <code>False</code>.</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-75-1" name="__codelineno-75-1" href="#__codelineno-75-1"></a><span class="n">cumprod</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cumprod" title="torch.cumprod"><code>torch.cumprod()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-76-1" name="__codelineno-76-1" href="#__codelineno-76-1"></a><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cumsum" title="torch.cumsum"><code>torch.cumsum()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-77-1" name="__codelineno-77-1" href="#__codelineno-77-1"></a><span class="n">data_ptr</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>返回 <code>self</code> tensor 的第一个元素的指针.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-78-1" name="__codelineno-78-1" href="#__codelineno-78-1"></a><span class="n">det</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.det" title="torch.det"><code>torch.det()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-79-1" name="__codelineno-79-1" href="#__codelineno-79-1"></a><span class="n">diag</span><span class="p">(</span><span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.diag" title="torch.diag"><code>torch.diag()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-80-1" name="__codelineno-80-1" href="#__codelineno-80-1"></a><span class="n">diag_embed</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.diag_embed" title="torch.diag_embed"><code>torch.diag_embed()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-81-1" name="__codelineno-81-1" href="#__codelineno-81-1"></a><span class="n">dim</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>返回 <code>self</code> tensor 的维度.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-82-1" name="__codelineno-82-1" href="#__codelineno-82-1"></a><span class="n">dist</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.dist" title="torch.dist"><code>torch.dist()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-83-1" name="__codelineno-83-1" href="#__codelineno-83-1"></a><span class="n">div</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.div" title="torch.div"><code>torch.div()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-84-1" name="__codelineno-84-1" href="#__codelineno-84-1"></a><span class="n">div_</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.div" title="torch.Tensor.div"><code>div()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-85-1" name="__codelineno-85-1" href="#__codelineno-85-1"></a><span class="n">dot</span><span class="p">(</span><span class="n">tensor2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.dot" title="torch.dot"><code>torch.dot()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-86-1" name="__codelineno-86-1" href="#__codelineno-86-1"></a><span class="n">double</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.double()</code> 等价于 <code>self.to(torch.float64)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-87-1" name="__codelineno-87-1" href="#__codelineno-87-1"></a><span class="n">eig</span><span class="p">(</span><span class="n">eigenvectors</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.eig" title="torch.eig"><code>torch.eig()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-88-1" name="__codelineno-88-1" href="#__codelineno-88-1"></a><span class="n">element_size</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>返回每个元素占用的字节数</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-89-1" name="__codelineno-89-1" href="#__codelineno-89-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span>
<a id="__codelineno-89-2" name="__codelineno-89-2" href="#__codelineno-89-2"></a><span class="mi">4</span>
<a id="__codelineno-89-3" name="__codelineno-89-3" href="#__codelineno-89-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span>
<a id="__codelineno-89-4" name="__codelineno-89-4" href="#__codelineno-89-4"></a><span class="mi">1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-90-1" name="__codelineno-90-1" href="#__codelineno-90-1"></a><span class="n">eq</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.eq" title="torch.eq"><code>torch.eq()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-91-1" name="__codelineno-91-1" href="#__codelineno-91-1"></a><span class="n">eq_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.eq" title="torch.Tensor.eq"><code>eq()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-92-1" name="__codelineno-92-1" href="#__codelineno-92-1"></a><span class="n">equal</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="nb">bool</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.equal" title="torch.equal"><code>torch.equal()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-93-1" name="__codelineno-93-1" href="#__codelineno-93-1"></a><span class="n">erf</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.erf" title="torch.erf"><code>torch.erf()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-94-1" name="__codelineno-94-1" href="#__codelineno-94-1"></a><span class="n">erf_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.erf" title="torch.Tensor.erf"><code>erf()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-95-1" name="__codelineno-95-1" href="#__codelineno-95-1"></a><span class="n">erfc</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.erfc" title="torch.erfc"><code>torch.erfc()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-96-1" name="__codelineno-96-1" href="#__codelineno-96-1"></a><span class="n">erfc_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>erfc()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-97-1" name="__codelineno-97-1" href="#__codelineno-97-1"></a><span class="n">erfinv</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.erfinv" title="torch.erfinv"><code>torch.erfinv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-98-1" name="__codelineno-98-1" href="#__codelineno-98-1"></a><span class="n">erfinv_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>erfinv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-99-1" name="__codelineno-99-1" href="#__codelineno-99-1"></a><span class="n">exp</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.exp" title="torch.exp"><code>torch.exp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-100-1" name="__codelineno-100-1" href="#__codelineno-100-1"></a><span class="n">exp_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.exp" title="torch.Tensor.exp"><code>exp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-101-1" name="__codelineno-101-1" href="#__codelineno-101-1"></a><span class="n">expm1</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.expm1" title="torch.expm1"><code>torch.expm1()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-102-1" name="__codelineno-102-1" href="#__codelineno-102-1"></a><span class="n">expm1_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>expm1()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-103-1" name="__codelineno-103-1" href="#__codelineno-103-1"></a><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">sizes</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个新的 <code>self</code> tensor 的视图, 其中单一维度扩展到更大的尺寸.</p>
<p>传递<code>-1</code>意味着不改变该维度的大小.</p>
<p>tensor 也可以扩展到更大的维度, 新的维度将会附加在前面.对于新维度, 其大小不能设置为- 1.</p>
<p>扩展张量不会分配新的内存, 但只会在现有张量上创建一个新的视图, 其中通过将<code>stride</code>设置为0, 第一个尺寸的维度会扩展到更大的尺寸.大小为1的任何维度都可以扩展到任意值, 而无需分配新内存.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>*sizes</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – 期望扩展的尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-104-1" name="__codelineno-104-1" href="#__codelineno-104-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<a id="__codelineno-104-2" name="__codelineno-104-2" href="#__codelineno-104-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-104-3" name="__codelineno-104-3" href="#__codelineno-104-3"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-104-4" name="__codelineno-104-4" href="#__codelineno-104-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-104-5" name="__codelineno-104-5" href="#__codelineno-104-5"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-104-6" name="__codelineno-104-6" href="#__codelineno-104-6"></a> <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
<a id="__codelineno-104-7" name="__codelineno-104-7" href="#__codelineno-104-7"></a> <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
<a id="__codelineno-104-8" name="__codelineno-104-8" href="#__codelineno-104-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>   <span class="c1"># -1 意味着不会改变该维度</span>
<a id="__codelineno-104-9" name="__codelineno-104-9" href="#__codelineno-104-9"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-104-10" name="__codelineno-104-10" href="#__codelineno-104-10"></a> <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
<a id="__codelineno-104-11" name="__codelineno-104-11" href="#__codelineno-104-11"></a> <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-105-1" name="__codelineno-105-1" href="#__codelineno-105-1"></a><span class="n">expand_as</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>扩展这个 tensor 使得其尺寸和 <code>other</code> 相同. <code>self.expand_as(other)</code> 等价于 <code>self.expand(other.size())</code>.</p>
<p>请看 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a> 获得更多关于 <code>expand</code> 的信息.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – 返回的 tensor 的尺寸和 <code>other</code>. 相同</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><a id="__codelineno-106-1" name="__codelineno-106-1" href="#__codelineno-106-1"></a><span class="n">exponential_</span><span class="p">(</span><span class="n">lambd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用取自 <code>exponential 分布</code> 的元素填充 <code>self</code> tensor :</p>
<p><img alt="" src="../img/3ba5517bd8983486f896da97d259de60.jpg" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-107-1" name="__codelineno-107-1" href="#__codelineno-107-1"></a><span class="n">fill_</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用指定的值填充 <code>self</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-108-1" name="__codelineno-108-1" href="#__codelineno-108-1"></a><span class="n">flatten</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.flatten" title="torch.flatten"><code>torch.flatten()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-109-1" name="__codelineno-109-1" href="#__codelineno-109-1"></a><span class="n">flip</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.flip" title="torch.flip"><code>torch.flip()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-110-1" name="__codelineno-110-1" href="#__codelineno-110-1"></a><span class="nb">float</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.float()</code> 等价于 <code>self.to(torch.float32)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-111-1" name="__codelineno-111-1" href="#__codelineno-111-1"></a><span class="n">floor</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.floor" title="torch.floor"><code>torch.floor()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-112-1" name="__codelineno-112-1" href="#__codelineno-112-1"></a><span class="n">floor_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.floor" title="torch.Tensor.floor"><code>floor()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-113-1" name="__codelineno-113-1" href="#__codelineno-113-1"></a><span class="n">fmod</span><span class="p">(</span><span class="n">divisor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.fmod" title="torch.fmod"><code>torch.fmod()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-114-1" name="__codelineno-114-1" href="#__codelineno-114-1"></a><span class="n">fmod_</span><span class="p">(</span><span class="n">divisor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>fmod()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-115-1" name="__codelineno-115-1" href="#__codelineno-115-1"></a><span class="n">frac</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.frac" title="torch.frac"><code>torch.frac()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-116-1" name="__codelineno-116-1" href="#__codelineno-116-1"></a><span class="n">frac_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.frac" title="torch.Tensor.frac"><code>frac()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-117-1" name="__codelineno-117-1" href="#__codelineno-117-1"></a><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.gather" title="torch.gather"><code>torch.gather()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-118-1" name="__codelineno-118-1" href="#__codelineno-118-1"></a><span class="n">ge</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.ge" title="torch.ge"><code>torch.ge()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-119-1" name="__codelineno-119-1" href="#__codelineno-119-1"></a><span class="n">ge_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.ge" title="torch.Tensor.ge"><code>ge()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-120-1" name="__codelineno-120-1" href="#__codelineno-120-1"></a><span class="n">gels</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.gels" title="torch.gels"><code>torch.gels()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-121-1" name="__codelineno-121-1" href="#__codelineno-121-1"></a><span class="n">geometric_</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用取自<code>geometric 分布</code>的值填充 <code>self</code> :</p>
<p><img alt="" src="../img/d8f96bc88098f6c83428092c8773bb7a.jpg" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-122-1" name="__codelineno-122-1" href="#__codelineno-122-1"></a><span class="n">geqrf</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-123-1" name="__codelineno-123-1" href="#__codelineno-123-1"></a><span class="n">ger</span><span class="p">(</span><span class="n">vec2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.ger" title="torch.ger"><code>torch.ger()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-124-1" name="__codelineno-124-1" href="#__codelineno-124-1"></a><span class="n">gesv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.gesv" title="torch.gesv"><code>torch.gesv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-125-1" name="__codelineno-125-1" href="#__codelineno-125-1"></a><span class="n">get_device</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Device</span> <span class="n">ordinal</span> <span class="p">(</span><span class="n">Integer</span><span class="p">)</span>
</code></pre></div>
<p>对于 CUDA tensors, 这个函数返回一个 GPU 序号, 对应 tensor 所在的设备. 对于 CPU tensors, 抛出一个错误.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-126-1" name="__codelineno-126-1" href="#__codelineno-126-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<a id="__codelineno-126-2" name="__codelineno-126-2" href="#__codelineno-126-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
<a id="__codelineno-126-3" name="__codelineno-126-3" href="#__codelineno-126-3"></a><span class="mi">0</span>
<a id="__codelineno-126-4" name="__codelineno-126-4" href="#__codelineno-126-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>  <span class="c1"># 运行时错误: get_device 没有在 torch.FloatTensor 上实现</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-127-1" name="__codelineno-127-1" href="#__codelineno-127-1"></a><span class="n">gt</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.gt" title="torch.gt"><code>torch.gt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-128-1" name="__codelineno-128-1" href="#__codelineno-128-1"></a><span class="n">gt_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.gt" title="torch.Tensor.gt"><code>gt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-129-1" name="__codelineno-129-1" href="#__codelineno-129-1"></a><span class="n">half</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.half()</code> 等价于 <code>self.to(torch.float16)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-130-1" name="__codelineno-130-1" href="#__codelineno-130-1"></a><span class="n">histc</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.histc" title="torch.histc"><code>torch.histc()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-131-1" name="__codelineno-131-1" href="#__codelineno-131-1"></a><span class="n">index_add_</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>根据参数<code>index</code> 中的索引的顺序, 累加 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素到 <code>self</code> tensor, 例如, 如果 <code>dim == 0</code> 并且 <code>index[i] == j</code>, 则第 <code>i</code> 行 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 会被加到第 <code>j</code>行.</p>
<p><a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>tensor</code></a> 第 <a href="torch.html#torch.tensor" title="torch.tensor"><code>dim</code></a> 维度 必须和 <code>index</code>(必须是一个向量) 的长度相同, 并且其它维度必须和 <code>self</code> 匹配, 否则将会抛出一个错误.</p>
<p>注意</p>
<p>当使用 CUDA 作为后端, 这个操作可能导致不确定性行为, 且不容易关闭. 请看 <a href="notes/randomness.html">Reproducibility</a>.</p>
<p>Parameters: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的维度</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 从 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中选择的索引</li>
<li><strong>tensor</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 用于相加的tensor</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-132-1" name="__codelineno-132-1" href="#__codelineno-132-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-132-2" name="__codelineno-132-2" href="#__codelineno-132-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-132-3" name="__codelineno-132-3" href="#__codelineno-132-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-132-4" name="__codelineno-132-4" href="#__codelineno-132-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<a id="__codelineno-132-5" name="__codelineno-132-5" href="#__codelineno-132-5"></a><span class="n">tensor</span><span class="p">([[</span>  <span class="mf">2.</span><span class="p">,</span>   <span class="mf">3.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">],</span>
<a id="__codelineno-132-6" name="__codelineno-132-6" href="#__codelineno-132-6"></a> <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
<a id="__codelineno-132-7" name="__codelineno-132-7" href="#__codelineno-132-7"></a> <span class="p">[</span>  <span class="mf">8.</span><span class="p">,</span>   <span class="mf">9.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">],</span>
<a id="__codelineno-132-8" name="__codelineno-132-8" href="#__codelineno-132-8"></a> <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
<a id="__codelineno-132-9" name="__codelineno-132-9" href="#__codelineno-132-9"></a> <span class="p">[</span>  <span class="mf">5.</span><span class="p">,</span>   <span class="mf">6.</span><span class="p">,</span>   <span class="mf">7.</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-133-1" name="__codelineno-133-1" href="#__codelineno-133-1"></a><span class="n">index_copy_</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>根据参数<code>index</code> 中的选择的索引, 复制 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素到 <code>self</code> tensor, 例如, 如果 <code>dim == 0</code> 并且 <code>index[i] == j</code>, 则第 <code>i</code> 行 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 会被加到第 <code>j</code>行.</p>
<p><a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>tensor</code></a> 第 <a href="torch.html#torch.tensor" title="torch.tensor"><code>dim</code></a> 维度 必须和 <code>index</code>(必须是一个向量) 的长度相同, 并且其它维度必须和 <code>self</code> 匹配, 否则将会抛出一个错误.</p>
<p>Parameters: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的维度</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 从 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中选择的索引</li>
<li><strong>tensor</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 用于复制的tensor</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-134-1" name="__codelineno-134-1" href="#__codelineno-134-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-134-2" name="__codelineno-134-2" href="#__codelineno-134-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-134-3" name="__codelineno-134-3" href="#__codelineno-134-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-134-4" name="__codelineno-134-4" href="#__codelineno-134-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">index_copy_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<a id="__codelineno-134-5" name="__codelineno-134-5" href="#__codelineno-134-5"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
<a id="__codelineno-134-6" name="__codelineno-134-6" href="#__codelineno-134-6"></a> <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<a id="__codelineno-134-7" name="__codelineno-134-7" href="#__codelineno-134-7"></a> <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">],</span>
<a id="__codelineno-134-8" name="__codelineno-134-8" href="#__codelineno-134-8"></a> <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<a id="__codelineno-134-9" name="__codelineno-134-9" href="#__codelineno-134-9"></a> <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-135-1" name="__codelineno-135-1" href="#__codelineno-135-1"></a><span class="n">index_fill_</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>根据 <code>index</code> 中指定的顺序索引, 用值 <code>val</code>填充 <code>self</code> tensor 中的元素.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定索引对应的维度</li>
<li><strong>index</strong> (<em>LongTensor</em>) –  <code>self</code> tensor 中将被填充的索引值</li>
<li><strong>val</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – 用于填充的值</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-136-1" name="__codelineno-136-1" href="#__codelineno-136-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-136-2" name="__codelineno-136-2" href="#__codelineno-136-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-136-3" name="__codelineno-136-3" href="#__codelineno-136-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">index_fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-136-4" name="__codelineno-136-4" href="#__codelineno-136-4"></a><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
<a id="__codelineno-136-5" name="__codelineno-136-5" href="#__codelineno-136-5"></a> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
<a id="__codelineno-136-6" name="__codelineno-136-6" href="#__codelineno-136-6"></a> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-137-1" name="__codelineno-137-1" href="#__codelineno-137-1"></a><span class="n">index_put_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>根据 <code>indices</code> (是一个 Tensors 的tuple)中指定的索引, 取出 tensor <code>value</code> 中的值放入 tensor <code>self</code> . 表达式 <code>tensor.index_put_(indices, value)</code> 等价于 <code>tensor[indices] = value</code>. 返回 <code>self</code>.</p>
<p>如果 <code>accumulate</code> 等于 <code>True</code>,  <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素会被加到 <code>self</code>. 如果是 <code>False</code>, 且 <code>indices</code> 中含有重复的元素, 则行为是未定义的.</p>
<p>参数: </p>
<ul>
<li><strong>indices</strong> (<em>tuple of LongTensor</em>) – tensors 用于索引 <code>self</code>.</li>
<li><strong>value</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 与 <code>self</code> 有相同数据类型的 tensor.</li>
<li><strong>accumulate</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 是否累加到自身</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-138-1" name="__codelineno-138-1" href="#__codelineno-138-1"></a><span class="n">index_select</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.index_select" title="torch.index_select"><code>torch.index_select()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-139-1" name="__codelineno-139-1" href="#__codelineno-139-1"></a><span class="nb">int</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.int()</code> is equivalent to <code>self.to(torch.int32)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-140-1" name="__codelineno-140-1" href="#__codelineno-140-1"></a><span class="n">inverse</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-141-1" name="__codelineno-141-1" href="#__codelineno-141-1"></a><span class="n">is_contiguous</span><span class="p">()</span> <span class="err">→</span> <span class="nb">bool</span>
</code></pre></div>
<p>返回 True 如果 <code>self</code> tensor 在内存中是连续存储的.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-142-1" name="__codelineno-142-1" href="#__codelineno-142-1"></a><span class="n">is_pinned</span><span class="p">()</span>
</code></pre></div>
<p>返回 true 如果 tensor 储存在pinned memory</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-143-1" name="__codelineno-143-1" href="#__codelineno-143-1"></a><span class="n">is_set_to</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="err">→</span> <span class="nb">bool</span>
</code></pre></div>
<p>返回 True 如果此对象在 Torch C API 中引用的 <code>THTensor</code> 对象和给定 tensor 是相同的.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-144-1" name="__codelineno-144-1" href="#__codelineno-144-1"></a><span class="n">is_signed</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-145-1" name="__codelineno-145-1" href="#__codelineno-145-1"></a><span class="n">item</span><span class="p">()</span> <span class="err">→</span> <span class="n">number</span>
</code></pre></div>
<p>返回 tensor 中的值作为一个标准的 Python number. 仅在只有一个元素的时候有效. 对于其他情况, 见 <a href="#torch.Tensor.tolist" title="torch.Tensor.tolist"><code>tolist()</code></a>.</p>
<p>这个操作是不可微分的.</p>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-146-1" name="__codelineno-146-1" href="#__codelineno-146-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<a id="__codelineno-146-2" name="__codelineno-146-2" href="#__codelineno-146-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<a id="__codelineno-146-3" name="__codelineno-146-3" href="#__codelineno-146-3"></a><span class="mf">1.0</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-147-1" name="__codelineno-147-1" href="#__codelineno-147-1"></a><span class="n">kthvalue</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.kthvalue" title="torch.kthvalue"><code>torch.kthvalue()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-148-1" name="__codelineno-148-1" href="#__codelineno-148-1"></a><span class="n">le</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.le" title="torch.le"><code>torch.le()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-149-1" name="__codelineno-149-1" href="#__codelineno-149-1"></a><span class="n">le_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.le" title="torch.Tensor.le"><code>le()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-150-1" name="__codelineno-150-1" href="#__codelineno-150-1"></a><span class="n">lerp</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.lerp" title="torch.lerp"><code>torch.lerp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-151-1" name="__codelineno-151-1" href="#__codelineno-151-1"></a><span class="n">lerp_</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>lerp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-152-1" name="__codelineno-152-1" href="#__codelineno-152-1"></a><span class="n">log</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.log" title="torch.log"><code>torch.log()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-153-1" name="__codelineno-153-1" href="#__codelineno-153-1"></a><span class="n">log_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.log" title="torch.Tensor.log"><code>log()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-154-1" name="__codelineno-154-1" href="#__codelineno-154-1"></a><span class="n">logdet</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.logdet" title="torch.logdet"><code>torch.logdet()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-155-1" name="__codelineno-155-1" href="#__codelineno-155-1"></a><span class="n">log10</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.log10" title="torch.log10"><code>torch.log10()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-156-1" name="__codelineno-156-1" href="#__codelineno-156-1"></a><span class="n">log10_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.log10" title="torch.Tensor.log10"><code>log10()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-157-1" name="__codelineno-157-1" href="#__codelineno-157-1"></a><span class="n">log1p</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-158-1" name="__codelineno-158-1" href="#__codelineno-158-1"></a><span class="n">log1p_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>log1p()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-159-1" name="__codelineno-159-1" href="#__codelineno-159-1"></a><span class="n">log2</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.log2" title="torch.log2"><code>torch.log2()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-160-1" name="__codelineno-160-1" href="#__codelineno-160-1"></a><span class="n">log2_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.log2" title="torch.Tensor.log2"><code>log2()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-161-1" name="__codelineno-161-1" href="#__codelineno-161-1"></a><span class="n">log_normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>用 <code>mean</code> <img alt="" src="../img/4e4d506c887c843f43a8fbcbe1884ffd.jpg" />和<code>std</code> <img alt="" src="../img/2469b2bd2a1ab19ebfcee223dcb52bb1.jpg" />初始化的 <code>log-normal 分布</code> 中取出的值填充 <code>self</code>. 注意 <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> 和 <a href="torch.html#torch.std" title="torch.std"><code>std</code></a> 是下面的 normal 分布的平均值和标准差, 而不是返回的分布:</p>
<p><img alt="" src="../img/8672e701dc33c217b7d832207b171eed.jpg" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-162-1" name="__codelineno-162-1" href="#__codelineno-162-1"></a><span class="n">logsumexp</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-163-1" name="__codelineno-163-1" href="#__codelineno-163-1"></a><span class="n">long</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.long()</code> is equivalent to <code>self.to(torch.int64)</code>. See <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-164-1" name="__codelineno-164-1" href="#__codelineno-164-1"></a><span class="n">lt</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.lt" title="torch.lt"><code>torch.lt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-165-1" name="__codelineno-165-1" href="#__codelineno-165-1"></a><span class="n">lt_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.lt" title="torch.Tensor.lt"><code>lt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-166-1" name="__codelineno-166-1" href="#__codelineno-166-1"></a><span class="n">map_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="nb">callable</span><span class="p">)</span>
</code></pre></div>
<p>对 <code>self</code> tensor 和 给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的每一个元素应用 <code>callable</code> 然后把结果存于 <code>self</code> tensor. <code>self</code> tensor 和给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 必须可广播 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p><code>callable</code> 应该有下面的函数签名:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-167-1" name="__codelineno-167-1" href="#__codelineno-167-1"></a><span class="k">def</span> <span class="nf">callable</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">number</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-168-1" name="__codelineno-168-1" href="#__codelineno-168-1"></a><span class="n">masked_scatter_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">source</span><span class="p">)</span>
</code></pre></div>
<p>从 <code>source</code> 复制元素到 <code>self</code> tensor 当对应 <code>mask</code> 对应的值是 1.  <code>mask</code> 的形状必须和底层 tensor 可广播 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.  <code>source</code> 的元素数量至少和 <code>mask</code>里面的1一样多</p>
<p>Parameters: </p>
<ul>
<li><strong>mask</strong> (<a href="#torch.ByteTensor" title="torch.ByteTensor"><em>ByteTensor</em></a>) – 二值掩码</li>
<li><strong>source</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 源 tensor</li>
</ul>
<p>注意</p>
<p><code>mask</code> 操作于 <code>self</code> tensor, 而不是给定的 <code>source</code> tensor.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-169-1" name="__codelineno-169-1" href="#__codelineno-169-1"></a><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div>
<p>用<code>value</code>填充 <code>self</code> tensor 中的元素, 当对应位置的 <code>mask</code> 是1. <code>mask</code> 的形状必须和底层 tensor <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a>.</p>
<p>参数: </p>
<ul>
<li><strong>mask</strong> (<a href="#torch.ByteTensor" title="torch.ByteTensor"><em>ByteTensor</em></a>) – 二值掩码</li>
<li><strong>value</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – 用于填充的值</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-170-1" name="__codelineno-170-1" href="#__codelineno-170-1"></a><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.masked_select" title="torch.masked_select"><code>torch.masked_select()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-171-1" name="__codelineno-171-1" href="#__codelineno-171-1"></a><span class="n">matmul</span><span class="p">(</span><span class="n">tensor2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.matmul" title="torch.matmul"><code>torch.matmul()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-172-1" name="__codelineno-172-1" href="#__codelineno-172-1"></a><span class="n">matrix_power</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.matrix_power" title="torch.matrix_power"><code>torch.matrix_power()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-173-1" name="__codelineno-173-1" href="#__codelineno-173-1"></a><span class="nb">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.max" title="torch.max"><code>torch.max()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-174-1" name="__codelineno-174-1" href="#__codelineno-174-1"></a><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.mean" title="torch.mean"><code>torch.mean()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-175-1" name="__codelineno-175-1" href="#__codelineno-175-1"></a><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.median" title="torch.median"><code>torch.median()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-176-1" name="__codelineno-176-1" href="#__codelineno-176-1"></a><span class="nb">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.min" title="torch.min"><code>torch.min()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-177-1" name="__codelineno-177-1" href="#__codelineno-177-1"></a><span class="n">mm</span><span class="p">(</span><span class="n">mat2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.mm" title="torch.mm"><code>torch.mm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-178-1" name="__codelineno-178-1" href="#__codelineno-178-1"></a><span class="n">mode</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.mode" title="torch.mode"><code>torch.mode()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-179-1" name="__codelineno-179-1" href="#__codelineno-179-1"></a><span class="n">mul</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.mul" title="torch.mul"><code>torch.mul()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-180-1" name="__codelineno-180-1" href="#__codelineno-180-1"></a><span class="n">mul_</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.mul" title="torch.Tensor.mul"><code>mul()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-181-1" name="__codelineno-181-1" href="#__codelineno-181-1"></a><span class="n">multinomial</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-182-1" name="__codelineno-182-1" href="#__codelineno-182-1"></a><span class="n">mv</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.mv" title="torch.mv"><code>torch.mv()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-183-1" name="__codelineno-183-1" href="#__codelineno-183-1"></a><span class="n">mvlgamma</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.mvlgamma" title="torch.mvlgamma"><code>torch.mvlgamma()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-184-1" name="__codelineno-184-1" href="#__codelineno-184-1"></a><span class="n">mvlgamma_</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>mvlgamma()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-185-1" name="__codelineno-185-1" href="#__codelineno-185-1"></a><span class="n">narrow</span><span class="p">(</span><span class="n">dimension</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.narrow" title="torch.narrow"><code>torch.narrow()</code></a></p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-186-1" name="__codelineno-186-1" href="#__codelineno-186-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-186-2" name="__codelineno-186-2" href="#__codelineno-186-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-186-3" name="__codelineno-186-3" href="#__codelineno-186-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-186-4" name="__codelineno-186-4" href="#__codelineno-186-4"></a> <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-186-5" name="__codelineno-186-5" href="#__codelineno-186-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-186-6" name="__codelineno-186-6" href="#__codelineno-186-6"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-186-7" name="__codelineno-186-7" href="#__codelineno-186-7"></a> <span class="p">[</span> <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
<a id="__codelineno-186-8" name="__codelineno-186-8" href="#__codelineno-186-8"></a> <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-187-1" name="__codelineno-187-1" href="#__codelineno-187-1"></a><span class="n">ndimension</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>Alias for <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-188-1" name="__codelineno-188-1" href="#__codelineno-188-1"></a><span class="n">ne</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.ne" title="torch.ne"><code>torch.ne()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-189-1" name="__codelineno-189-1" href="#__codelineno-189-1"></a><span class="n">ne_</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.ne" title="torch.Tensor.ne"><code>ne()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-190-1" name="__codelineno-190-1" href="#__codelineno-190-1"></a><span class="n">neg</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-191-1" name="__codelineno-191-1" href="#__codelineno-191-1"></a><span class="n">neg_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.neg" title="torch.Tensor.neg"><code>neg()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-192-1" name="__codelineno-192-1" href="#__codelineno-192-1"></a><span class="n">nelement</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>别名 <a href="#torch.Tensor.numel" title="torch.Tensor.numel"><code>numel()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-193-1" name="__codelineno-193-1" href="#__codelineno-193-1"></a><span class="n">nonzero</span><span class="p">()</span> <span class="err">→</span> <span class="n">LongTensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-194-1" name="__codelineno-194-1" href="#__codelineno-194-1"></a><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>见 :func: <code>torch.norm</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-195-1" name="__codelineno-195-1" href="#__codelineno-195-1"></a><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用采样于 normal 分布的元素填充 <code>self</code> tensor, normal 分布使用参数 <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> and <a href="torch.html#torch.std" title="torch.std"><code>std</code></a>初始化.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-196-1" name="__codelineno-196-1" href="#__codelineno-196-1"></a><span class="n">numel</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.numel" title="torch.numel"><code>torch.numel()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-197-1" name="__codelineno-197-1" href="#__codelineno-197-1"></a><span class="n">numpy</span><span class="p">()</span> <span class="err">→</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
</code></pre></div>
<p>返回 <code>self</code> tensor 作为一个 NumPy <code>ndarray</code>. 此 tensor 和返回的 <code>ndarray</code> 共享同一个底层存储. 改变<code>self</code> tensor 将会同时改变 <code>ndarray</code> .</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-198-1" name="__codelineno-198-1" href="#__codelineno-198-1"></a><span class="n">orgqr</span><span class="p">(</span><span class="n">input2</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.orgqr" title="torch.orgqr"><code>torch.orgqr()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-199-1" name="__codelineno-199-1" href="#__codelineno-199-1"></a><span class="n">ormqr</span><span class="p">(</span><span class="n">input2</span><span class="p">,</span> <span class="n">input3</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.ormqr" title="torch.ormqr"><code>torch.ormqr()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-200-1" name="__codelineno-200-1" href="#__codelineno-200-1"></a><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">dims</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>排列 tensor 的维度.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>*dims</strong> (<em>int...</em>) – 维度的排列顺序</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Example</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-201-1" name="__codelineno-201-1" href="#__codelineno-201-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-201-2" name="__codelineno-201-2" href="#__codelineno-201-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-201-3" name="__codelineno-201-3" href="#__codelineno-201-3"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<a id="__codelineno-201-4" name="__codelineno-201-4" href="#__codelineno-201-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-201-5" name="__codelineno-201-5" href="#__codelineno-201-5"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-202-1" name="__codelineno-202-1" href="#__codelineno-202-1"></a><span class="n">pin_memory</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-203-1" name="__codelineno-203-1" href="#__codelineno-203-1"></a><span class="n">pinverse</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-204-1" name="__codelineno-204-1" href="#__codelineno-204-1"></a><span class="n">potrf</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-205-1" name="__codelineno-205-1" href="#__codelineno-205-1"></a><span class="n">potri</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.potri" title="torch.potri"><code>torch.potri()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-206-1" name="__codelineno-206-1" href="#__codelineno-206-1"></a><span class="n">potrs</span><span class="p">(</span><span class="n">input2</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.potrs" title="torch.potrs"><code>torch.potrs()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-207-1" name="__codelineno-207-1" href="#__codelineno-207-1"></a><span class="nb">pow</span><span class="p">(</span><span class="n">exponent</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.pow" title="torch.pow"><code>torch.pow()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-208-1" name="__codelineno-208-1" href="#__codelineno-208-1"></a><span class="n">pow_</span><span class="p">(</span><span class="n">exponent</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.pow" title="torch.Tensor.pow"><code>pow()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-209-1" name="__codelineno-209-1" href="#__codelineno-209-1"></a><span class="n">prod</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.prod" title="torch.prod"><code>torch.prod()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-210-1" name="__codelineno-210-1" href="#__codelineno-210-1"></a><span class="n">pstrf</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tol</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">IntTensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.pstrf" title="torch.pstrf"><code>torch.pstrf()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-211-1" name="__codelineno-211-1" href="#__codelineno-211-1"></a><span class="n">put_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>从 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中复制元素到 indices 指定的位置. 对于目的索引,  <code>self</code> tensor 被当作一个 1-D tensor.</p>
<p>如果 <code>accumulate</code> 是 <code>True</code>, <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素被被加到 <code>self</code>. 如果 accumulate 是 <code>False</code>, 当 indices 中有重复索引时行为未定义.</p>
<p>Parameters: </p>
<ul>
<li><strong>indices</strong> (<em>LongTensor</em>) – self 的索引位置</li>
<li><strong>tensor</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 包含待复制元素的 tensor</li>
<li><strong>accumulate</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 是否累加到 self</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-212-1" name="__codelineno-212-1" href="#__codelineno-212-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<a id="__codelineno-212-2" name="__codelineno-212-2" href="#__codelineno-212-2"></a> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<a id="__codelineno-212-3" name="__codelineno-212-3" href="#__codelineno-212-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">src</span><span class="o">.</span><span class="n">put_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<a id="__codelineno-212-4" name="__codelineno-212-4" href="#__codelineno-212-4"></a><span class="n">tensor</span><span class="p">([[</span>  <span class="mi">4</span><span class="p">,</span>   <span class="mi">9</span><span class="p">,</span>   <span class="mi">5</span><span class="p">],</span>
<a id="__codelineno-212-5" name="__codelineno-212-5" href="#__codelineno-212-5"></a> <span class="p">[</span> <span class="mi">10</span><span class="p">,</span>   <span class="mi">7</span><span class="p">,</span>   <span class="mi">8</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-213-1" name="__codelineno-213-1" href="#__codelineno-213-1"></a><span class="n">qr</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.qr" title="torch.qr"><code>torch.qr()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-214-1" name="__codelineno-214-1" href="#__codelineno-214-1"></a><span class="n">random_</span><span class="p">(</span><span class="n">from</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用离散均匀分布介于  <code>[from, to - 1]</code> 采样的数字填充 <code>self</code> tensor. 如果没有特别指定, 这些采样的数值被 <code>self</code> tensor's 数据类型界定. 然而, 对于浮点型, 如果没有特别指定, 范围将是 <code>[0, 2^mantissa]</code> 来确保每一个值是可表示的. 例如, <code>torch.tensor(1, dtype=torch.double).random_()</code> 将会被设为 <code>[0, 2^53]</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-215-1" name="__codelineno-215-1" href="#__codelineno-215-1"></a><span class="n">reciprocal</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.reciprocal" title="torch.reciprocal"><code>torch.reciprocal()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-216-1" name="__codelineno-216-1" href="#__codelineno-216-1"></a><span class="n">reciprocal_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>reciprocal()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-217-1" name="__codelineno-217-1" href="#__codelineno-217-1"></a><span class="n">remainder</span><span class="p">(</span><span class="n">divisor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-218-1" name="__codelineno-218-1" href="#__codelineno-218-1"></a><span class="n">remainder_</span><span class="p">(</span><span class="n">divisor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>remainder()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-219-1" name="__codelineno-219-1" href="#__codelineno-219-1"></a><span class="n">renorm</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.renorm" title="torch.renorm"><code>torch.renorm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-220-1" name="__codelineno-220-1" href="#__codelineno-220-1"></a><span class="n">renorm_</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>renorm()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-221-1" name="__codelineno-221-1" href="#__codelineno-221-1"></a><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">sizes</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>在指定的维度重复这个 tensor.</p>
<p>不像 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a>, 这个函数会拷贝底层数据.</p>
<p>警告</p>
<p><code>torch.repeat()</code> 的行为和 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html">numpy.repeat</a> 不一样, 更类似于 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html">numpy.tile</a>.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>sizes</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – 每个维度重复的次数</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-222-1" name="__codelineno-222-1" href="#__codelineno-222-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-222-2" name="__codelineno-222-2" href="#__codelineno-222-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-222-3" name="__codelineno-222-3" href="#__codelineno-222-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-222-4" name="__codelineno-222-4" href="#__codelineno-222-4"></a> <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-222-5" name="__codelineno-222-5" href="#__codelineno-222-5"></a> <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-222-6" name="__codelineno-222-6" href="#__codelineno-222-6"></a> <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>
<a id="__codelineno-222-7" name="__codelineno-222-7" href="#__codelineno-222-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-222-8" name="__codelineno-222-8" href="#__codelineno-222-8"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-223-1" name="__codelineno-223-1" href="#__codelineno-223-1"></a><span class="n">requires_grad_</span><span class="p">(</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>设置是否应该自动求导: 原地设置这个 tensor 的 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> 属性.返回这个 tensor.</p>
<p><code>require_grad_()</code> 的主要使用情况是告诉自动求导开始记录Tensor <code>tensor</code>上的操作. 如果 <code>tensor</code> 的 <code>requires_grad=False</code> (因为它是通过 DataLoader 获得或者需要预处理或初始化), <code>tensor.requires_grad_()</code> 将会使得自动求导开始生效.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – 是否自动求导应该记录相关操作. Default: <code>True</code>.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-224-1" name="__codelineno-224-1" href="#__codelineno-224-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Let&#39;s say we want to preprocess some saved weights and use</span>
<a id="__codelineno-224-2" name="__codelineno-224-2" href="#__codelineno-224-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># the result as new weights.</span>
<a id="__codelineno-224-3" name="__codelineno-224-3" href="#__codelineno-224-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">saved_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]</span>
<a id="__codelineno-224-4" name="__codelineno-224-4" href="#__codelineno-224-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">loaded_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">saved_weights</span><span class="p">)</span>
<a id="__codelineno-224-5" name="__codelineno-224-5" href="#__codelineno-224-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">loaded_weights</span><span class="p">)</span>  <span class="c1"># some function</span>
<a id="__codelineno-224-6" name="__codelineno-224-6" href="#__codelineno-224-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span>
<a id="__codelineno-224-7" name="__codelineno-224-7" href="#__codelineno-224-7"></a><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5503</span><span class="p">,</span>  <span class="mf">0.4926</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1158</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8303</span><span class="p">])</span>
<a id="__codelineno-224-8" name="__codelineno-224-8" href="#__codelineno-224-8"></a>
<a id="__codelineno-224-9" name="__codelineno-224-9" href="#__codelineno-224-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Now, start to record operations done to weights</span>
<a id="__codelineno-224-10" name="__codelineno-224-10" href="#__codelineno-224-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<a id="__codelineno-224-11" name="__codelineno-224-11" href="#__codelineno-224-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-224-12" name="__codelineno-224-12" href="#__codelineno-224-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-224-13" name="__codelineno-224-13" href="#__codelineno-224-13"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">weights</span><span class="o">.</span><span class="n">grad</span>
<a id="__codelineno-224-14" name="__codelineno-224-14" href="#__codelineno-224-14"></a><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.1007</span><span class="p">,</span>  <span class="mf">0.9853</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.2316</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6606</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-225-1" name="__codelineno-225-1" href="#__codelineno-225-1"></a><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个 tensor, 其data和元素数量与 <code>self</code> 一样, 但是改变成指定的形状. 这个方法返回一个tensor的试图 如果 <code>shape</code> 和当前的形状是兼容的. 见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 关于是什么时候返回一个 view.</p>
<p>见 <a href="torch.html#torch.reshape" title="torch.reshape"><code>torch.reshape()</code></a></p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>shape</strong> (<em>tuple of python:ints</em> <em>or</em> <em>int...</em>) – 期望变成的形状</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><a id="__codelineno-226-1" name="__codelineno-226-1" href="#__codelineno-226-1"></a><span class="n">reshape_as</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个tensor形状与 <code>other</code> 相同. <code>self.reshape_as(other)</code> 等价于 <code>self.reshape(other.sizes())</code>. 这个方法返回一个tensor的试图 如果 <code>self.reshape(other.sizes())</code> 和当前的形状是兼容的. 见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 关于是什么时候返回一个 view.</p>
<p>请参考 <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a> 获得更多关于 <code>reshape</code> 的信息.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – 返回的tensor形状与 <code>other</code> 一致.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><a id="__codelineno-227-1" name="__codelineno-227-1" href="#__codelineno-227-1"></a><span class="n">resize_</span><span class="p">(</span><span class="o">*</span><span class="n">sizes</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>缩放 <code>self</code> tensor到指定的大小. 如果指定的元素数量比当前的要大, 底层的存储结构会缩放到合适的大小. 如果数量更小, 底层存储不变. 当前的元素都会被保留, 没有任何的新的初始化.</p>
<p>警告</p>
<p>这是一个底层的操作. 存储被重新解释为C-contiguous, 忽略当前stride(除非目标大小等于当前大小, 在这种情况下tensor保持不变）.在大多数情况下, 您将要使用 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a>, 它会检查连续性, 或者 <a href="#torch.Tensor.reshape" title="torch.Tensor.reshape"><code>reshape()</code></a>, 在必要的时候会拷贝数据. 如果想要改变大小并且自定义stride, 见 <a href="#torch.Tensor.set_" title="torch.Tensor.set_"><code>set_()</code></a>.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>sizes</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – 期望的大小</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-228-1" name="__codelineno-228-1" href="#__codelineno-228-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<a id="__codelineno-228-2" name="__codelineno-228-2" href="#__codelineno-228-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-228-3" name="__codelineno-228-3" href="#__codelineno-228-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">],</span>
<a id="__codelineno-228-4" name="__codelineno-228-4" href="#__codelineno-228-4"></a> <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-229-1" name="__codelineno-229-1" href="#__codelineno-229-1"></a><span class="n">resize_as_</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>缩放 <code>self</code> tensor 的大小与参数 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 相同. 等价于 <code>self.resize_(tensor.size())</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-230-1" name="__codelineno-230-1" href="#__codelineno-230-1"></a><span class="nb">round</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.round" title="torch.round"><code>torch.round()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-231-1" name="__codelineno-231-1" href="#__codelineno-231-1"></a><span class="n">round_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.round" title="torch.Tensor.round"><code>round()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-232-1" name="__codelineno-232-1" href="#__codelineno-232-1"></a><span class="n">rsqrt</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.rsqrt" title="torch.rsqrt"><code>torch.rsqrt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-233-1" name="__codelineno-233-1" href="#__codelineno-233-1"></a><span class="n">rsqrt_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>rsqrt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-234-1" name="__codelineno-234-1" href="#__codelineno-234-1"></a><span class="n">scatter_</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>根据 <code>index</code> tensor 中指定的索引, 将所有 tensor <code>src</code> 中的值写入<code>self</code> . 对于  <code>src</code> 中的每一个值, 当 <code>dimension != dim</code>, 它的输出的索引由 <code>src</code> 中的索引指定, 当 <code>dimension = dim</code>,  由 <code>index</code> 中对应的值指定.</p>
<p>对于一个 3-D tensor, <code>self</code> 的更新规则如下:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-235-1" name="__codelineno-235-1" href="#__codelineno-235-1"></a><span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>
<a id="__codelineno-235-2" name="__codelineno-235-2" href="#__codelineno-235-2"></a><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>
<a id="__codelineno-235-3" name="__codelineno-235-3" href="#__codelineno-235-3"></a><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 2</span>
</code></pre></div>
<p>这是 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a> 中描述的方式的逆向操作.</p>
<p><code>self</code>, <code>index</code> and <code>src</code> (if it is a Tensor) 应该有相同数量的维度. 同时也要求 <code>index.size(d) &lt;= src.size(d)</code> 对于每一个维度 <code>d</code>, 而且 <code>index.size(d) &lt;= self.size(d)</code> 对于每一个维度 <code>d != dim</code>.</p>
<p>此外, 关于 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a>,  <code>index</code> 的值必须介于 <code>0</code> 和 <code>self.size(dim) - 1</code> (包括), 并且沿着指定维度<a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>的行中的所有值必须是唯一的.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的轴</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 需要 scatter 的元素的索引, 可以是空的，也可以与src大小相同。当为空时，操作返回恒等</li>
<li><strong>src</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – scatter 源</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-236-1" name="__codelineno-236-1" href="#__codelineno-236-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-236-2" name="__codelineno-236-2" href="#__codelineno-236-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<a id="__codelineno-236-3" name="__codelineno-236-3" href="#__codelineno-236-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.3992</span><span class="p">,</span>  <span class="mf">0.2908</span><span class="p">,</span>  <span class="mf">0.9044</span><span class="p">,</span>  <span class="mf">0.4850</span><span class="p">,</span>  <span class="mf">0.6004</span><span class="p">],</span>
<a id="__codelineno-236-4" name="__codelineno-236-4" href="#__codelineno-236-4"></a> <span class="p">[</span> <span class="mf">0.5735</span><span class="p">,</span>  <span class="mf">0.9006</span><span class="p">,</span>  <span class="mf">0.6797</span><span class="p">,</span>  <span class="mf">0.4152</span><span class="p">,</span>  <span class="mf">0.1732</span><span class="p">]])</span>
<a id="__codelineno-236-5" name="__codelineno-236-5" href="#__codelineno-236-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">x</span><span class="p">)</span>
<a id="__codelineno-236-6" name="__codelineno-236-6" href="#__codelineno-236-6"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.3992</span><span class="p">,</span>  <span class="mf">0.9006</span><span class="p">,</span>  <span class="mf">0.6797</span><span class="p">,</span>  <span class="mf">0.4850</span><span class="p">,</span>  <span class="mf">0.6004</span><span class="p">],</span>
<a id="__codelineno-236-7" name="__codelineno-236-7" href="#__codelineno-236-7"></a> <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.2908</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.4152</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
<a id="__codelineno-236-8" name="__codelineno-236-8" href="#__codelineno-236-8"></a> <span class="p">[</span> <span class="mf">0.5735</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.9044</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.1732</span><span class="p">]])</span>
<a id="__codelineno-236-9" name="__codelineno-236-9" href="#__codelineno-236-9"></a>
<a id="__codelineno-236-10" name="__codelineno-236-10" href="#__codelineno-236-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]),</span> <span class="mf">1.23</span><span class="p">)</span>
<a id="__codelineno-236-11" name="__codelineno-236-11" href="#__codelineno-236-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">z</span>
<a id="__codelineno-236-12" name="__codelineno-236-12" href="#__codelineno-236-12"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">1.2300</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">],</span>
<a id="__codelineno-236-13" name="__codelineno-236-13" href="#__codelineno-236-13"></a> <span class="p">[</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">0.0000</span><span class="p">,</span>  <span class="mf">1.2300</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-237-1" name="__codelineno-237-1" href="#__codelineno-237-1"></a><span class="n">scatter_add_</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>根据 <code>index</code> tensor 中指定的索引(方式和<a href="#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>scatter_()</code></a>类似), 将所有 tensor <code>other</code> 中的值加到<code>self</code> . 对于  <code>other</code> 中的每一个值, 当 <code>dimension != dim</code>, 它的输出的索引由 <code>other</code> 中的索引指定, 当 <code>dimension = dim</code>,  由 <code>index</code> 中对应的值指定.</p>
<p>对于一个 3-D tensor, <code>self</code> 的更新规则如下:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-238-1" name="__codelineno-238-1" href="#__codelineno-238-1"></a><span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">other</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>
<a id="__codelineno-238-2" name="__codelineno-238-2" href="#__codelineno-238-2"></a><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">other</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>
<a id="__codelineno-238-3" name="__codelineno-238-3" href="#__codelineno-238-3"></a><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span> <span class="o">+=</span> <span class="n">other</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 2</span>
</code></pre></div>
<p><code>self</code>, <code>index</code> and <code>other</code> 应该有相同数量的维度. 也要求 <code>index.size(d) &lt;= other.size(d)</code> 对于所有的维度 <code>d</code>, 并且 <code>index.size(d) &lt;= self.size(d)</code> 对于所有的维度 <code>d != dim</code>.</p>
<p>此外, 关于 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a>,  <code>index</code> 的值必须介于 <code>0</code> 和 <code>self.size(dim) - 1</code> (包括), 并且沿着指定维度<a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>的行中的所有值必须是唯一的.</p>
<p>注意</p>
<p>当使用 CUDA 作为后端, 这个操作将导致不确定性行为, 并且难以停止. 请参考 <a href="notes/randomness.html">Reproducibility</a> 获得相关背景.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要索引的轴</li>
<li><strong>index</strong> (<em>LongTensor</em>) – 需要 scatter add 的元素的索引, 可以是空的，也可以与src大小相同。当为空时，操作返回恒等</li>
<li><strong>src</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – scatter 源</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-239-1" name="__codelineno-239-1" href="#__codelineno-239-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a id="__codelineno-239-2" name="__codelineno-239-2" href="#__codelineno-239-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<a id="__codelineno-239-3" name="__codelineno-239-3" href="#__codelineno-239-3"></a><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.7404</span><span class="p">,</span> <span class="mf">0.0427</span><span class="p">,</span> <span class="mf">0.6480</span><span class="p">,</span> <span class="mf">0.3806</span><span class="p">,</span> <span class="mf">0.8328</span><span class="p">],</span>
<a id="__codelineno-239-4" name="__codelineno-239-4" href="#__codelineno-239-4"></a> <span class="p">[</span><span class="mf">0.7953</span><span class="p">,</span> <span class="mf">0.2009</span><span class="p">,</span> <span class="mf">0.9154</span><span class="p">,</span> <span class="mf">0.6782</span><span class="p">,</span> <span class="mf">0.9620</span><span class="p">]])</span>
<a id="__codelineno-239-5" name="__codelineno-239-5" href="#__codelineno-239-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">x</span><span class="p">)</span>
<a id="__codelineno-239-6" name="__codelineno-239-6" href="#__codelineno-239-6"></a><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.7404</span><span class="p">,</span> <span class="mf">1.2009</span><span class="p">,</span> <span class="mf">1.9154</span><span class="p">,</span> <span class="mf">1.3806</span><span class="p">,</span> <span class="mf">1.8328</span><span class="p">],</span>
<a id="__codelineno-239-7" name="__codelineno-239-7" href="#__codelineno-239-7"></a> <span class="p">[</span><span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.0427</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.6782</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">],</span>
<a id="__codelineno-239-8" name="__codelineno-239-8" href="#__codelineno-239-8"></a> <span class="p">[</span><span class="mf">1.7953</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.6480</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="mf">1.9620</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-240-1" name="__codelineno-240-1" href="#__codelineno-240-1"></a><span class="n">select</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>沿着选择的维度在给定的索引处切取 <code>self</code> tensor.这个函数返回的 tensor 指定的维度被移除了.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要切片的维度</li>
<li><strong>index</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 选择的索引</li>
</ul>
<p>注意</p>
<p><a href="#torch.Tensor.select" title="torch.Tensor.select"><code>select()</code></a> 等价于切片. 例如, <code>tensor.select(0, index)</code> 等价于 <code>tensor[index]</code> and <code>tensor.select(2, index)</code> 等价于 <code>tensor[:,:,index]</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-241-1" name="__codelineno-241-1" href="#__codelineno-241-1"></a><span class="n">set_</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">storage_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>设置底层存储, 大小, 和 strides. 如果 <code>source</code> 是一个 tensor, <code>self</code> tensor 将会和 <code>source</code> 共享底层存储, 并有用一样的大小和 strides. 在一个 tensor 中改变元素将会反应到另一个tensor.</p>
<p>如果 <code>source</code> 是一个 <code>Storage</code>, 此方法设置底层存储, offset, 大小, 和 stride.</p>
<p>参数: </p>
<ul>
<li><strong>source</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <em>Storage</em>) – 要设置的 tensor 或者 storage</li>
<li><strong>storage_offset</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>optional</em>) – storage 的 offset</li>
<li><strong>size</strong> (<em>torch.Size__,</em> <em>optional</em>) – 期望的大小.默认是 source 的大小.</li>
<li><strong>stride</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>,</em> <em>optional</em>) – 期望的 stride.默认值是 C-contiguous strides.</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-242-1" name="__codelineno-242-1" href="#__codelineno-242-1"></a><span class="n">share_memory_</span><span class="p">()</span>
</code></pre></div>
<p>移动底层存储到共享内存.</p>
<p>这是一个空操作如果底层存储已经在共享内存中或者是 CUDA tensors. 共享内存中的 tensor 不能 resize.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-243-1" name="__codelineno-243-1" href="#__codelineno-243-1"></a><span class="n">short</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self.short()</code> 等价于 <code>self.to(torch.int16)</code>. 见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-244-1" name="__codelineno-244-1" href="#__codelineno-244-1"></a><span class="n">sigmoid</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sigmoid" title="torch.sigmoid"><code>torch.sigmoid()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-245-1" name="__codelineno-245-1" href="#__codelineno-245-1"></a><span class="n">sigmoid_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>sigmoid()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-246-1" name="__codelineno-246-1" href="#__codelineno-246-1"></a><span class="n">sign</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sign" title="torch.sign"><code>torch.sign()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-247-1" name="__codelineno-247-1" href="#__codelineno-247-1"></a><span class="n">sign_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.sign" title="torch.Tensor.sign"><code>sign()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-248-1" name="__codelineno-248-1" href="#__codelineno-248-1"></a><span class="n">sin</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sin" title="torch.sin"><code>torch.sin()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-249-1" name="__codelineno-249-1" href="#__codelineno-249-1"></a><span class="n">sin_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.sin" title="torch.Tensor.sin"><code>sin()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-250-1" name="__codelineno-250-1" href="#__codelineno-250-1"></a><span class="n">sinh</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sinh" title="torch.sinh"><code>torch.sinh()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-251-1" name="__codelineno-251-1" href="#__codelineno-251-1"></a><span class="n">sinh_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>sinh()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-252-1" name="__codelineno-252-1" href="#__codelineno-252-1"></a><span class="n">size</span><span class="p">()</span> <span class="err">→</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>
</code></pre></div>
<p>返回 <code>self</code> tensor 的尺寸. 返回值是  [<code>tuple</code>] 的子类(https://docs.python.org/3/library/stdtypes.html#tuple "(in Python v3.7)").</p>
<p>例如:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-253-1" name="__codelineno-253-1" href="#__codelineno-253-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-253-2" name="__codelineno-253-2" href="#__codelineno-253-2"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-254-1" name="__codelineno-254-1" href="#__codelineno-254-1"></a><span class="n">slogdet</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-255-1" name="__codelineno-255-1" href="#__codelineno-255-1"></a><span class="n">sort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sort" title="torch.sort"><code>torch.sort()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-256-1" name="__codelineno-256-1" href="#__codelineno-256-1"></a><span class="n">split</span><span class="p">(</span><span class="n">split_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.split" title="torch.split"><code>torch.split()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-257-1" name="__codelineno-257-1" href="#__codelineno-257-1"></a><span class="n">sparse_mask</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用  <code>mask</code> 的索引过滤 Tensor <code>input</code>, 返回一个新的 SparseTensor. <code>input</code> 和 <code>mask</code> 必须有相同的形状.</p>
<p>参数: </p>
<ul>
<li><strong>input</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入 Tensor</li>
<li><strong>mask</strong> (<em>SparseTensor</em>) – SparseTensor 用其索引过滤 <code>input</code> </li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-258-1" name="__codelineno-258-1" href="#__codelineno-258-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nnz</span> <span class="o">=</span> <span class="mi">5</span>
<a id="__codelineno-258-2" name="__codelineno-258-2" href="#__codelineno-258-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-258-3" name="__codelineno-258-3" href="#__codelineno-258-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nnz</span><span class="p">,)),</span>
<a id="__codelineno-258-4" name="__codelineno-258-4" href="#__codelineno-258-4"></a> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nnz</span><span class="p">,))],</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">nnz</span><span class="p">)</span>
<a id="__codelineno-258-5" name="__codelineno-258-5" href="#__codelineno-258-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nnz</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-258-6" name="__codelineno-258-6" href="#__codelineno-258-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
<a id="__codelineno-258-7" name="__codelineno-258-7" href="#__codelineno-258-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">S</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span>
<a id="__codelineno-258-8" name="__codelineno-258-8" href="#__codelineno-258-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
<a id="__codelineno-258-9" name="__codelineno-258-9" href="#__codelineno-258-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">sparse_mask</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
<a id="__codelineno-258-10" name="__codelineno-258-10" href="#__codelineno-258-10"></a><span class="n">tensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<a id="__codelineno-258-11" name="__codelineno-258-11" href="#__codelineno-258-11"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span>
<a id="__codelineno-258-12" name="__codelineno-258-12" href="#__codelineno-258-12"></a> <span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[[</span> <span class="mf">1.6550</span><span class="p">,</span>  <span class="mf">0.2397</span><span class="p">],</span>
<a id="__codelineno-258-13" name="__codelineno-258-13" href="#__codelineno-258-13"></a> <span class="p">[</span><span class="o">-</span><span class="mf">0.1611</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0779</span><span class="p">]],</span>
<a id="__codelineno-258-14" name="__codelineno-258-14" href="#__codelineno-258-14"></a>
<a id="__codelineno-258-15" name="__codelineno-258-15" href="#__codelineno-258-15"></a> <span class="p">[[</span> <span class="mf">0.2326</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0558</span><span class="p">],</span>
<a id="__codelineno-258-16" name="__codelineno-258-16" href="#__codelineno-258-16"></a> <span class="p">[</span> <span class="mf">1.4711</span><span class="p">,</span>  <span class="mf">1.9678</span><span class="p">]],</span>
<a id="__codelineno-258-17" name="__codelineno-258-17" href="#__codelineno-258-17"></a>
<a id="__codelineno-258-18" name="__codelineno-258-18" href="#__codelineno-258-18"></a> <span class="p">[[</span><span class="o">-</span><span class="mf">0.5138</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0411</span><span class="p">],</span>
<a id="__codelineno-258-19" name="__codelineno-258-19" href="#__codelineno-258-19"></a> <span class="p">[</span> <span class="mf">1.9417</span><span class="p">,</span>  <span class="mf">0.5158</span><span class="p">]],</span>
<a id="__codelineno-258-20" name="__codelineno-258-20" href="#__codelineno-258-20"></a>
<a id="__codelineno-258-21" name="__codelineno-258-21" href="#__codelineno-258-21"></a> <span class="p">[[</span> <span class="mf">0.0793</span><span class="p">,</span>  <span class="mf">0.0036</span><span class="p">],</span>
<a id="__codelineno-258-22" name="__codelineno-258-22" href="#__codelineno-258-22"></a> <span class="p">[</span><span class="o">-</span><span class="mf">0.2569</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1055</span><span class="p">]]]),</span>
<a id="__codelineno-258-23" name="__codelineno-258-23" href="#__codelineno-258-23"></a> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nnz</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-259-1" name="__codelineno-259-1" href="#__codelineno-259-1"></a><span class="n">sqrt</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sqrt" title="torch.sqrt"><code>torch.sqrt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-260-1" name="__codelineno-260-1" href="#__codelineno-260-1"></a><span class="n">sqrt_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>sqrt()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-261-1" name="__codelineno-261-1" href="#__codelineno-261-1"></a><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-262-1" name="__codelineno-262-1" href="#__codelineno-262-1"></a><span class="n">squeeze_</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>squeeze()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-263-1" name="__codelineno-263-1" href="#__codelineno-263-1"></a><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.std" title="torch.std"><code>torch.std()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-264-1" name="__codelineno-264-1" href="#__codelineno-264-1"></a><span class="n">storage</span><span class="p">()</span> <span class="err">→</span> <span class="n">torch</span><span class="o">.</span><span class="n">Storage</span>
</code></pre></div>
<p>返回底层的 storage</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-265-1" name="__codelineno-265-1" href="#__codelineno-265-1"></a><span class="n">storage_offset</span><span class="p">()</span> <span class="err">→</span> <span class="nb">int</span>
</code></pre></div>
<p>根据存储元素的数量(而不是字节)，返回底层存储中的<code>tesor</code>偏移量(offset)。</p>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-266-1" name="__codelineno-266-1" href="#__codelineno-266-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<a id="__codelineno-266-2" name="__codelineno-266-2" href="#__codelineno-266-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">()</span>
<a id="__codelineno-266-3" name="__codelineno-266-3" href="#__codelineno-266-3"></a><span class="mi">0</span>
<a id="__codelineno-266-4" name="__codelineno-266-4" href="#__codelineno-266-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">()</span>
<a id="__codelineno-266-5" name="__codelineno-266-5" href="#__codelineno-266-5"></a><span class="mi">3</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-267-1" name="__codelineno-267-1" href="#__codelineno-267-1"></a><span class="n">storage_type</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-268-1" name="__codelineno-268-1" href="#__codelineno-268-1"></a><span class="n">stride</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="err">→</span> <span class="nb">tuple</span> <span class="ow">or</span> <span class="nb">int</span>
</code></pre></div>
<p>返回 <code>self</code> tensor 的 stride.</p>
<p>stride 是必要的用于在指定的维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 找到下一个元素. 如果传入空, 则返回一个 tuple 包含所有维度的 stride. 否则, 将会返回一个 int 表示指定维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 的 stride.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em> <em>optional</em>) – 需要返回 stride 的维度</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-269-1" name="__codelineno-269-1" href="#__codelineno-269-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<a id="__codelineno-269-2" name="__codelineno-269-2" href="#__codelineno-269-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">stride</span><span class="p">()</span>
<a id="__codelineno-269-3" name="__codelineno-269-3" href="#__codelineno-269-3"></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-269-4" name="__codelineno-269-4" href="#__codelineno-269-4"></a><span class="o">&gt;&gt;&gt;</span><span class="n">x</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-269-5" name="__codelineno-269-5" href="#__codelineno-269-5"></a><span class="mi">5</span>
<a id="__codelineno-269-6" name="__codelineno-269-6" href="#__codelineno-269-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-269-7" name="__codelineno-269-7" href="#__codelineno-269-7"></a><span class="mi">1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-270-1" name="__codelineno-270-1" href="#__codelineno-270-1"></a><span class="n">sub</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p><code>self</code> tensor 减去一个 scalar 或者 tensor. 如果 <code>value</code> 和 <code>other</code> 都被指定,  在相减之前, <code>other</code> 的每个元素将会用 <code>value</code> 缩放.</p>
<p>当 <code>other</code> 是一个 tensor,  <code>other</code> 的形状必须和底层存储是可广播的 <a href="notes/broadcasting.html#broadcasting-semantics">broadcastable</a> .</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-271-1" name="__codelineno-271-1" href="#__codelineno-271-1"></a><span class="n">sub_</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.sub" title="torch.Tensor.sub"><code>sub()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-272-1" name="__codelineno-272-1" href="#__codelineno-272-1"></a><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.sum" title="torch.sum"><code>torch.sum()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-273-1" name="__codelineno-273-1" href="#__codelineno-273-1"></a><span class="n">svd</span><span class="p">(</span><span class="n">some</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.svd" title="torch.svd"><code>torch.svd()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-274-1" name="__codelineno-274-1" href="#__codelineno-274-1"></a><span class="n">symeig</span><span class="p">(</span><span class="n">eigenvectors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.symeig" title="torch.symeig"><code>torch.symeig()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-275-1" name="__codelineno-275-1" href="#__codelineno-275-1"></a><span class="n">t</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.t" title="torch.t"><code>torch.t()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-276-1" name="__codelineno-276-1" href="#__codelineno-276-1"></a><span class="n">t_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.t" title="torch.Tensor.t"><code>t()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-277-1" name="__codelineno-277-1" href="#__codelineno-277-1"></a><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>执行 tensor 类型或者设备转换. <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 是从参数中推断的 <code>self.to(*args, **kwargs)</code>.</p>
<p>注意</p>
<p>如果 <code>self</code> Tensor 已经有正确的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, 则 <code>self</code> 被返回. 否则, 将返回复制的 <code>self</code> 期望的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>.</p>
<p>下面是调用的方法 <code>to</code>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-278-1" name="__codelineno-278-1" href="#__codelineno-278-1"></a><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个 Tensor 指定类型 <code>dtype</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-279-1" name="__codelineno-279-1" href="#__codelineno-279-1"></a><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个 Tensor 并指定 <a href="#torch.Tensor.device" title="torch.Tensor.device"><code>device</code></a> 和 (可选的) <code>dtype</code>. 如果 <code>dtype</code> 是 <code>None</code> 则推断为 <code>self.dtype</code> . 当启用 <code>non_blocking</code>, 试图在主机上执行异步转换, 例如, 转换一个 pinned memory 的 CPU Tensor 到 CUDA Tensor. 当 <code>copy</code> 被设置, 一个新的 tensor 被创建.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-280-1" name="__codelineno-280-1" href="#__codelineno-280-1"></a><span class="n">to</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个 Tensor 并有和 Tensor <code>other</code> 相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>. 当启用 <code>non_blocking</code>, 试图在主机上执行异步转换, 例如, 转换一个 pinned memory 的 CPU Tensor 到 CUDA Tensor. 当 <code>copy</code> 被设置, 一个新的 tensor 被创建.</p>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-281-1" name="__codelineno-281-1" href="#__codelineno-281-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Initially dtype=float32, device=cpu</span>
<a id="__codelineno-281-2" name="__codelineno-281-2" href="#__codelineno-281-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a id="__codelineno-281-3" name="__codelineno-281-3" href="#__codelineno-281-3"></a><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
<a id="__codelineno-281-4" name="__codelineno-281-4" href="#__codelineno-281-4"></a> <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a id="__codelineno-281-5" name="__codelineno-281-5" href="#__codelineno-281-5"></a>
<a id="__codelineno-281-6" name="__codelineno-281-6" href="#__codelineno-281-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">cuda0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<a id="__codelineno-281-7" name="__codelineno-281-7" href="#__codelineno-281-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cuda0</span><span class="p">)</span>
<a id="__codelineno-281-8" name="__codelineno-281-8" href="#__codelineno-281-8"></a><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
<a id="__codelineno-281-9" name="__codelineno-281-9" href="#__codelineno-281-9"></a> <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<a id="__codelineno-281-10" name="__codelineno-281-10" href="#__codelineno-281-10"></a>
<a id="__codelineno-281-11" name="__codelineno-281-11" href="#__codelineno-281-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cuda0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a id="__codelineno-281-12" name="__codelineno-281-12" href="#__codelineno-281-12"></a><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
<a id="__codelineno-281-13" name="__codelineno-281-13" href="#__codelineno-281-13"></a> <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<a id="__codelineno-281-14" name="__codelineno-281-14" href="#__codelineno-281-14"></a>
<a id="__codelineno-281-15" name="__codelineno-281-15" href="#__codelineno-281-15"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">other</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda0</span><span class="p">)</span>
<a id="__codelineno-281-16" name="__codelineno-281-16" href="#__codelineno-281-16"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-281-17" name="__codelineno-281-17" href="#__codelineno-281-17"></a><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.5044</span><span class="p">,</span>  <span class="mf">0.0005</span><span class="p">],</span>
<a id="__codelineno-281-18" name="__codelineno-281-18" href="#__codelineno-281-18"></a> <span class="p">[</span> <span class="mf">0.3310</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0584</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-282-1" name="__codelineno-282-1" href="#__codelineno-282-1"></a><span class="n">take</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.take" title="torch.take"><code>torch.take()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-283-1" name="__codelineno-283-1" href="#__codelineno-283-1"></a><span class="n">tan</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-284-1" name="__codelineno-284-1" href="#__codelineno-284-1"></a><span class="n">tan_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.tan" title="torch.Tensor.tan"><code>tan()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-285-1" name="__codelineno-285-1" href="#__codelineno-285-1"></a><span class="n">tanh</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.tanh" title="torch.tanh"><code>torch.tanh()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-286-1" name="__codelineno-286-1" href="#__codelineno-286-1"></a><span class="n">tanh_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>tanh()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-287-1" name="__codelineno-287-1" href="#__codelineno-287-1"></a><span class="n">tolist</span><span class="p">()</span>
</code></pre></div>
<p>” tolist() -&gt; list or number</p>
<p>返回tensor 作为(嵌套的) list. 对于 scalars,一个标准的 Python number 被返回, 就像 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>item()</code></a> 一样. Tensors 会自动移动到 CPU 上如果有必要.</p>
<p>这个操作是不可微分的.</p>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-288-1" name="__codelineno-288-1" href="#__codelineno-288-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-288-2" name="__codelineno-288-2" href="#__codelineno-288-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<a id="__codelineno-288-3" name="__codelineno-288-3" href="#__codelineno-288-3"></a><span class="p">[[</span><span class="mf">0.012766935862600803</span><span class="p">,</span> <span class="mf">0.5415473580360413</span><span class="p">],</span>
<a id="__codelineno-288-4" name="__codelineno-288-4" href="#__codelineno-288-4"></a> <span class="p">[</span><span class="o">-</span><span class="mf">0.08909505605697632</span><span class="p">,</span> <span class="mf">0.7729271650314331</span><span class="p">]]</span>
<a id="__codelineno-288-5" name="__codelineno-288-5" href="#__codelineno-288-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<a id="__codelineno-288-6" name="__codelineno-288-6" href="#__codelineno-288-6"></a><span class="mf">0.012766935862600803</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-289-1" name="__codelineno-289-1" href="#__codelineno-289-1"></a><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.topk" title="torch.topk"><code>torch.topk()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-290-1" name="__codelineno-290-1" href="#__codelineno-290-1"></a><span class="n">to_sparse</span><span class="p">(</span><span class="n">sparseDims</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个稀疏复制的 tensor. PyTorch 支持 <a href="sparse.html#sparse-docs">coordinate 格式</a> 的稀疏 tensors. :param sparseDims: 要包含在新稀疏tensor中的稀疏维数 :type sparseDims: int, 可选的</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-291-1" name="__codelineno-291-1" href="#__codelineno-291-1"></a><span class="n">例子</span><span class="p">::</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-292-1" name="__codelineno-292-1" href="#__codelineno-292-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<a id="__codelineno-292-2" name="__codelineno-292-2" href="#__codelineno-292-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">d</span>
<a id="__codelineno-292-3" name="__codelineno-292-3" href="#__codelineno-292-3"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
<a id="__codelineno-292-4" name="__codelineno-292-4" href="#__codelineno-292-4"></a> <span class="p">[</span> <span class="mi">9</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
<a id="__codelineno-292-5" name="__codelineno-292-5" href="#__codelineno-292-5"></a> <span class="p">[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">0</span><span class="p">]])</span>
<a id="__codelineno-292-6" name="__codelineno-292-6" href="#__codelineno-292-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">d</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
<a id="__codelineno-292-7" name="__codelineno-292-7" href="#__codelineno-292-7"></a><span class="n">tensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-292-8" name="__codelineno-292-8" href="#__codelineno-292-8"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span>
<a id="__codelineno-292-9" name="__codelineno-292-9" href="#__codelineno-292-9"></a> <span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span>
<a id="__codelineno-292-10" name="__codelineno-292-10" href="#__codelineno-292-10"></a> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nnz</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">)</span>
<a id="__codelineno-292-11" name="__codelineno-292-11" href="#__codelineno-292-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">d</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-292-12" name="__codelineno-292-12" href="#__codelineno-292-12"></a><span class="n">tensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]]),</span>
<a id="__codelineno-292-13" name="__codelineno-292-13" href="#__codelineno-292-13"></a> <span class="n">values</span><span class="o">=</span><span class="n">tensor</span><span class="p">([[</span> <span class="mi">9</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]]),</span>
<a id="__codelineno-292-14" name="__codelineno-292-14" href="#__codelineno-292-14"></a> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nnz</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-293-1" name="__codelineno-293-1" href="#__codelineno-293-1"></a><span class="n">trace</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.trace" title="torch.trace"><code>torch.trace()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-294-1" name="__codelineno-294-1" href="#__codelineno-294-1"></a><span class="n">transpose</span><span class="p">(</span><span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-295-1" name="__codelineno-295-1" href="#__codelineno-295-1"></a><span class="n">transpose_</span><span class="p">(</span><span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>transpose()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-296-1" name="__codelineno-296-1" href="#__codelineno-296-1"></a><span class="n">tril</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.tril" title="torch.tril"><code>torch.tril()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-297-1" name="__codelineno-297-1" href="#__codelineno-297-1"></a><span class="n">tril_</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.tril" title="torch.Tensor.tril"><code>tril()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-298-1" name="__codelineno-298-1" href="#__codelineno-298-1"></a><span class="n">triu</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.triu" title="torch.triu"><code>torch.triu()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-299-1" name="__codelineno-299-1" href="#__codelineno-299-1"></a><span class="n">triu_</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.triu" title="torch.Tensor.triu"><code>triu()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-300-1" name="__codelineno-300-1" href="#__codelineno-300-1"></a><span class="n">trtrs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unitriangular</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.trtrs" title="torch.trtrs"><code>torch.trtrs()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-301-1" name="__codelineno-301-1" href="#__codelineno-301-1"></a><span class="n">trunc</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-302-1" name="__codelineno-302-1" href="#__codelineno-302-1"></a><span class="n">trunc_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>trunc()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-303-1" name="__codelineno-303-1" href="#__codelineno-303-1"></a><span class="nb">type</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="err">→</span> <span class="nb">str</span> <span class="ow">or</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回 type 如果 <code>dtype</code> 没有被设置, 否则将会强制转换成 <code>dtype</code> 类型.</p>
<p>如果这已经是正确的类型，则不执行复制，并返回原始对象.</p>
<p>参数: </p>
<ul>
<li><strong>dtype</strong> (<a href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)"><em>type</em></a> <em>or</em> <em>string</em>) – 期望类型</li>
<li><strong>non_blocking</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) –  如果 <code>True</code>，并且源在pinned memory中，目的地在GPU上，则拷贝相对于主机异步执行。否则，这个参数没有任何作用。</li>
<li><strong>**kwargs</strong> – 为了兼容性, 可能包含 <code>async</code> 用来置换 <code>non_blocking</code> 参数.  <code>async</code> 参数被废弃了.</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-304-1" name="__codelineno-304-1" href="#__codelineno-304-1"></a><span class="n">type_as</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回 tensor 强制转换为 tensor 的数据类型.</p>
<p>如果这已经是正确的类型，则是空操作. 等价于:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-305-1" name="__codelineno-305-1" href="#__codelineno-305-1"></a><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">type</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-306-1" name="__codelineno-306-1" href="#__codelineno-306-1"></a><span class="n">Params</span><span class="p">:</span>
</code></pre></div>
<p>tensor (Tensor): 拥有目标数据类型的 tensor</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-307-1" name="__codelineno-307-1" href="#__codelineno-307-1"></a><span class="n">unfold</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个 tensor 包含 <code>self</code> tensor 在维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 上的所有切片, 每一个的大小为 size.</p>
<p><code>step</code> 指定每一个切片的间距.</p>
<p>如果 <code>sizedim</code> 是 <code>self</code> dim 维度的大小, 返回的 tensor 的维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 大小是 <code>(sizedim - size) / step + 1</code>.</p>
<p>一个附加的size size的维度追加于返回的 tensor.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定 unfold 的维度</li>
<li><strong>size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定每个slice的大小</li>
<li><strong>step</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 指定步长</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-308-1" name="__codelineno-308-1" href="#__codelineno-308-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<a id="__codelineno-308-2" name="__codelineno-308-2" href="#__codelineno-308-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span>
<a id="__codelineno-308-3" name="__codelineno-308-3" href="#__codelineno-308-3"></a><span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">])</span>
<a id="__codelineno-308-4" name="__codelineno-308-4" href="#__codelineno-308-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-308-5" name="__codelineno-308-5" href="#__codelineno-308-5"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<a id="__codelineno-308-6" name="__codelineno-308-6" href="#__codelineno-308-6"></a> <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
<a id="__codelineno-308-7" name="__codelineno-308-7" href="#__codelineno-308-7"></a> <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
<a id="__codelineno-308-8" name="__codelineno-308-8" href="#__codelineno-308-8"></a> <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">],</span>
<a id="__codelineno-308-9" name="__codelineno-308-9" href="#__codelineno-308-9"></a> <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
<a id="__codelineno-308-10" name="__codelineno-308-10" href="#__codelineno-308-10"></a> <span class="p">[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">]])</span>
<a id="__codelineno-308-11" name="__codelineno-308-11" href="#__codelineno-308-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-308-12" name="__codelineno-308-12" href="#__codelineno-308-12"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<a id="__codelineno-308-13" name="__codelineno-308-13" href="#__codelineno-308-13"></a> <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
<a id="__codelineno-308-14" name="__codelineno-308-14" href="#__codelineno-308-14"></a> <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-309-1" name="__codelineno-309-1" href="#__codelineno-309-1"></a><span class="n">uniform_</span><span class="p">(</span><span class="n">from</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用连续均匀分布的采样值填充 <code>self</code> tensor:</p>
<p><img alt="" src="../img/759db301c6ca0348b6d47aaeac0a6b23.jpg" /></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-310-1" name="__codelineno-310-1" href="#__codelineno-310-1"></a><span class="n">unique</span><span class="p">(</span><span class="nb">sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<p>返回 tensor 中唯一的标量作为 1-D tensor.</p>
<p>见 <a href="torch.html#torch.unique" title="torch.unique"><code>torch.unique()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-311-1" name="__codelineno-311-1" href="#__codelineno-311-1"></a><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.unsqueeze" title="torch.unsqueeze"><code>torch.unsqueeze()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-312-1" name="__codelineno-312-1" href="#__codelineno-312-1"></a><span class="n">unsqueeze_</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>原地版本的 <a href="#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>unsqueeze()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-313-1" name="__codelineno-313-1" href="#__codelineno-313-1"></a><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>见 <a href="torch.html#torch.var" title="torch.var"><code>torch.var()</code></a></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-314-1" name="__codelineno-314-1" href="#__codelineno-314-1"></a><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回一个新的 tersor, 和 <code>self</code> 有相同的数据, 但是有不同的 <code>shape</code>.</p>
<p>返回的 tensor 共享相同的数据，并且具有相同数量的元素，但是可能有不同的大小。要 <code>view()</code> 一个tensor，新视图大小必须与其原始大小和 stride 兼容, 例如, 每个新视图维度必须是原始维度的子空间，或者仅跨越原始维度 <img alt="" src="../img/3e487bf64409a04d51b45d9f7de99192.jpg" /> 满足以下连续性条件 <img alt="" src="../img/286a7af66db16ee513cef761bb621504.jpg" />,</p>
<p><img alt="" src="../img/b7a97800576bc71106c2607bb5f1eb37.jpg" /></p>
<p>否则在 <code>view()</code> 之前, <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a> 需要被调用. 可参考: <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a>, 返回一个view 当形状是兼容的, 否则复制 (等价于调用 <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a>).</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>shape</strong> (<em>torch.Size</em> <em>or</em> <em>int...</em>) – the desired size</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-315-1" name="__codelineno-315-1" href="#__codelineno-315-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-315-2" name="__codelineno-315-2" href="#__codelineno-315-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-315-3" name="__codelineno-315-3" href="#__codelineno-315-3"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<a id="__codelineno-315-4" name="__codelineno-315-4" href="#__codelineno-315-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
<a id="__codelineno-315-5" name="__codelineno-315-5" href="#__codelineno-315-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-315-6" name="__codelineno-315-6" href="#__codelineno-315-6"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">16</span><span class="p">])</span>
<a id="__codelineno-315-7" name="__codelineno-315-7" href="#__codelineno-315-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># the size -1 is inferred from other dimensions</span>
<a id="__codelineno-315-8" name="__codelineno-315-8" href="#__codelineno-315-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">z</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-315-9" name="__codelineno-315-9" href="#__codelineno-315-9"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-316-1" name="__codelineno-316-1" href="#__codelineno-316-1"></a><span class="n">view_as</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>使用 <code>other</code> 的大小 View tensor . <code>self.view_as(other)</code> 等价于 <code>self.view(other.size())</code>.</p>
<p>请参考 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a> 获得更多信息关于 <code>view</code>.</p>
<table>
<thead>
<tr>
<th>参数:</th>
<th><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – 返回的tensor 和 <code>other</code> 大小相同.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><a id="__codelineno-317-1" name="__codelineno-317-1" href="#__codelineno-317-1"></a><span class="n">zero_</span><span class="p">()</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>用 0 填充 <code>self</code> tensor.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-318-1" name="__codelineno-318-1" href="#__codelineno-318-1"></a><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">ByteTensor</span>
</code></pre></div>
<p>下面的方法是 <a href="#torch.ByteTensor" title="torch.ByteTensor"><code>torch.ByteTensor</code></a> 独占.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-319-1" name="__codelineno-319-1" href="#__codelineno-319-1"></a><span class="nb">all</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-320-1" name="__codelineno-320-1" href="#__codelineno-320-1"></a><span class="nb">all</span><span class="p">()</span> <span class="err">→</span> <span class="nb">bool</span>
</code></pre></div>
<p>返回 True 如果所有的元素非零, 否则 False.</p>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-321-1" name="__codelineno-321-1" href="#__codelineno-321-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span>
<a id="__codelineno-321-2" name="__codelineno-321-2" href="#__codelineno-321-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<a id="__codelineno-321-3" name="__codelineno-321-3" href="#__codelineno-321-3"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<a id="__codelineno-321-4" name="__codelineno-321-4" href="#__codelineno-321-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<a id="__codelineno-321-5" name="__codelineno-321-5" href="#__codelineno-321-5"></a><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-322-1" name="__codelineno-322-1" href="#__codelineno-322-1"></a><span class="nb">all</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回 True 如果 tensor 在指定维度<code>dim</code>每一行的所有的元素非零, 否则 False.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 则输出 tensor 的大小与 <code>input</code>相同, 但尺寸为1的维度<code>dim</code>除外. 否则, <code>dim</code> 会被压缩 (见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), 导致输出张量比<code>input</code>少1维.</p>
<p>Parameters: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要reduce的维度</li>
<li><strong>keepdim</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – output tensor 是否保留 <code>dim</code> </li>
<li><strong>out</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – output tensor</li>
</ul>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-323-1" name="__codelineno-323-1" href="#__codelineno-323-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span>
<a id="__codelineno-323-2" name="__codelineno-323-2" href="#__codelineno-323-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<a id="__codelineno-323-3" name="__codelineno-323-3" href="#__codelineno-323-3"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<a id="__codelineno-323-4" name="__codelineno-323-4" href="#__codelineno-323-4"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<a id="__codelineno-323-5" name="__codelineno-323-5" href="#__codelineno-323-5"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-323-6" name="__codelineno-323-6" href="#__codelineno-323-6"></a> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<a id="__codelineno-323-7" name="__codelineno-323-7" href="#__codelineno-323-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-323-8" name="__codelineno-323-8" href="#__codelineno-323-8"></a><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-324-1" name="__codelineno-324-1" href="#__codelineno-324-1"></a><span class="nb">any</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-325-1" name="__codelineno-325-1" href="#__codelineno-325-1"></a><span class="nb">any</span><span class="p">()</span> <span class="err">→</span> <span class="nb">bool</span>
</code></pre></div>
<p>返回 True 如果任意元素非零, 否则 False.</p>
<p>例子:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-326-1" name="__codelineno-326-1" href="#__codelineno-326-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span>
<a id="__codelineno-326-2" name="__codelineno-326-2" href="#__codelineno-326-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<a id="__codelineno-326-3" name="__codelineno-326-3" href="#__codelineno-326-3"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<a id="__codelineno-326-4" name="__codelineno-326-4" href="#__codelineno-326-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
<a id="__codelineno-326-5" name="__codelineno-326-5" href="#__codelineno-326-5"></a><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-327-1" name="__codelineno-327-1" href="#__codelineno-327-1"></a><span class="nb">any</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div>
<p>返回 True 如果 tensor 在指定维度<code>dim</code>每一行的任意的元素非零, 否则 False.</p>
<p>如果 <code>keepdim</code> 是 <code>True</code>, 则输出 tensor 的大小与 <code>input</code>相同, 但尺寸为1的维度<code>dim</code>除外. 否则, <code>dim</code> 会被压缩 (见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), 导致输出张量比<code>input</code>少1维.</p>
<p>参数: </p>
<ul>
<li><strong>dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – 要减少的维度</li>
<li><strong>keepdim</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – output tensor 是否保留 <code>dim</code> </li>
<li><strong>out</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>可选的</em>) – output tensor</li>
</ul>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-328-1" name="__codelineno-328-1" href="#__codelineno-328-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span>
<a id="__codelineno-328-2" name="__codelineno-328-2" href="#__codelineno-328-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<a id="__codelineno-328-3" name="__codelineno-328-3" href="#__codelineno-328-3"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<a id="__codelineno-328-4" name="__codelineno-328-4" href="#__codelineno-328-4"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<a id="__codelineno-328-5" name="__codelineno-328-5" href="#__codelineno-328-5"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-328-6" name="__codelineno-328-6" href="#__codelineno-328-6"></a> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<a id="__codelineno-328-7" name="__codelineno-328-7" href="#__codelineno-328-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-328-8" name="__codelineno-328-8" href="#__codelineno-328-8"></a><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../torch_math_operations_blas_lapack_ops/" class="md-footer__link md-footer__link--prev" aria-label="Previous: BLAS and LAPACK Operations">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                BLAS and LAPACK Operations
              </div>
            </div>
          </a>
        
        
          
          <a href="../tensor_attributes/" class="md-footer__link md-footer__link--next" aria-label="Next: Tensor Attributes">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Tensor Attributes
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>