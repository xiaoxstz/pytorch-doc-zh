
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/1.4/77/">
      
      
        <link rel="prev" href="../76/">
      
      
        <link rel="next" href="../78/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.0">
    
    
      
        <title>torch张量 - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.45e1311d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              torch张量
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" >
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/introyt/captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Modeling with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.compile Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial%23using-sdpa-with-torch-compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using SDPA with torch.compile
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/scaled_dot_product_attention_tutorial%23conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Mobile
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Mobile
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deeplabv3_on_ios/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on iOS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/deeplabv3_on_android/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on Android
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/tutorials/beginner/flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2.0/docs/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.7 中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    学习 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            学习 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 深度学习：60 分钟的突击
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 深度学习：60 分钟的突击
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/02/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/03/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/04/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.autograd的简要介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/05/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/06/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1_2" >
        
          
          <label class="md-nav__link" for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    通过示例学习 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_2">
            <span class="md-nav__icon md-icon"></span>
            通过示例学习 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/07/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/08/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    热身：NumPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/09/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：张量和 Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：定义新的 Autograd 函数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/14/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：自定义nn模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/15/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch：控制流 - 权重共享
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/16/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn到底是什么？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TensorBoard 可视化模型，数据和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图片/视频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            图片/视频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/19/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision对象检测微调教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉的迁移学习教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/21/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            音频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/24/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    音频 I/O 和torchaudio的预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/25/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用torchaudio的语音命令识别
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/27/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用nn.Transformer和torchtext的序列到序列建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/28/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用字符级 RNN 分类名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用字符级 RNN 生成名称
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从零开始的 NLP：使用序列到序列网络和注意力的翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用torchtext的文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext语言翻译
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/34/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习（DQN）教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/35/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练玩马里奥的 RL 智能体
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" >
        
          
          <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    在生产中部署 PyTorch 模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            在生产中部署 PyTorch 模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/37/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过使用 Flask 的 REST API 在 Python 中部署 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/38/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/39/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中加载 TorchScript 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/40/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将模型从 PyTorch 导出到 ONNX 并使用 ONNX 运行时运行它（可选）
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_7" >
        
          
          <label class="md-nav__link" for="__nav_4_7" id="__nav_4_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    前端 API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_7">
            <span class="md-nav__icon md-icon"></span>
            前端 API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/42/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中的命名张量简介（原型）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/43/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中通道在最后的内存格式（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/44/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C++ 前端
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/45/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自定义 C++ 和 CUDA 扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/46/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C++ 运算符扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/47/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C++ 类扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/48/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 中的动态并行性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/49/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++ 前端中的 Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中注册调度运算符
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_8" >
        
          
          <label class="md-nav__link" for="__nav_4_8" id="__nav_4_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型优化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_8">
            <span class="md-nav__icon md-icon"></span>
            模型优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/52/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分析您的 PyTorch 模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/53/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Ray Tune 的超参数调整
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/54/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    模型剪裁教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/55/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM 单词语言模型上的动态量化（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/56/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERT 上的动态量化（Beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/57/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中使用 Eager 模式的静态量化（beta）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/58/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算机视觉的量化迁移学习教程（beta）
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_9" >
        
          
          <label class="md-nav__link" for="__nav_4_9" id="__nav_4_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    并行和分布式训练
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_9">
            <span class="md-nav__icon md-icon"></span>
            并行和分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/60/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 分布式概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/61/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    单机模型并行最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/62/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式数据并行入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/63/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 PyTorch 编写分布式应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/64/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/65/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用分布式 RPC 框架实现参数服务器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/66/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 RPC 的分布式管道并行化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/67/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用异步执行实现批量 RPC 处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.7/68/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将分布式DataParallel与分布式 RPC 框架相结合
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.4 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1_1" id="__nav_5_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    使用 PyTorch 进行深度学习：60 分钟的闪电战
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_1">
            <span class="md-nav__icon md-icon"></span>
            使用 PyTorch 进行深度学习：60 分钟的闪电战
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/tensor_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    什么是PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/autograd_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd：自动求导
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/neural_networks_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/cifar10_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blitz/data_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    可选：数据并行
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    编写自定义数据集，数据加载器和转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TensorBoard 可视化模型，数据和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图片
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            图片
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision 对象检测微调教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    转移学习的计算机视觉教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空间变压器网络教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行神经传递
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            音频
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio 教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 使用char-RNN对姓氏进行分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 生成名称与字符级RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TorchText 进行文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 TorchText 进行语言翻译
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 nn.Transformer 和 TorchText 进行序列到序列建模
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    命名为 Tensor(实验性）
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            命名为 Tensor(实验性）
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../24/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性)PyTorch 中的命名张量简介
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" >
        
          
          <label class="md-nav__link" for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../26/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习(DQN)教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          <label class="md-nav__link" for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    在生产中部署 PyTorch 模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            在生产中部署 PyTorch 模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../28/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过带有 Flask 的 REST API 在 Python 中部署 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchScript 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../30/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C --中加载 TorchScript 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_8" >
        
          
          <label class="md-nav__link" for="__nav_5_8" id="__nav_5_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    并行和分布式训练
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_8">
            <span class="md-nav__icon md-icon"></span>
            并行和分布式训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../33/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    单机模型并行最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../34/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式数据并行入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../35/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 PyTorch 编写分布式应用程序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../36/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../37/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" >
        
          
          <label class="md-nav__link" for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            扩展 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../39/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C --运算符扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../40/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用自定义 C --类扩展 TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../41/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 numpy 和 scipy 创建扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../42/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自定义 C --和 CUDA 扩展
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_10" >
        
          
          <label class="md-nav__link" for="__nav_5_10" id="__nav_5_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    模型优化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_10">
            <span class="md-nav__icon md-icon"></span>
            模型优化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../44/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM Word 语言模型上的(实验）动态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../45/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性）在 PyTorch 中使用 Eager 模式进行静态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../46/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验性）计算机视觉教程的量化转移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../47/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (实验）BERT 上的动态量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../48/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    修剪教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_11" >
        
          
          <label class="md-nav__link" for="__nav_5_11" id="__nav_5_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 用其他语言
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_11">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 用其他语言
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C --前端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_12" >
        
          
          <label class="md-nav__link" for="__nav_5_12" id="__nav_5_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 基础知识
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_12">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 基础知识
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../52/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过示例学习 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../53/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn 到底是什么？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_13" >
        
          
          <label class="md-nav__link" for="__nav_5_13" id="__nav_5_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_13">
            <span class="md-nav__icon md-icon"></span>
            笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../56/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动求导机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../57/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    广播语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../58/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 线程和 TorchScript 推断
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../59/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA 语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../60/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 Autograd 设计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../61/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../62/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    经常问的问题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../63/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模部署的功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../64/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    并行处理最佳实践
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../65/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    重现性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../66/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    远程参考协议
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../67/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列化语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../68/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows 常见问题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../69/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XLA 设备上的 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_14" >
        
          
          <label class="md-nav__link" for="__nav_5_14" id="__nav_5_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    语言绑定
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_14">
            <span class="md-nav__icon md-icon"></span>
            语言绑定
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../71/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch C -- API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../72/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Java API
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_15" checked>
        
          
          <label class="md-nav__link" for="__nav_5_15" id="__nav_5_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_15_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_15">
            <span class="md-nav__icon md-icon"></span>
            Python API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../74/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../75/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../76/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    torch张量
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../78/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    张量属性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../79/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动差分包-Torch.Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../81/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式通讯包-Torch.Distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../82/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    概率分布-torch分布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../84/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch脚本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../86/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../87/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../88/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    分布式 RPC 框架
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch随机
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../91/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch稀疏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../92/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch存储
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../93/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../94/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../96/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../98/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../99/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    类型信息
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../101/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名张量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../102/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    命名为 Tensors 操作员范围
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../103/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    糟糕！
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_16" >
        
          
          <label class="md-nav__link" for="__nav_5_16" id="__nav_5_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchvision参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_16">
            <span class="md-nav__icon md-icon"></span>
            torchvision参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../105/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_17" >
        
          
          <label class="md-nav__link" for="__nav_5_17" id="__nav_5_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    音频参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_17">
            <span class="md-nav__icon md-icon"></span>
            音频参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../107/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_18" >
        
          
          <label class="md-nav__link" for="__nav_5_18" id="__nav_5_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchtext参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_18">
            <span class="md-nav__icon md-icon"></span>
            torchtext参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../109/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_19" >
        
          
          <label class="md-nav__link" for="__nav_5_19" id="__nav_5_19_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    社区
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_19">
            <span class="md-nav__icon md-icon"></span>
            社区
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../111/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 贡献指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../112/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 治理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../113/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 治理| 感兴趣的人
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 1.0 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1" id="__nav_6_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1">
            <span class="md-nav__icon md-icon"></span>
            入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1_1" id="__nav_6_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 深度学习: 60 分钟极速入门
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 深度学习: 60 分钟极速入门
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_tensor_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    什么是 PyTorch？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_autograd_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd：自动求导
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_neural_networks_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_cifar10_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练分类器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/blitz_data_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    可选：数据并行处理
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/data_loading_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据加载和处理教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用例子学习 PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deploy_seq2seq_hybrid_frontend_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合前端的 seq2seq 模型部署
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/saving_loading_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving and Loading Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2_2" id="__nav_6_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图像
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_2">
            <span class="md-nav__icon md-icon"></span>
            图像
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/finetuning_torchvision_models_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torchvision 模型微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空间变换器网络教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/neural_style_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行图像风格转换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对抗性示例生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/super_resolution_with_caffe2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3" id="__nav_6_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    文本
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3">
            <span class="md-nav__icon md-icon"></span>
            文本
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/chatbot_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天机器人教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用字符级别特征的 RNN 网络生成姓氏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用字符级别特征的 RNN 网络进行姓氏分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3_4" id="__nav_6_2_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deep Learning for NLP with Pytorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            Deep Learning for NLP with Pytorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/deep_learning_nlp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在深度学习和 NLP 中使用 Pytorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_pytorch_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_deep_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 进行深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_word_embeddings_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Word Embeddings: Encoding Lexical Semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_sequence_models_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    序列模型和 LSTM 网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nlp_advanced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于注意力机制的 seq2seq 神经网络翻译
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_4" id="__nav_6_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    生成
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_4">
            <span class="md-nav__icon md-icon"></span>
            生成
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_5" >
        
          
          <label class="md-nav__link" for="__nav_6_2_5" id="__nav_6_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_5">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_6" >
        
          
          <label class="md-nav__link" for="__nav_6_2_6" id="__nav_6_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩展 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_6">
            <span class="md-nav__icon md-icon"></span>
            扩展 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/numpy_extensions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 numpy 和 scipy 创建扩展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_7" >
        
          
          <label class="md-nav__link" for="__nav_6_2_7" id="__nav_6_2_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    生产性使用
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_7">
            <span class="md-nav__icon md-icon"></span>
            生产性使用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/aws_distributed_training_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Amazon AWS 进行分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/ONNXLive/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ONNX 现场演示教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 C++ 中加载 PYTORCH 模型
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_8" >
        
          
          <label class="md-nav__link" for="__nav_6_2_8" id="__nav_6_2_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其它语言中的 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_8">
            <span class="md-nav__icon md-icon"></span>
            其它语言中的 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch C++ 前端
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_1" >
        
          
          <label class="md-nav__link" for="__nav_6_3_1" id="__nav_6_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    注解
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_1">
            <span class="md-nav__icon md-icon"></span>
            注解
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    自动求导机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_broadcasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    广播语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA 语义
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_extending/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multiprocessing best practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_randomness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reproducibility
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_serialization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/notes_windows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2" id="__nav_6_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    包参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2">
            <span class="md-nav__icon md-icon"></span>
            包参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2_1" id="__nav_6_3_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_3_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2_1">
            <span class="md-nav__icon md-icon"></span>
            torch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_tensors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_random_sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Random sampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_serialization_parallelism_utilities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization, Parallelism, Utilities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_6_3_2_1_5" id="__nav_6_3_2_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Math operations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_6_3_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            Math operations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_pointwise_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pointwise Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_reduction_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reduction Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_comparison_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Comparison Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_spectral_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spectral Ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_other_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Other Operations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torch_math_operations_blas_lapack_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BLAS and LAPACK Operations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/tensors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Tensor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/tensor_attributes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor Attributes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/type_info/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据类型信息
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/sparse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_functional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/nn_init/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic differentiation package - torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed communication package - torch.distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability distributions - torch.distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/jit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Torch Script
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多进程包 - torch.multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/bottleneck/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/checkpoint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/docs_cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/dlpack/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/hub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/model_zoo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/distributed_deprecated/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed communication package (deprecated) - torch.distributed.deprecated
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3_3" id="__nav_6_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torchvision 参考
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3_3">
            <span class="md-nav__icon md-icon"></span>
            torchvision 参考
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/docs_torchvision_ref/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1.0/torchvision_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision.utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/1.4/77.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/1.4/77.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<h1 id="torch">torch张量</h1>
<blockquote>
<p>原文： <a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a></p>
</blockquote>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是包含单个数据类型元素的多维矩阵。</p>
<p>Torch 定义了 9 种 CPU 张量类型和 9 种 GPU 张量类型：</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>dtype</th>
<th>CPU 张量</th>
<th>GPU 张量</th>
</tr>
</thead>
<tbody>
<tr>
<td>32 位浮点</td>
<td><code>torch.float32</code>或<code>torch.float</code></td>
<td><code>torch.FloatTensor</code></td>
<td><code>torch.cuda.FloatTensor</code></td>
</tr>
<tr>
<td>64 位浮点</td>
<td><code>torch.float64</code>或<code>torch.double</code></td>
<td><code>torch.DoubleTensor</code></td>
<td><code>torch.cuda.DoubleTensor</code></td>
</tr>
<tr>
<td>16 位浮点</td>
<td><code>torch.float16</code>或<code>torch.half</code></td>
<td><code>torch.HalfTensor</code></td>
<td><code>torch.cuda.HalfTensor</code></td>
</tr>
<tr>
<td>8 位整数(无符号）</td>
<td><code>torch.uint8</code></td>
<td><code>torch.ByteTensor</code></td>
<td><code>torch.cuda.ByteTensor</code></td>
</tr>
<tr>
<td>8 位整数(有符号）</td>
<td><code>torch.int8</code></td>
<td><code>torch.CharTensor</code></td>
<td><code>torch.cuda.CharTensor</code></td>
</tr>
<tr>
<td>16 位整数(有符号）</td>
<td><code>torch.int16</code>或<code>torch.short</code></td>
<td><code>torch.ShortTensor</code></td>
<td><code>torch.cuda.ShortTensor</code></td>
</tr>
<tr>
<td>32 位整数(有符号）</td>
<td><code>torch.int32</code>或<code>torch.int</code></td>
<td><code>torch.IntTensor</code></td>
<td><code>torch.cuda.IntTensor</code></td>
</tr>
<tr>
<td>64 位整数(有符号）</td>
<td><code>torch.int64</code>或<code>torch.long</code></td>
<td><code>torch.LongTensor</code></td>
<td><code>torch.cuda.LongTensor</code></td>
</tr>
<tr>
<td>布尔型</td>
<td><code>torch.bool</code></td>
<td><a href="#torch.BoolTensor" title="torch.BoolTensor"><code>torch.BoolTensor</code></a></td>
<td><code>torch.cuda.BoolTensor</code></td>
</tr>
</tbody>
</table>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 是默认张量类型(<code>torch.FloatTensor</code>）的别名。</p>
<p>可以使用 <a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 构造函数从 Python <code>list</code>或序列构造张量：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>&gt;&gt;&gt; torch.tensor([[1., -1.], [1., -1.]])
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>tensor([[ 1.0000, -1.0000],
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>        [ 1.0000, -1.0000]])
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>&gt;&gt;&gt; torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>tensor([[ 1,  2,  3],
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>        [ 4,  5,  6]])
</code></pre></div>
<p>警告</p>
<p><a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 始终复制<code>data</code>。 如果您具有张量<code>data</code>，而只想更改其<code>requires_grad</code>标志，请使用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> 或 <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>detach()</code></a> 以避免复制。 如果您有一个 numpy 数组并且想要避免复制，请使用 <a href="torch.html#torch.as_tensor" title="torch.as_tensor"><code>torch.as_tensor()</code></a> 。</p>
<p>可以通过将 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和/或 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 传递给构造函数或张量创建操作来构造特定数据类型的张量：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>&gt;&gt;&gt; torch.zeros([2, 4], dtype=torch.int32)
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>tensor([[ 0,  0,  0,  0],
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>        [ 0,  0,  0,  0]], dtype=torch.int32)
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>&gt;&gt;&gt; cuda0 = torch.device(&#39;cuda:0&#39;)
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>&gt;&gt;&gt; torch.ones([2, 4], dtype=torch.float64, device=cuda0)
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device=&#39;cuda:0&#39;)
</code></pre></div>
<p>张量的内容可以使用 Python 的索引和切片符号来访问和修改：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6]])
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>&gt;&gt;&gt; print(x[1][2])
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>tensor(6)
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>&gt;&gt;&gt; x[0][1] = 8
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>&gt;&gt;&gt; print(x)
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>tensor([[ 1,  8,  3],
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>        [ 4,  5,  6]])
</code></pre></div>
<p>使用 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>torch.Tensor.item()</code></a> 从张量中获取包含单个值的 Python 数字：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>&gt;&gt;&gt; x = torch.tensor([[1]])
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>&gt;&gt;&gt; x
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>tensor([[ 1]])
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>&gt;&gt;&gt; x.item()
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>1
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>&gt;&gt;&gt; x = torch.tensor(2.5)
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>&gt;&gt;&gt; x
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>tensor(2.5000)
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>&gt;&gt;&gt; x.item()
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>2.5
</code></pre></div>
<p>可以使用<code>requires_grad=True</code>创建一个张量，以便 <a href="autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> 对其进行记录操作以进行自动微分。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>&gt;&gt;&gt; x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>&gt;&gt;&gt; out = x.pow(2).sum()
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>&gt;&gt;&gt; out.backward()
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>&gt;&gt;&gt; x.grad
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>tensor([[ 2.0000, -2.0000],
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        [ 2.0000,  2.0000]])
</code></pre></div>
<p>每个张量都有一个关联的<code>torch.Storage</code>，它保存其数据。 张量类提供了存储的多维<a href="https://en.wikipedia.org/wiki/Stride_of_an_array">跨度</a>视图，并定义了数字运算。</p>
<p>注意</p>
<p>有关 <a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> ， <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 和 <a href="tensor_attributes.html#torch.torch.layout" title="torch.torch.layout"><code>torch.layout</code></a> 属性的更多信息，请参阅[ <a href="tensor_attributes.html#tensor-attributes-doc">Tensor Attributes</a> 。</p>
<p>注意</p>
<p>改变张量的方法用下划线后缀标记。 例如，<code>torch.FloatTensor.abs_()</code>在原位计算绝对值并返回修改后的张量，而<code>torch.FloatTensor.abs()</code>在新张量中计算结果。</p>
<p>注意</p>
<p>要更改现有张量的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 和/或 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> ，请考虑在张量上使用 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 方法。</p>
<p>警告</p>
<p><a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> 的当前实现引入了内存开销，因此，在具有许多微小张量的应用程序中，它可能导致意外的高内存使用率。 如果是这种情况，请考虑使用一种大型结构。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>class torch.Tensor
</code></pre></div>
<p>根据您的用例，创建张量的主要方法有几种。</p>
<ul>
<li>
<p>要使用现有数据创建张量，请使用 <a href="torch.html#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> 。</p>
</li>
<li>
<p>要创建具有特定大小的张量，请使用<code>torch.*</code>张量创建操作(请参见 <a href="torch.html#tensor-creation-ops">Creation Ops</a>)。</p>
</li>
<li>
<p>要创建与另一个张量具有相同大小(和相似类型）的张量，请使用<code>torch.*_like</code>张量创建操作(请参见<a href="torch.html#tensor-creation-ops">创建操作</a>）。</p>
</li>
<li>
<p>要创建与其他张量具有相似类型但大小不同的张量，请使用<code>tensor.new_*</code>创建操作。</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>new_tensor(data, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre></div>
<p>返回以<code>data</code>作为张量数据的新张量。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>警告</p>
<p><a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 始终复制<code>data</code>。 如果您有张量<code>data</code>并希望避免复制，请使用 <a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>torch.Tensor.requires_grad_()</code></a> 或 <a href="autograd.html#torch.Tensor.detach" title="torch.Tensor.detach"><code>torch.Tensor.detach()</code></a> 。 如果您有一个 numpy 数组并且想要避免复制，请使用 <a href="torch.html#torch.from_numpy" title="torch.from_numpy"><code>torch.from_numpy()</code></a> 。</p>
<p>警告</p>
<p>当数据是张量 <em>x</em> 时， <a href="#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>new_tensor()</code></a> 从传递的任何数据中读出“数据”，并构造一个叶子变量。 因此，<code>tensor.new_tensor(x)</code>等同于<code>x.clone().detach()</code>，<code>tensor.new_tensor(x, requires_grad=True)</code>等同于<code>x.clone().detach().requires_grad_(True)</code>。 建议使用<code>clone()</code>和<code>detach()</code>的等效项。</p>
<p>参数</p>
<ul>
<li>
<p><strong>data</strong> (<em>array_like</em> )–返回的张量副本<code>data</code>。</p>
</li>
<li>
<p><strong>dtype</strong>  (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> ，可选）– 返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 。</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> ，可选）– 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>require_grad</strong>  (<em>bool</em> <em>，</em> <em>可选</em>）– 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>&gt;&gt;&gt; tensor = torch.ones((2,), dtype=torch.int8)
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>&gt;&gt;&gt; data = [[0, 1], [2, 3]]
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>&gt;&gt;&gt; tensor.new_tensor(data)
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>tensor([[ 0,  1],
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>        [ 2,  3]], dtype=torch.int8)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>new_full(size, fill_value, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre></div>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，并用<code>fill_value</code>填充。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>fill_value</strong> (<em>标量</em>）–用来填充输出张量的数字。</p>
</li>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – 返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 。</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>&gt;&gt;&gt; tensor = torch.ones((2,), dtype=torch.float64)
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>&gt;&gt;&gt; tensor.new_full((3, 4), 3.141592)
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>        [ 3.1416,  3.1416,  3.1416,  3.1416],
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>        [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>new_empty(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre></div>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，其中填充了未初始化的数据。 默认情况下，返回的张量具有与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – </p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>&gt;&gt;&gt; tensor = torch.ones(())
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>&gt;&gt;&gt; tensor.new_empty((2, 3))
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>        [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>new_ones(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre></div>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，并用<code>1</code>填充。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>大小</strong> (<em>python：int ...</em> )–定义输出张量形状的整数列表，元组或<code>torch.Size</code>。</p>
</li>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – 返回张量的所需类型。 默认: 如果是 None, 和 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 一样</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量所在的设备。 默认: 如果是 None, 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 一样</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>&gt;&gt;&gt; tensor = torch.tensor((), dtype=torch.int32)
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>&gt;&gt;&gt; tensor.new_ones((2, 3))
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>tensor([[ 1,  1,  1],
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>        [ 1,  1,  1]], dtype=torch.int32)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>new_zeros(size, dtype=None, device=None, requires_grad=False) → Tensor
</code></pre></div>
<p>返回大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的张量，并用<code>0</code>填充。 默认情况下，返回的张量与此张量具有相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<p>参数</p>
<ul>
<li>
<p><strong>size</strong> (<em>python:int...</em>) – a list, tuple, or <code>torch.Size</code> of integers defining the shape of the output tensor.</p>
</li>
<li>
<p><strong>dtype</strong> (<a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>, optional) – 返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 。</p>
</li>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>, optional) – 返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
</li>
<li>
<p><strong>requires_grad</strong> (<em>bool__,</em> <em>optional</em>) – 返回的张量是否需要自动求导。 默认值：<code>False</code>。</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>&gt;&gt;&gt; tensor = torch.tensor((), dtype=torch.float64)
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>&gt;&gt;&gt; tensor.new_zeros((2, 3))
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>tensor([[ 0.,  0.,  0.],
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>        [ 0.,  0.,  0.]], dtype=torch.float64)
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>is_cuda
</code></pre></div>
<p>如果张量存储在 GPU 上，则为<code>True</code>，否则为<code>False</code>。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>device
</code></pre></div>
<p>张量所在的 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>grad
</code></pre></div>
<p>此属性默认为<code>None</code>，并在首次调用 <a href="autograd.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>backward()</code></a> 计算<code>self</code>的梯度时成为张量。 然后，该属性将包含计算出的梯度以及 <a href="autograd.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>backward()</code></a>返回的梯度值，然后进行梯度累加。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>ndim
</code></pre></div>
<p><a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a> 的别名</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>T
</code></pre></div>
<p>这个张量的尺寸是否颠倒了吗？</p>
<p>如果<code>n</code>是<code>x</code>中的尺寸数，则<code>x.T</code>等效于<code>x.permute(n-1, n-2, ..., 0)</code>。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>abs() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>abs_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.abs" title="torch.Tensor.abs"><code>abs()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>acos() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.acos" title="torch.acos"><code>torch.acos()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>acos_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.acos" title="torch.Tensor.acos"><code>acos()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>add(value) → Tensor
</code></pre></div>
<p>add(value = 1，other）-&gt;张量</p>
<p>参见 <a href="torch.html#torch.add" title="torch.add"><code>torch.add()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>add_(value) → Tensor
</code></pre></div>
<p>add_(value = 1，other）-&gt;张量</p>
<p>就地版本的 <a href="#torch.Tensor.add" title="torch.Tensor.add"><code>add()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>addbmm(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.addbmm" title="torch.addbmm"><code>torch.addbmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>addbmm_(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>addbmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>addcdiv(value=1, tensor1, tensor2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.addcdiv" title="torch.addcdiv"><code>torch.addcdiv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>addcdiv_(value=1, tensor1, tensor2) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>addcdiv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>addcmul(value=1, tensor1, tensor2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.addcmul" title="torch.addcmul"><code>torch.addcmul()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>addcmul_(value=1, tensor1, tensor2) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>addcmul()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>addmm(beta=1, alpha=1, mat1, mat2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.addmm" title="torch.addmm"><code>torch.addmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>addmm_(beta=1, alpha=1, mat1, mat2) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>addmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>addmv(beta=1, alpha=1, mat, vec) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.addmv" title="torch.addmv"><code>torch.addmv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>addmv_(beta=1, alpha=1, mat, vec) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>addmv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a>addr(beta=1, alpha=1, vec1, vec2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.addr" title="torch.addr"><code>torch.addr()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>addr_(beta=1, alpha=1, vec1, vec2) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.addr" title="torch.Tensor.addr"><code>addr()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a>allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.allclose" title="torch.allclose"><code>torch.allclose()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a>angle() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.angle" title="torch.angle"><code>torch.angle()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a>apply_(callable) → Tensor
</code></pre></div>
<p>将函数<code>callable</code>应用于张量中的每个元素，并用<code>callable</code>返回的值替换每个元素。</p>
<p>注意</p>
<p>此功能仅适用于 CPU 张量，不应在需要高性能的代码段中使用。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a>argmax(dim=None, keepdim=False) → LongTensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.argmax" title="torch.argmax"><code>torch.argmax()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a>argmin(dim=None, keepdim=False) → LongTensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.argmin" title="torch.argmin"><code>torch.argmin()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a>argsort(dim=-1, descending=False) → LongTensor
</code></pre></div>
<p>参见：func： &lt;cite&gt;torch.argsort&lt;/cite&gt;</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a>asin() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.asin" title="torch.asin"><code>torch.asin()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a>asin_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.asin" title="torch.Tensor.asin"><code>asin()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a>as_strided(size, stride, storage_offset=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.as_strided" title="torch.as_strided"><code>torch.as_strided()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a>atan() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.atan" title="torch.atan"><code>torch.atan()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a>atan2(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.atan2" title="torch.atan2"><code>torch.atan2()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a>atan2_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>atan2()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a>atan_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.atan" title="torch.Tensor.atan"><code>atan()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a>backward(gradient=None, retain_graph=None, create_graph=False)
</code></pre></div>
<p>计算当前张量的梯度 w.r.t. 图叶。</p>
<p>该图使用链式法则进行区分。 如果张量是非标量的(即其数据具有多个元素）并且需要梯度，则该函数还需要指定<code>gradient</code>。 它应该是匹配类型和位置的张量，其中包含微分函数 w.r.t 的梯度。 <code>self</code>。</p>
<p>此函数是叶子梯度累加-调用它之前可能需要将它们归零。</p>
<p>参数</p>
<ul>
<li>
<p><strong>gradient</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a> <em>Tensor</em> <em>None</em>）– 梯度 w.r.t. 张量。 如果它是张量，除非<code>create_graph</code>为 True，否则它将自动转换为不需要 grad 的张量。 无法为标量张量或不需要等级的张量指定任何值。 如果 None 值可以接受，那么此参数是可选的。</p>
</li>
<li>
<p><strong>retian_graph</strong>  (<em>bool</em> <em>，</em> <em>可选</em>）– 如果<code>False</code>，则用于计算等级的图形将被释放。 请注意，几乎在所有情况下都不需要将此选项设置为 True，并且通常可以以更有效的方式解决它。 默认为<code>create_graph</code>的值。</p>
</li>
<li>
<p><strong>create_graph</strong>  (<em>bool</em> <em>，</em> <em>可选</em>）– 如果<code>True</code>，则将构造导数图，从而允许计算高阶导数产品。 默认为<code>False</code>。</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a>baddbmm(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.baddbmm" title="torch.baddbmm"><code>torch.baddbmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a>baddbmm_(beta=1, alpha=1, batch1, batch2) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>baddbmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a>bernoulli(*, generator=None) → Tensor
</code></pre></div>
<p>返回结果张量，其中每个<span class="arithmatex">\(result[i]\)</span>从<span class="arithmatex">\(Bernoulli(self[i])\)</span>中独立采样。 <code>self</code>必须具有浮点<code>dtype</code>，结果将具有相同的<code>dtype</code>。</p>
<p>参见 <a href="torch.html#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a>bernoulli_(p=0.5, *, generator=None) → Tensor
</code></pre></div>
<p>用<span class="arithmatex">\(Bernoulli(p)\)</span>的独立样本填充<code>self</code>的每个位置。 <code>self</code>可以具有整数<code>dtype</code>。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a>bfloat16() → Tensor
</code></pre></div>
<p><code>self.bfloat16()</code>等效于<code>self.to(torch.bfloat16)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a>bincount(weights=None, minlength=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.bincount" title="torch.bincount"><code>torch.bincount()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a>bitwise_not() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.bitwise_not" title="torch.bitwise_not"><code>torch.bitwise_not()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a>bitwise_not_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code>bitwise_not()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a>bitwise_xor() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.bitwise_xor" title="torch.bitwise_xor"><code>torch.bitwise_xor()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a>bitwise_xor_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code>bitwise_xor()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a>bmm(batch2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.bmm" title="torch.bmm"><code>torch.bmm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a>bool() → Tensor
</code></pre></div>
<p><code>self.bool()</code>等效于<code>self.to(torch.bool)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a>byte() → Tensor
</code></pre></div>
<p><code>self.byte()</code>等效于<code>self.to(torch.uint8)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a>cauchy_(median=0, sigma=1, *, generator=None) → Tensor
</code></pre></div>
<p>用从柯西分布中得出的数字填充张量：</p>
<div class="arithmatex">\[f(x)=\frac {1}{\pi}\frac {\sigma}{(x-median)^2+\sigma^2}\]</div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a>ceil() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.ceil" title="torch.ceil"><code>torch.ceil()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-68-1" name="__codelineno-68-1" href="#__codelineno-68-1"></a>ceil_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>ceil()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-69-1" name="__codelineno-69-1" href="#__codelineno-69-1"></a>char() → Tensor
</code></pre></div>
<p><code>self.char()</code>等效于<code>self.to(torch.int8)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-70-1" name="__codelineno-70-1" href="#__codelineno-70-1"></a>cholesky(upper=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-71-1" name="__codelineno-71-1" href="#__codelineno-71-1"></a>cholesky_inverse(upper=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cholesky_inverse" title="torch.cholesky_inverse"><code>torch.cholesky_inverse()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-72-1" name="__codelineno-72-1" href="#__codelineno-72-1"></a>cholesky_solve(input2, upper=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cholesky_solve" title="torch.cholesky_solve"><code>torch.cholesky_solve()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-73-1" name="__codelineno-73-1" href="#__codelineno-73-1"></a>chunk(chunks, dim=0) → List of Tensors
</code></pre></div>
<p>参见 <a href="torch.html#torch.chunk" title="torch.chunk"><code>torch.chunk()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-74-1" name="__codelineno-74-1" href="#__codelineno-74-1"></a>clamp(min, max) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-75-1" name="__codelineno-75-1" href="#__codelineno-75-1"></a>clamp_(min, max) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-76-1" name="__codelineno-76-1" href="#__codelineno-76-1"></a>clone() → Tensor
</code></pre></div>
<p>返回<code>self</code>张量的副本。 该副本的大小和数据类型与<code>self</code>相同。</p>
<p>注意</p>
<p>与 _copy__()不同，此功能记录在计算图中。 传播到克隆张量的渐变将传播到原始张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-77-1" name="__codelineno-77-1" href="#__codelineno-77-1"></a>contiguous() → Tensor
</code></pre></div>
<p>返回包含与<code>self</code>张量相同的数据的连续张量。 如果<code>self</code>张量是连续的，则此函数返回<code>self</code>张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-78-1" name="__codelineno-78-1" href="#__codelineno-78-1"></a>copy_(src, non_blocking=False) → Tensor
</code></pre></div>
<p>将元素从<code>src</code>复制到<code>self</code>张量并返回<code>self</code>。</p>
<p><code>src</code>张量必须与<code>self</code>张量一起<a href="注意s/broadcasting.html#broadcasting-semantics">广播</a>。 它可以具有不同的数据类型，也可以位于不同的设备上。</p>
<p>参数</p>
<ul>
<li>
<p><strong>src</strong>  (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–要从中复制的源张量</p>
</li>
<li>
<p><strong>non_blocking</strong>  (<em>bool</em> )–如果<code>True</code>并且此副本位于 CPU 和 GPU 之间，则该副本可能相对于主机异步发生。 在其他情况下，此参数无效。</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-79-1" name="__codelineno-79-1" href="#__codelineno-79-1"></a>conj() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.conj" title="torch.conj"><code>torch.conj()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-80-1" name="__codelineno-80-1" href="#__codelineno-80-1"></a>cos() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cos" title="torch.cos"><code>torch.cos()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-81-1" name="__codelineno-81-1" href="#__codelineno-81-1"></a>cos_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.cos" title="torch.Tensor.cos"><code>cos()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-82-1" name="__codelineno-82-1" href="#__codelineno-82-1"></a>cosh() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cosh" title="torch.cosh"><code>torch.cosh()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-83-1" name="__codelineno-83-1" href="#__codelineno-83-1"></a>cosh_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>cosh()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-84-1" name="__codelineno-84-1" href="#__codelineno-84-1"></a>cpu() → Tensor
</code></pre></div>
<p>返回此对象在 CPU 内存中的副本。</p>
<p>如果该对象已经在 CPU 内存中并且在正确的设备上，则不执行任何复制操作并返回原始对象。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-85-1" name="__codelineno-85-1" href="#__codelineno-85-1"></a>cross(other, dim=-1) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cross" title="torch.cross"><code>torch.cross()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-86-1" name="__codelineno-86-1" href="#__codelineno-86-1"></a>cuda(device=None, non_blocking=False) → Tensor
</code></pre></div>
<p>返回此对象在 CUDA 内存中的副本。</p>
<p>如果此对象已经在 CUDA 内存中并且在正确的设备上，则不执行任何复制，并返回原始对象。</p>
<p>参数</p>
<ul>
<li>
<p><strong>device</strong> (<a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a>) – 目标 GPU 设备。 默认为当前 CUDA 设备。</p>
</li>
<li>
<p><strong>non_blocking</strong>  (<em>bool</em> ) – 如果<code>True</code>并且源位于固定内存中，则副本将相对于主机是异步的。 否则，该参数无效。 默认值：<code>False</code>。</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-87-1" name="__codelineno-87-1" href="#__codelineno-87-1"></a>cumprod(dim, dtype=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cumprod" title="torch.cumprod"><code>torch.cumprod()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-88-1" name="__codelineno-88-1" href="#__codelineno-88-1"></a>cumsum(dim, dtype=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.cumsum" title="torch.cumsum"><code>torch.cumsum()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-89-1" name="__codelineno-89-1" href="#__codelineno-89-1"></a>data_ptr() → int
</code></pre></div>
<p>返回<code>self</code>张量的第一个元素的地址。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-90-1" name="__codelineno-90-1" href="#__codelineno-90-1"></a>dequantize() → Tensor
</code></pre></div>
<p>给定量化的张量，对其进行反量化，然后返回反量化后的浮点张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-91-1" name="__codelineno-91-1" href="#__codelineno-91-1"></a>det() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.det" title="torch.det"><code>torch.det()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-92-1" name="__codelineno-92-1" href="#__codelineno-92-1"></a>dense_dim() → int
</code></pre></div>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回密集尺寸的数量。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.sparse_dim" title="torch.Tensor.sparse_dim"><code>Tensor.sparse_dim()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-93-1" name="__codelineno-93-1" href="#__codelineno-93-1"></a>detach()
</code></pre></div>
<p>返回与当前图形分离的新 Tensor。</p>
<p>结果将永远不需要梯度。</p>
<p>注意</p>
<p>返回的 Tensor 与原始 Tensor 共享相同的存储。 可以看到对它们中的任何一个的就地修改，并且可能触发正确性检查中的错误。 重要说明：以前，就地大小/步幅/存储更改(例如 _resize__/_resize_as__/_set__/_transpose__) 返回的张量也会更新原始张量。 现在，这些就地更改将不再更新原始张量，而将触发错误。 对于稀疏张量：原位索引 / 值更改(例如 _zero__/_copy__/_add__)将不会再更新原始张量， 而是触发错误。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-94-1" name="__codelineno-94-1" href="#__codelineno-94-1"></a>detach_()
</code></pre></div>
<p>从创建它的图形中分离张量，使其成为一片叶子。 视图不能就地分离。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-95-1" name="__codelineno-95-1" href="#__codelineno-95-1"></a>diag(diagonal=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.diag" title="torch.diag"><code>torch.diag()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-96-1" name="__codelineno-96-1" href="#__codelineno-96-1"></a>diag_embed(offset=0, dim1=-2, dim2=-1) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.diag_embed" title="torch.diag_embed"><code>torch.diag_embed()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-97-1" name="__codelineno-97-1" href="#__codelineno-97-1"></a>diagflat(offset=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.diagflat" title="torch.diagflat"><code>torch.diagflat()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-98-1" name="__codelineno-98-1" href="#__codelineno-98-1"></a>diagonal(offset=0, dim1=0, dim2=1) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.diagonal" title="torch.diagonal"><code>torch.diagonal()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-99-1" name="__codelineno-99-1" href="#__codelineno-99-1"></a>fill_diagonal_(fill_value, wrap=False) → Tensor
</code></pre></div>
<p>填充具有至少 2 维的张量的主对角线。 当&gt; 2 变暗时，所有输入尺寸必须相等。 此函数就地修改输入张量，并返回输入张量。</p>
<p>参数</p>
<ul>
<li>
<p><strong>fill_value</strong> (<em>标量</em>）– 填充值</p>
</li>
<li>
<p><strong>wrap</strong> (<em>bool</em> ) – 对角线“包裹”在高列的 N 列之后。</p>
</li>
</ul>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-100-1" name="__codelineno-100-1" href="#__codelineno-100-1"></a>&gt;&gt;&gt; a = torch.zeros(3, 3)
<a id="__codelineno-100-2" name="__codelineno-100-2" href="#__codelineno-100-2"></a>&gt;&gt;&gt; a.fill_diagonal_(5)
<a id="__codelineno-100-3" name="__codelineno-100-3" href="#__codelineno-100-3"></a>tensor([[5., 0., 0.],
<a id="__codelineno-100-4" name="__codelineno-100-4" href="#__codelineno-100-4"></a>        [0., 5., 0.],
<a id="__codelineno-100-5" name="__codelineno-100-5" href="#__codelineno-100-5"></a>        [0., 0., 5.]])
<a id="__codelineno-100-6" name="__codelineno-100-6" href="#__codelineno-100-6"></a>&gt;&gt;&gt; b = torch.zeros(7, 3)
<a id="__codelineno-100-7" name="__codelineno-100-7" href="#__codelineno-100-7"></a>&gt;&gt;&gt; b.fill_diagonal_(5)
<a id="__codelineno-100-8" name="__codelineno-100-8" href="#__codelineno-100-8"></a>tensor([[5., 0., 0.],
<a id="__codelineno-100-9" name="__codelineno-100-9" href="#__codelineno-100-9"></a>        [0., 5., 0.],
<a id="__codelineno-100-10" name="__codelineno-100-10" href="#__codelineno-100-10"></a>        [0., 0., 5.],
<a id="__codelineno-100-11" name="__codelineno-100-11" href="#__codelineno-100-11"></a>        [0., 0., 0.],
<a id="__codelineno-100-12" name="__codelineno-100-12" href="#__codelineno-100-12"></a>        [0., 0., 0.],
<a id="__codelineno-100-13" name="__codelineno-100-13" href="#__codelineno-100-13"></a>        [0., 0., 0.],
<a id="__codelineno-100-14" name="__codelineno-100-14" href="#__codelineno-100-14"></a>        [0., 0., 0.]])
<a id="__codelineno-100-15" name="__codelineno-100-15" href="#__codelineno-100-15"></a>&gt;&gt;&gt; c = torch.zeros(7, 3)
<a id="__codelineno-100-16" name="__codelineno-100-16" href="#__codelineno-100-16"></a>&gt;&gt;&gt; c.fill_diagonal_(5, wrap=True)
<a id="__codelineno-100-17" name="__codelineno-100-17" href="#__codelineno-100-17"></a>tensor([[5., 0., 0.],
<a id="__codelineno-100-18" name="__codelineno-100-18" href="#__codelineno-100-18"></a>        [0., 5., 0.],
<a id="__codelineno-100-19" name="__codelineno-100-19" href="#__codelineno-100-19"></a>        [0., 0., 5.],
<a id="__codelineno-100-20" name="__codelineno-100-20" href="#__codelineno-100-20"></a>        [0., 0., 0.],
<a id="__codelineno-100-21" name="__codelineno-100-21" href="#__codelineno-100-21"></a>        [5., 0., 0.],
<a id="__codelineno-100-22" name="__codelineno-100-22" href="#__codelineno-100-22"></a>        [0., 5., 0.],
<a id="__codelineno-100-23" name="__codelineno-100-23" href="#__codelineno-100-23"></a>        [0., 0., 5.]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-101-1" name="__codelineno-101-1" href="#__codelineno-101-1"></a>digamma() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.digamma" title="torch.digamma"><code>torch.digamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-102-1" name="__codelineno-102-1" href="#__codelineno-102-1"></a>digamma_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.digamma" title="torch.Tensor.digamma"><code>digamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-103-1" name="__codelineno-103-1" href="#__codelineno-103-1"></a>dim() → int
</code></pre></div>
<p>返回<code>self</code>张量的维数。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-104-1" name="__codelineno-104-1" href="#__codelineno-104-1"></a>dist(other, p=2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.dist" title="torch.dist"><code>torch.dist()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-105-1" name="__codelineno-105-1" href="#__codelineno-105-1"></a>div(value) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.div" title="torch.div"><code>torch.div()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-106-1" name="__codelineno-106-1" href="#__codelineno-106-1"></a>div_(value) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.div" title="torch.Tensor.div"><code>div()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-107-1" name="__codelineno-107-1" href="#__codelineno-107-1"></a>dot(tensor2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.dot" title="torch.dot"><code>torch.dot()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-108-1" name="__codelineno-108-1" href="#__codelineno-108-1"></a>double() → Tensor
</code></pre></div>
<p><code>self.double()</code>等效于<code>self.to(torch.float64)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-109-1" name="__codelineno-109-1" href="#__codelineno-109-1"></a>eig(eigenvectors=False) -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.eig" title="torch.eig"><code>torch.eig()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-110-1" name="__codelineno-110-1" href="#__codelineno-110-1"></a>element_size() → int
</code></pre></div>
<p>返回单个元素的大小(以字节为单位）。</p>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-111-1" name="__codelineno-111-1" href="#__codelineno-111-1"></a>&gt;&gt;&gt; torch.tensor([]).element_size()
<a id="__codelineno-111-2" name="__codelineno-111-2" href="#__codelineno-111-2"></a>4
<a id="__codelineno-111-3" name="__codelineno-111-3" href="#__codelineno-111-3"></a>&gt;&gt;&gt; torch.tensor([], dtype=torch.uint8).element_size()
<a id="__codelineno-111-4" name="__codelineno-111-4" href="#__codelineno-111-4"></a>1
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-112-1" name="__codelineno-112-1" href="#__codelineno-112-1"></a>eq(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.eq" title="torch.eq"><code>torch.eq()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-113-1" name="__codelineno-113-1" href="#__codelineno-113-1"></a>eq_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.eq" title="torch.Tensor.eq"><code>eq()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-114-1" name="__codelineno-114-1" href="#__codelineno-114-1"></a>equal(other) → bool
</code></pre></div>
<p>参见 <a href="torch.html#torch.equal" title="torch.equal"><code>torch.equal()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-115-1" name="__codelineno-115-1" href="#__codelineno-115-1"></a>erf() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.erf" title="torch.erf"><code>torch.erf()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-116-1" name="__codelineno-116-1" href="#__codelineno-116-1"></a>erf_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.erf" title="torch.Tensor.erf"><code>erf()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-117-1" name="__codelineno-117-1" href="#__codelineno-117-1"></a>erfc() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.erfc" title="torch.erfc"><code>torch.erfc()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-118-1" name="__codelineno-118-1" href="#__codelineno-118-1"></a>erfc_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>erfc()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-119-1" name="__codelineno-119-1" href="#__codelineno-119-1"></a>erfinv() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.erfinv" title="torch.erfinv"><code>torch.erfinv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-120-1" name="__codelineno-120-1" href="#__codelineno-120-1"></a>erfinv_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>erfinv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-121-1" name="__codelineno-121-1" href="#__codelineno-121-1"></a>exp() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.exp" title="torch.exp"><code>torch.exp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-122-1" name="__codelineno-122-1" href="#__codelineno-122-1"></a>exp_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.exp" title="torch.Tensor.exp"><code>exp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-123-1" name="__codelineno-123-1" href="#__codelineno-123-1"></a>expm1() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.expm1" title="torch.expm1"><code>torch.expm1()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-124-1" name="__codelineno-124-1" href="#__codelineno-124-1"></a>expm1_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>expm1()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-125-1" name="__codelineno-125-1" href="#__codelineno-125-1"></a>expand(*sizes) → Tensor
</code></pre></div>
<p>返回<code>self</code>张量的新视图，其中单例尺寸扩展为更大的尺寸。</p>
<p>将-1 传递为尺寸的大小表示不更改该尺寸的大小。</p>
<p>Tensor 也可以扩展到更大的尺寸，并且新尺寸将附加在前面。 对于新尺寸，尺寸不能设置为-1。</p>
<p>扩展张量不会分配新的内存，而只会在现有张量上创建一个新视图，其中通过将<code>stride</code>设置为 0，将尺寸为 1 的维扩展为更大的尺寸。尺寸为 1 的任何维都可以扩展为 不分配新内存的任意值。</p>
<p>参数</p>
<p><strong>*大小</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–所需的扩展大小</p>
<p>警告</p>
<p>扩展张量的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果需要写张量，请先克隆它们。</p>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-126-1" name="__codelineno-126-1" href="#__codelineno-126-1"></a>&gt;&gt;&gt; x = torch.tensor([[1], [2], [3]])
<a id="__codelineno-126-2" name="__codelineno-126-2" href="#__codelineno-126-2"></a>&gt;&gt;&gt; x.size()
<a id="__codelineno-126-3" name="__codelineno-126-3" href="#__codelineno-126-3"></a>torch.Size([3, 1])
<a id="__codelineno-126-4" name="__codelineno-126-4" href="#__codelineno-126-4"></a>&gt;&gt;&gt; x.expand(3, 4)
<a id="__codelineno-126-5" name="__codelineno-126-5" href="#__codelineno-126-5"></a>tensor([[ 1,  1,  1,  1],
<a id="__codelineno-126-6" name="__codelineno-126-6" href="#__codelineno-126-6"></a>        [ 2,  2,  2,  2],
<a id="__codelineno-126-7" name="__codelineno-126-7" href="#__codelineno-126-7"></a>        [ 3,  3,  3,  3]])
<a id="__codelineno-126-8" name="__codelineno-126-8" href="#__codelineno-126-8"></a>&gt;&gt;&gt; x.expand(-1, 4)   # -1 means not changing the size of that dimension
<a id="__codelineno-126-9" name="__codelineno-126-9" href="#__codelineno-126-9"></a>tensor([[ 1,  1,  1,  1],
<a id="__codelineno-126-10" name="__codelineno-126-10" href="#__codelineno-126-10"></a>        [ 2,  2,  2,  2],
<a id="__codelineno-126-11" name="__codelineno-126-11" href="#__codelineno-126-11"></a>        [ 3,  3,  3,  3]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-127-1" name="__codelineno-127-1" href="#__codelineno-127-1"></a>expand_as(other) → Tensor
</code></pre></div>
<p>将该张量扩展为与<code>other</code>相同的大小。 <code>self.expand_as(other)</code>等效于<code>self.expand(other.size())</code>。</p>
<p>有关<code>expand</code>的更多信息，请参见 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a> 。</p>
<p>参数</p>
<p><strong>其他</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>)–结果张量的大小与<code>other</code>相同。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-128-1" name="__codelineno-128-1" href="#__codelineno-128-1"></a>exponential_(lambd=1, *, generator=None) → Tensor
</code></pre></div>
<p>用从指数分布中绘制的元素填充<code>self</code>张量：</p>
<div class="arithmatex">\[f(x)=\lambda e^{-\lambda x}\]</div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-129-1" name="__codelineno-129-1" href="#__codelineno-129-1"></a>fft(signal_ndim, normalized=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.fft" title="torch.fft"><code>torch.fft()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-130-1" name="__codelineno-130-1" href="#__codelineno-130-1"></a>fill_(value) → Tensor
</code></pre></div>
<p>用指定值填充<code>self</code>张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-131-1" name="__codelineno-131-1" href="#__codelineno-131-1"></a>flatten(input, start_dim=0, end_dim=-1) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.flatten" title="torch.flatten"><code>torch.flatten()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-132-1" name="__codelineno-132-1" href="#__codelineno-132-1"></a>flip(dims) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.flip" title="torch.flip"><code>torch.flip()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-133-1" name="__codelineno-133-1" href="#__codelineno-133-1"></a>float() → Tensor
</code></pre></div>
<p><code>self.float()</code>等效于<code>self.to(torch.float32)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-134-1" name="__codelineno-134-1" href="#__codelineno-134-1"></a>floor() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.floor" title="torch.floor"><code>torch.floor()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-135-1" name="__codelineno-135-1" href="#__codelineno-135-1"></a>floor_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.floor" title="torch.Tensor.floor"><code>floor()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-136-1" name="__codelineno-136-1" href="#__codelineno-136-1"></a>fmod(divisor) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.fmod" title="torch.fmod"><code>torch.fmod()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-137-1" name="__codelineno-137-1" href="#__codelineno-137-1"></a>fmod_(divisor) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>fmod()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-138-1" name="__codelineno-138-1" href="#__codelineno-138-1"></a>frac() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.frac" title="torch.frac"><code>torch.frac()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-139-1" name="__codelineno-139-1" href="#__codelineno-139-1"></a>frac_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.frac" title="torch.Tensor.frac"><code>frac()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-140-1" name="__codelineno-140-1" href="#__codelineno-140-1"></a>gather(dim, index) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.gather" title="torch.gather"><code>torch.gather()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-141-1" name="__codelineno-141-1" href="#__codelineno-141-1"></a>ge(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.ge" title="torch.ge"><code>torch.ge()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-142-1" name="__codelineno-142-1" href="#__codelineno-142-1"></a>ge_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.ge" title="torch.Tensor.ge"><code>ge()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-143-1" name="__codelineno-143-1" href="#__codelineno-143-1"></a>geometric_(p, *, generator=None) → Tensor
</code></pre></div>
<p>用从几何分布中绘制的元素填充<code>self</code>张量：</p>
<div class="arithmatex">\[f(X=k)=p^{k-1}(1-p)\]</div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-144-1" name="__codelineno-144-1" href="#__codelineno-144-1"></a>geqrf() -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-145-1" name="__codelineno-145-1" href="#__codelineno-145-1"></a>ger(vec2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.ger" title="torch.ger"><code>torch.ger()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-146-1" name="__codelineno-146-1" href="#__codelineno-146-1"></a>get_device() -&gt; Device ordinal (Integer)
</code></pre></div>
<p>对于 CUDA 张量，此函数返回张量所在的 GPU 的设备序号。 对于 CPU 张量，将引发错误。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-147-1" name="__codelineno-147-1" href="#__codelineno-147-1"></a>&gt;&gt;&gt; x = torch.randn(3, 4, 5, device=&#39;cuda:0&#39;)
<a id="__codelineno-147-2" name="__codelineno-147-2" href="#__codelineno-147-2"></a>&gt;&gt;&gt; x.get_device()
<a id="__codelineno-147-3" name="__codelineno-147-3" href="#__codelineno-147-3"></a>0
<a id="__codelineno-147-4" name="__codelineno-147-4" href="#__codelineno-147-4"></a>&gt;&gt;&gt; x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-148-1" name="__codelineno-148-1" href="#__codelineno-148-1"></a>gt(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.gt" title="torch.gt"><code>torch.gt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-149-1" name="__codelineno-149-1" href="#__codelineno-149-1"></a>gt_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.gt" title="torch.Tensor.gt"><code>gt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-150-1" name="__codelineno-150-1" href="#__codelineno-150-1"></a>half() → Tensor
</code></pre></div>
<p><code>self.half()</code>等效于<code>self.to(torch.float16)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-151-1" name="__codelineno-151-1" href="#__codelineno-151-1"></a>hardshrink(lambd=0.5) → Tensor
</code></pre></div>
<p>参见 <a href="nn.functional.html#torch.nn.functional.hardshrink" title="torch.nn.functional.hardshrink"><code>torch.nn.functional.hardshrink()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-152-1" name="__codelineno-152-1" href="#__codelineno-152-1"></a>histc(bins=100, min=0, max=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.histc" title="torch.histc"><code>torch.histc()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-153-1" name="__codelineno-153-1" href="#__codelineno-153-1"></a>ifft(signal_ndim, normalized=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.ifft" title="torch.ifft"><code>torch.ifft()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-154-1" name="__codelineno-154-1" href="#__codelineno-154-1"></a>imag() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.imag" title="torch.imag"><code>torch.imag()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-155-1" name="__codelineno-155-1" href="#__codelineno-155-1"></a>index_add_(dim, index, tensor) → Tensor
</code></pre></div>
<p>通过按<code>index</code>中给定的顺序添加索引，将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的元素累积到<code>self</code>张量中。 例如，如果<code>dim == 0</code>和<code>index[i] == j</code>，则将<a href="torch.html#torch.tensor" title="torch.tensor">的第<code>i</code>行<code>tensor</code></a> 添加到<code>self</code>的第<code>j</code>行。</p>
<p><a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 尺寸必须与<code>index</code>的长度(必须为矢量）的尺寸相同，并且所有其他尺寸必须与<code>self</code> ]，否则将引发错误。</p>
<p>注意</p>
<p>使用 CUDA 后端时，此操作可能会导致不确定的行为，不容易关闭。 有关背景，请参见<a href="注意s/randomness.html">重现性</a>的注释。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> )–索引所沿的维度</p>
</li>
<li>
<p><strong>索引</strong> (<em>LongTensor</em> )– <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的索引</p>
</li>
<li>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–张量包含要添加的值</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-156-1" name="__codelineno-156-1" href="#__codelineno-156-1"></a>&gt;&gt;&gt; x = torch.ones(5, 3)
<a id="__codelineno-156-2" name="__codelineno-156-2" href="#__codelineno-156-2"></a>&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
<a id="__codelineno-156-3" name="__codelineno-156-3" href="#__codelineno-156-3"></a>&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
<a id="__codelineno-156-4" name="__codelineno-156-4" href="#__codelineno-156-4"></a>&gt;&gt;&gt; x.index_add_(0, index, t)
<a id="__codelineno-156-5" name="__codelineno-156-5" href="#__codelineno-156-5"></a>tensor([[  2.,   3.,   4.],
<a id="__codelineno-156-6" name="__codelineno-156-6" href="#__codelineno-156-6"></a>        [  1.,   1.,   1.],
<a id="__codelineno-156-7" name="__codelineno-156-7" href="#__codelineno-156-7"></a>        [  8.,   9.,  10.],
<a id="__codelineno-156-8" name="__codelineno-156-8" href="#__codelineno-156-8"></a>        [  1.,   1.,   1.],
<a id="__codelineno-156-9" name="__codelineno-156-9" href="#__codelineno-156-9"></a>        [  5.,   6.,   7.]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-157-1" name="__codelineno-157-1" href="#__codelineno-157-1"></a>index_add(dim, index, tensor) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code>torch.Tensor.index_add_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-158-1" name="__codelineno-158-1" href="#__codelineno-158-1"></a>index_copy_(dim, index, tensor) → Tensor
</code></pre></div>
<p>通过按<code>index</code>中给定的顺序选择索引，将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的元素复制到<code>self</code>张量中。 例如，如果<code>dim == 0</code>和<code>index[i] == j</code>，则将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 的第<code>i</code>行复制到<code>self</code>的第<code>j</code>行。</p>
<p>The <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>th dimension of <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> must have the same size as the length of <code>index</code> (which must be a vector), and all other dimensions must match <code>self</code>, or an error will be raised.</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – dimension along which to index</p>
</li>
<li>
<p><strong>index</strong> (<em>LongTensor</em>) – indices of <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> to select from</p>
</li>
<li>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–张量包含要复制的值</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-159-1" name="__codelineno-159-1" href="#__codelineno-159-1"></a>&gt;&gt;&gt; x = torch.zeros(5, 3)
<a id="__codelineno-159-2" name="__codelineno-159-2" href="#__codelineno-159-2"></a>&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
<a id="__codelineno-159-3" name="__codelineno-159-3" href="#__codelineno-159-3"></a>&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
<a id="__codelineno-159-4" name="__codelineno-159-4" href="#__codelineno-159-4"></a>&gt;&gt;&gt; x.index_copy_(0, index, t)
<a id="__codelineno-159-5" name="__codelineno-159-5" href="#__codelineno-159-5"></a>tensor([[ 1.,  2.,  3.],
<a id="__codelineno-159-6" name="__codelineno-159-6" href="#__codelineno-159-6"></a>        [ 0.,  0.,  0.],
<a id="__codelineno-159-7" name="__codelineno-159-7" href="#__codelineno-159-7"></a>        [ 7.,  8.,  9.],
<a id="__codelineno-159-8" name="__codelineno-159-8" href="#__codelineno-159-8"></a>        [ 0.,  0.,  0.],
<a id="__codelineno-159-9" name="__codelineno-159-9" href="#__codelineno-159-9"></a>        [ 4.,  5.,  6.]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-160-1" name="__codelineno-160-1" href="#__codelineno-160-1"></a>index_copy(dim, index, tensor) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code>torch.Tensor.index_copy_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-161-1" name="__codelineno-161-1" href="#__codelineno-161-1"></a>index_fill_(dim, index, val) → Tensor
</code></pre></div>
<p>通过按<code>index</code>中给定的顺序选择索引，用值<code>val</code>填充<code>self</code>张量的元素。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – dimension along which to index</p>
</li>
<li>
<p><strong>索引</strong> (<em>LongTensor</em> )–填写的<code>self</code>张量索引</p>
</li>
<li>
<p><strong>val</strong>  (<em>python：float</em> )–要填充的值</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-162-1" name="__codelineno-162-1" href="#__codelineno-162-1"></a>例：:
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-163-1" name="__codelineno-163-1" href="#__codelineno-163-1"></a>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
<a id="__codelineno-163-2" name="__codelineno-163-2" href="#__codelineno-163-2"></a>&gt;&gt;&gt; index = torch.tensor([0, 2])
<a id="__codelineno-163-3" name="__codelineno-163-3" href="#__codelineno-163-3"></a>&gt;&gt;&gt; x.index_fill_(1, index, -1)
<a id="__codelineno-163-4" name="__codelineno-163-4" href="#__codelineno-163-4"></a>tensor([[-1.,  2., -1.],
<a id="__codelineno-163-5" name="__codelineno-163-5" href="#__codelineno-163-5"></a>        [-1.,  5., -1.],
<a id="__codelineno-163-6" name="__codelineno-163-6" href="#__codelineno-163-6"></a>        [-1.,  8., -1.]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-164-1" name="__codelineno-164-1" href="#__codelineno-164-1"></a>index_fill(dim, index, value) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code>torch.Tensor.index_fill_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-165-1" name="__codelineno-165-1" href="#__codelineno-165-1"></a>index_put_(indices, value, accumulate=False) → Tensor
</code></pre></div>
<p>使用在 <a href="#torch.Tensor.indices" title="torch.Tensor.indices"><code>indices</code></a> 中指定的索引(张量的元组）将张量<code>value</code>的值放入张量<code>self</code>。 表达式<code>tensor.index_put_(indices, value)</code>等效于<code>tensor[indices] = value</code>。 返回<code>self</code>。</p>
<p>如果<code>accumulate</code>为<code>True</code>，则将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素添加到<code>self</code>中。 如果 accumulate 为<code>False</code>，则在索引包含重复元素的情况下行为未定义。</p>
<p>参数</p>
<ul>
<li>
<p><strong>索引</strong>(LongTensor 的_元组）–用于索引&lt;cite&gt;自身&lt;/cite&gt;的张量。_</p>
</li>
<li>
<p><strong>值</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–与&lt;cite&gt;自身&lt;/cite&gt;相同类型的张量。</p>
</li>
<li>
<p><strong>累积</strong> (<em>bool</em> )–是否累积</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-166-1" name="__codelineno-166-1" href="#__codelineno-166-1"></a>index_put(indices, value, accumulate=False) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code>index_put_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-167-1" name="__codelineno-167-1" href="#__codelineno-167-1"></a>index_select(dim, index) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.index_select" title="torch.index_select"><code>torch.index_select()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-168-1" name="__codelineno-168-1" href="#__codelineno-168-1"></a>indices() → Tensor
</code></pre></div>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回包含的索引张量的视图。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.values" title="torch.Tensor.values"><code>Tensor.values()</code></a> 。</p>
<p>注意</p>
<p>只能在合并的稀疏张量上调用此方法。 有关详细信息，请参见<code>Tensor.coalesce()</code>。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-169-1" name="__codelineno-169-1" href="#__codelineno-169-1"></a>int() → Tensor
</code></pre></div>
<p><code>self.int()</code>等效于<code>self.to(torch.int32)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-170-1" name="__codelineno-170-1" href="#__codelineno-170-1"></a>int_repr() → Tensor
</code></pre></div>
<p>给定量化的 Tensor，<code>self.int_repr()</code>返回以 uint8_t 作为数据类型的 CPU Tensor，该数据类型存储给定 Tensor 的基础 uint8_t 值。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-171-1" name="__codelineno-171-1" href="#__codelineno-171-1"></a>inverse() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-172-1" name="__codelineno-172-1" href="#__codelineno-172-1"></a>irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.irfft" title="torch.irfft"><code>torch.irfft()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-173-1" name="__codelineno-173-1" href="#__codelineno-173-1"></a>is_contiguous() → bool
</code></pre></div>
<p>如果<code>self</code>张量在内存中以 C 顺序连续，则返回 True。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-174-1" name="__codelineno-174-1" href="#__codelineno-174-1"></a>is_floating_point() → bool
</code></pre></div>
<p>如果<code>self</code>的数据类型是浮点数据类型，则返回 True。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-175-1" name="__codelineno-175-1" href="#__codelineno-175-1"></a>is_leaf
</code></pre></div>
<p>按照惯例，所有具有 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> 即<code>False</code>的张量将是叶张量。</p>
<p>对于具有 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> (即<code>True</code>）的张量，如果它们是由用户创建的，则它们将是叶张量。 这意味着它们不是运算的结果，因此<code>grad_fn</code>为“无”。</p>
<p>在调用 <a href="autograd.html#torch.Tensor.backward" title="torch.Tensor.backward"><code>backward()</code></a> 期间，仅叶子张量会填充其 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> 。 要为非叶张量填充 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> ，可以使用 <a href="autograd.html#torch.Tensor.retain_grad" title="torch.Tensor.retain_grad"><code>retain_grad()</code></a> 。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-176-1" name="__codelineno-176-1" href="#__codelineno-176-1"></a>&gt;&gt;&gt; a = torch.rand(10, requires_grad=True)
<a id="__codelineno-176-2" name="__codelineno-176-2" href="#__codelineno-176-2"></a>&gt;&gt;&gt; a.is_leaf
<a id="__codelineno-176-3" name="__codelineno-176-3" href="#__codelineno-176-3"></a>True
<a id="__codelineno-176-4" name="__codelineno-176-4" href="#__codelineno-176-4"></a>&gt;&gt;&gt; b = torch.rand(10, requires_grad=True).cuda()
<a id="__codelineno-176-5" name="__codelineno-176-5" href="#__codelineno-176-5"></a>&gt;&gt;&gt; b.is_leaf
<a id="__codelineno-176-6" name="__codelineno-176-6" href="#__codelineno-176-6"></a>False
<a id="__codelineno-176-7" name="__codelineno-176-7" href="#__codelineno-176-7"></a># b was created by the operation that cast a cpu Tensor into a cuda Tensor
<a id="__codelineno-176-8" name="__codelineno-176-8" href="#__codelineno-176-8"></a>&gt;&gt;&gt; c = torch.rand(10, requires_grad=True) + 2
<a id="__codelineno-176-9" name="__codelineno-176-9" href="#__codelineno-176-9"></a>&gt;&gt;&gt; c.is_leaf
<a id="__codelineno-176-10" name="__codelineno-176-10" href="#__codelineno-176-10"></a>False
<a id="__codelineno-176-11" name="__codelineno-176-11" href="#__codelineno-176-11"></a># c was created by the addition operation
<a id="__codelineno-176-12" name="__codelineno-176-12" href="#__codelineno-176-12"></a>&gt;&gt;&gt; d = torch.rand(10).cuda()
<a id="__codelineno-176-13" name="__codelineno-176-13" href="#__codelineno-176-13"></a>&gt;&gt;&gt; d.is_leaf
<a id="__codelineno-176-14" name="__codelineno-176-14" href="#__codelineno-176-14"></a>True
<a id="__codelineno-176-15" name="__codelineno-176-15" href="#__codelineno-176-15"></a># d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)
<a id="__codelineno-176-16" name="__codelineno-176-16" href="#__codelineno-176-16"></a>&gt;&gt;&gt; e = torch.rand(10).cuda().requires_grad_()
<a id="__codelineno-176-17" name="__codelineno-176-17" href="#__codelineno-176-17"></a>&gt;&gt;&gt; e.is_leaf
<a id="__codelineno-176-18" name="__codelineno-176-18" href="#__codelineno-176-18"></a>True
<a id="__codelineno-176-19" name="__codelineno-176-19" href="#__codelineno-176-19"></a># e requires gradients and has no operations creating it
<a id="__codelineno-176-20" name="__codelineno-176-20" href="#__codelineno-176-20"></a>&gt;&gt;&gt; f = torch.rand(10, requires_grad=True, device=&quot;cuda&quot;)
<a id="__codelineno-176-21" name="__codelineno-176-21" href="#__codelineno-176-21"></a>&gt;&gt;&gt; f.is_leaf
<a id="__codelineno-176-22" name="__codelineno-176-22" href="#__codelineno-176-22"></a>True
<a id="__codelineno-176-23" name="__codelineno-176-23" href="#__codelineno-176-23"></a># f requires grad, has no operation creating it
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-177-1" name="__codelineno-177-1" href="#__codelineno-177-1"></a>is_pinned()
</code></pre></div>
<p>如果该张量驻留在固定的内存中，则返回 true。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-178-1" name="__codelineno-178-1" href="#__codelineno-178-1"></a>is_set_to(tensor) → bool
</code></pre></div>
<p>如果此对象引用与 Torch C API 中相同的<code>THTensor</code>对象作为给定张量，则返回 True。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-179-1" name="__codelineno-179-1" href="#__codelineno-179-1"></a>is_shared()
</code></pre></div>
<p>检查张量是否在共享内存中。</p>
<p>CUDA 张量始终为<code>True</code>。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-180-1" name="__codelineno-180-1" href="#__codelineno-180-1"></a>is_signed() → bool
</code></pre></div>
<p>如果<code>self</code>的数据类型是带符号的数据类型，则返回 True。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-181-1" name="__codelineno-181-1" href="#__codelineno-181-1"></a>is_sparse
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-182-1" name="__codelineno-182-1" href="#__codelineno-182-1"></a>item() → number
</code></pre></div>
<p>返回此张量的值作为标准 Python 数。 这仅适用于具有一个元素的张量。 对于其他情况，请参见 <a href="#torch.Tensor.tolist" title="torch.Tensor.tolist"><code>tolist()</code></a> 。</p>
<p>此操作不可区分。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-183-1" name="__codelineno-183-1" href="#__codelineno-183-1"></a>&gt;&gt;&gt; x = torch.tensor([1.0])
<a id="__codelineno-183-2" name="__codelineno-183-2" href="#__codelineno-183-2"></a>&gt;&gt;&gt; x.item()
<a id="__codelineno-183-3" name="__codelineno-183-3" href="#__codelineno-183-3"></a>1.0
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-184-1" name="__codelineno-184-1" href="#__codelineno-184-1"></a>kthvalue(k, dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.kthvalue" title="torch.kthvalue"><code>torch.kthvalue()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-185-1" name="__codelineno-185-1" href="#__codelineno-185-1"></a>le(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.le" title="torch.le"><code>torch.le()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-186-1" name="__codelineno-186-1" href="#__codelineno-186-1"></a>le_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.le" title="torch.Tensor.le"><code>le()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-187-1" name="__codelineno-187-1" href="#__codelineno-187-1"></a>lerp(end, weight) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.lerp" title="torch.lerp"><code>torch.lerp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-188-1" name="__codelineno-188-1" href="#__codelineno-188-1"></a>lerp_(end, weight) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>lerp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-189-1" name="__codelineno-189-1" href="#__codelineno-189-1"></a>lgamma() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.lgamma" title="torch.lgamma"><code>torch.lgamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-190-1" name="__codelineno-190-1" href="#__codelineno-190-1"></a>lgamma_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code>lgamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-191-1" name="__codelineno-191-1" href="#__codelineno-191-1"></a>log() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.log" title="torch.log"><code>torch.log()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-192-1" name="__codelineno-192-1" href="#__codelineno-192-1"></a>log_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.log" title="torch.Tensor.log"><code>log()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-193-1" name="__codelineno-193-1" href="#__codelineno-193-1"></a>logdet() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.logdet" title="torch.logdet"><code>torch.logdet()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-194-1" name="__codelineno-194-1" href="#__codelineno-194-1"></a>log10() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.log10" title="torch.log10"><code>torch.log10()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-195-1" name="__codelineno-195-1" href="#__codelineno-195-1"></a>log10_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.log10" title="torch.Tensor.log10"><code>log10()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-196-1" name="__codelineno-196-1" href="#__codelineno-196-1"></a>log1p() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-197-1" name="__codelineno-197-1" href="#__codelineno-197-1"></a>log1p_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>log1p()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-198-1" name="__codelineno-198-1" href="#__codelineno-198-1"></a>log2() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.log2" title="torch.log2"><code>torch.log2()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-199-1" name="__codelineno-199-1" href="#__codelineno-199-1"></a>log2_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.log2" title="torch.Tensor.log2"><code>log2()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-200-1" name="__codelineno-200-1" href="#__codelineno-200-1"></a>log_normal_(mean=1, std=2, *, generator=None)
</code></pre></div>
<p>用对数正态分布中由给定平均值<img alt="" src="../img/fba1f12214374ac856c1e4be142c9dff.jpg" />和标准偏差<img alt="" src="../img/cc84e998f72a1c5a0a5f736ba6a9ff34.jpg" />参数化的数字样本填充<code>self</code>张量。 请注意， <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> 和 <a href="torch.html#torch.std" title="torch.std"><code>std</code></a> 是基础正态分布的均值和标准偏差，而不是返回的正态分布：</p>
<div class="arithmatex">\[f(x)=\frac {1}{x\sigma \sqrt {2\pi}}e^{-\frac {(lnx - \mu)^2}{2\sigma^2}}\]</div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-201-1" name="__codelineno-201-1" href="#__codelineno-201-1"></a>logsumexp(dim, keepdim=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-202-1" name="__codelineno-202-1" href="#__codelineno-202-1"></a>logical_not() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.logical_not" title="torch.logical_not"><code>torch.logical_not()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-203-1" name="__codelineno-203-1" href="#__codelineno-203-1"></a>logical_not_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code>logical_not()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-204-1" name="__codelineno-204-1" href="#__codelineno-204-1"></a>logical_xor() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.logical_xor" title="torch.logical_xor"><code>torch.logical_xor()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-205-1" name="__codelineno-205-1" href="#__codelineno-205-1"></a>logical_xor_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code>logical_xor()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-206-1" name="__codelineno-206-1" href="#__codelineno-206-1"></a>long() → Tensor
</code></pre></div>
<p><code>self.long()</code>等效于<code>self.to(torch.int64)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-207-1" name="__codelineno-207-1" href="#__codelineno-207-1"></a>lstsq(A) -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.lstsq" title="torch.lstsq"><code>torch.lstsq()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-208-1" name="__codelineno-208-1" href="#__codelineno-208-1"></a>lt(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.lt" title="torch.lt"><code>torch.lt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-209-1" name="__codelineno-209-1" href="#__codelineno-209-1"></a>lt_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.lt" title="torch.Tensor.lt"><code>lt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-210-1" name="__codelineno-210-1" href="#__codelineno-210-1"></a>lu(pivot=True, get_infos=False)
</code></pre></div>
<p>参见 <a href="torch.html#torch.lu" title="torch.lu"><code>torch.lu()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-211-1" name="__codelineno-211-1" href="#__codelineno-211-1"></a>lu_solve(LU_data, LU_pivots) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.lu_solve" title="torch.lu_solve"><code>torch.lu_solve()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-212-1" name="__codelineno-212-1" href="#__codelineno-212-1"></a>map_(tensor, callable)
</code></pre></div>
<p>对<code>self</code>张量中的每个元素和给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 应用<code>callable</code>，并将结果存储在<code>self</code>张量中。 <code>self</code>张量和给定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>。</p>
<p><code>callable</code>应具有签名：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-213-1" name="__codelineno-213-1" href="#__codelineno-213-1"></a>def callable(a, b) -&gt; number
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-214-1" name="__codelineno-214-1" href="#__codelineno-214-1"></a>masked_scatter_(mask, source)
</code></pre></div>
<p>在<code>mask</code>为 True 的位置将元素从<code>source</code>复制到<code>self</code>张量。 <code>mask</code>的形状必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>，并具有基础张量的形状。 <code>source</code>中的元素数量至少应与<code>mask</code>中的元素数量一样多。</p>
<p>参数</p>
<ul>
<li>
<p><strong>掩码</strong> (<a href="#torch.BoolTensor" title="torch.BoolTensor"><em>BoolTensor</em></a>)–布尔掩码</p>
</li>
<li>
<p><strong>源</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–要从中复制的张量</p>
</li>
</ul>
<p>注意</p>
<p><code>mask</code>在<code>self</code>张量上运行，而不是在给定的<code>source</code>张量上运行。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-215-1" name="__codelineno-215-1" href="#__codelineno-215-1"></a>masked_scatter(mask, tensor) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code>torch.Tensor.masked_scatter_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-216-1" name="__codelineno-216-1" href="#__codelineno-216-1"></a>masked_fill_(mask, value)
</code></pre></div>
<p>用<code>value</code>填充<code>self</code>张量的元素，其中<code>mask</code>为 True。 <code>mask</code>的形状必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>，并具有基础张量的形状。</p>
<p>参数</p>
<ul>
<li>
<p><strong>mask</strong> (<a href="#torch.BoolTensor" title="torch.BoolTensor"><em>BoolTensor</em></a>) – the boolean mask</p>
</li>
<li>
<p><strong>值</strong> (<em>python：float</em> )–要填写的值</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-217-1" name="__codelineno-217-1" href="#__codelineno-217-1"></a>masked_fill(mask, value) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code>torch.Tensor.masked_fill_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-218-1" name="__codelineno-218-1" href="#__codelineno-218-1"></a>masked_select(mask) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.masked_select" title="torch.masked_select"><code>torch.masked_select()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-219-1" name="__codelineno-219-1" href="#__codelineno-219-1"></a>matmul(tensor2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.matmul" title="torch.matmul"><code>torch.matmul()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-220-1" name="__codelineno-220-1" href="#__codelineno-220-1"></a>matrix_power(n) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.matrix_power" title="torch.matrix_power"><code>torch.matrix_power()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-221-1" name="__codelineno-221-1" href="#__codelineno-221-1"></a>max(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.max" title="torch.max"><code>torch.max()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-222-1" name="__codelineno-222-1" href="#__codelineno-222-1"></a>mean(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.mean" title="torch.mean"><code>torch.mean()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-223-1" name="__codelineno-223-1" href="#__codelineno-223-1"></a>median(dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.median" title="torch.median"><code>torch.median()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-224-1" name="__codelineno-224-1" href="#__codelineno-224-1"></a>min(dim=None, keepdim=False) -&gt; Tensor or (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.min" title="torch.min"><code>torch.min()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-225-1" name="__codelineno-225-1" href="#__codelineno-225-1"></a>mm(mat2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.mm" title="torch.mm"><code>torch.mm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-226-1" name="__codelineno-226-1" href="#__codelineno-226-1"></a>mode(dim=None, keepdim=False) -&gt; (Tensor, LongTensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.mode" title="torch.mode"><code>torch.mode()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-227-1" name="__codelineno-227-1" href="#__codelineno-227-1"></a>mul(value) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.mul" title="torch.mul"><code>torch.mul()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-228-1" name="__codelineno-228-1" href="#__codelineno-228-1"></a>mul_(value)
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.mul" title="torch.Tensor.mul"><code>mul()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-229-1" name="__codelineno-229-1" href="#__codelineno-229-1"></a>multinomial(num_samples, replacement=False, *, generator=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-230-1" name="__codelineno-230-1" href="#__codelineno-230-1"></a>mv(vec) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.mv" title="torch.mv"><code>torch.mv()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-231-1" name="__codelineno-231-1" href="#__codelineno-231-1"></a>mvlgamma(p) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.mvlgamma" title="torch.mvlgamma"><code>torch.mvlgamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-232-1" name="__codelineno-232-1" href="#__codelineno-232-1"></a>mvlgamma_(p) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>mvlgamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-233-1" name="__codelineno-233-1" href="#__codelineno-233-1"></a>narrow(dimension, start, length) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.narrow" title="torch.narrow"><code>torch.narrow()</code></a></p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-234-1" name="__codelineno-234-1" href="#__codelineno-234-1"></a>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
<a id="__codelineno-234-2" name="__codelineno-234-2" href="#__codelineno-234-2"></a>&gt;&gt;&gt; x.narrow(0, 0, 2)
<a id="__codelineno-234-3" name="__codelineno-234-3" href="#__codelineno-234-3"></a>tensor([[ 1,  2,  3],
<a id="__codelineno-234-4" name="__codelineno-234-4" href="#__codelineno-234-4"></a>        [ 4,  5,  6]])
<a id="__codelineno-234-5" name="__codelineno-234-5" href="#__codelineno-234-5"></a>&gt;&gt;&gt; x.narrow(1, 1, 2)
<a id="__codelineno-234-6" name="__codelineno-234-6" href="#__codelineno-234-6"></a>tensor([[ 2,  3],
<a id="__codelineno-234-7" name="__codelineno-234-7" href="#__codelineno-234-7"></a>        [ 5,  6],
<a id="__codelineno-234-8" name="__codelineno-234-8" href="#__codelineno-234-8"></a>        [ 8,  9]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-235-1" name="__codelineno-235-1" href="#__codelineno-235-1"></a>narrow_copy(dimension, start, length) → Tensor
</code></pre></div>
<p>与 <a href="#torch.Tensor.narrow" title="torch.Tensor.narrow"><code>Tensor.narrow()</code></a> 相同，只是返回副本而不是共享存储。 这主要用于稀疏张量，它们没有共享存储的窄方法。 用<code>dimemsion &amp;gt; self.sparse_dim()</code>调用<code>narrow_copy`将返回缩小了相关密集尺寸的副本，并相应地更新了</code>self.shape``。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-236-1" name="__codelineno-236-1" href="#__codelineno-236-1"></a>ndimension() → int
</code></pre></div>
<p>Alias for <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-237-1" name="__codelineno-237-1" href="#__codelineno-237-1"></a>ne(other) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.ne" title="torch.ne"><code>torch.ne()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-238-1" name="__codelineno-238-1" href="#__codelineno-238-1"></a>ne_(other) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.ne" title="torch.Tensor.ne"><code>ne()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-239-1" name="__codelineno-239-1" href="#__codelineno-239-1"></a>neg() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-240-1" name="__codelineno-240-1" href="#__codelineno-240-1"></a>neg_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.neg" title="torch.Tensor.neg"><code>neg()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-241-1" name="__codelineno-241-1" href="#__codelineno-241-1"></a>nelement() → int
</code></pre></div>
<p><a href="#torch.Tensor.numel" title="torch.Tensor.numel"><code>numel()</code></a> 的别名</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-242-1" name="__codelineno-242-1" href="#__codelineno-242-1"></a>nonzero() → LongTensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-243-1" name="__codelineno-243-1" href="#__codelineno-243-1"></a>norm(p=&#39;fro&#39;, dim=None, keepdim=False, dtype=None)
</code></pre></div>
<p>参见 <a href="torch.html#torch.norm" title="torch.norm"><code>torch.norm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-244-1" name="__codelineno-244-1" href="#__codelineno-244-1"></a>normal_(mean=0, std=1, *, generator=None) → Tensor
</code></pre></div>
<p>用由 <a href="torch.html#torch.mean" title="torch.mean"><code>mean</code></a> 和 <a href="torch.html#torch.std" title="torch.std"><code>std</code></a> 参数化的正态分布的元素样本填充<code>self</code>张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-245-1" name="__codelineno-245-1" href="#__codelineno-245-1"></a>numel() → int
</code></pre></div>
<p>参见 <a href="torch.html#torch.numel" title="torch.numel"><code>torch.numel()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-246-1" name="__codelineno-246-1" href="#__codelineno-246-1"></a>numpy() → numpy.ndarray
</code></pre></div>
<p>以 NumPy <code>ndarray</code>的形式返回<code>self</code>张量。 该张量和返回的<code>ndarray</code>共享相同的基础存储。 对<code>self</code>张量的更改将反映在<code>ndarray</code>中，反之亦然。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-247-1" name="__codelineno-247-1" href="#__codelineno-247-1"></a>orgqr(input2) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.orgqr" title="torch.orgqr"><code>torch.orgqr()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-248-1" name="__codelineno-248-1" href="#__codelineno-248-1"></a>ormqr(input2, input3, left=True, transpose=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.ormqr" title="torch.ormqr"><code>torch.ormqr()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-249-1" name="__codelineno-249-1" href="#__codelineno-249-1"></a>permute(*dims) → Tensor
</code></pre></div>
<p>置换此张量的尺寸。</p>
<p>参数</p>
<p><strong>*dims</strong> (<em>python：int ...</em> ) – 所需的维度顺序</p>
<p>例:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-250-1" name="__codelineno-250-1" href="#__codelineno-250-1"></a>&gt;&gt;&gt; x = torch.randn(2, 3, 5)
<a id="__codelineno-250-2" name="__codelineno-250-2" href="#__codelineno-250-2"></a>&gt;&gt;&gt; x.size()
<a id="__codelineno-250-3" name="__codelineno-250-3" href="#__codelineno-250-3"></a>torch.Size([2, 3, 5])
<a id="__codelineno-250-4" name="__codelineno-250-4" href="#__codelineno-250-4"></a>&gt;&gt;&gt; x.permute(2, 0, 1).size()
<a id="__codelineno-250-5" name="__codelineno-250-5" href="#__codelineno-250-5"></a>torch.Size([5, 2, 3])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-251-1" name="__codelineno-251-1" href="#__codelineno-251-1"></a>pin_memory() → Tensor
</code></pre></div>
<p>将张量复制到固定的内存(如果尚未固定）。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-252-1" name="__codelineno-252-1" href="#__codelineno-252-1"></a>pinverse() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-253-1" name="__codelineno-253-1" href="#__codelineno-253-1"></a>polygamma(n) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.polygamma" title="torch.polygamma"><code>torch.polygamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-254-1" name="__codelineno-254-1" href="#__codelineno-254-1"></a>polygamma_(n) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code>polygamma()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-255-1" name="__codelineno-255-1" href="#__codelineno-255-1"></a>pow(exponent) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.pow" title="torch.pow"><code>torch.pow()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-256-1" name="__codelineno-256-1" href="#__codelineno-256-1"></a>pow_(exponent) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.pow" title="torch.Tensor.pow"><code>pow()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-257-1" name="__codelineno-257-1" href="#__codelineno-257-1"></a>prod(dim=None, keepdim=False, dtype=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.prod" title="torch.prod"><code>torch.prod()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-258-1" name="__codelineno-258-1" href="#__codelineno-258-1"></a>put_(indices, tensor, accumulate=False) → Tensor
</code></pre></div>
<p>将 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 中的元素复制到索引指定的位置。 为了建立索引，将<code>self</code>张量视为一维张量。</p>
<p>If <code>accumulate</code> is <code>True</code>, the elements in <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> are added to <code>self</code>. If accumulate is <code>False</code>, the behavior is undefined if indices contain duplicate elements.</p>
<p>参数</p>
<ul>
<li>
<p><strong>索引</strong> (<em>LongTensor</em> )–自身索引</p>
</li>
<li>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–张量包含要复制的值</p>
</li>
<li>
<p><strong>accumulate</strong> (<em>bool</em>) – whether to accumulate into self</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-259-1" name="__codelineno-259-1" href="#__codelineno-259-1"></a>&gt;&gt;&gt; src = torch.tensor([[4, 3, 5],
<a id="__codelineno-259-2" name="__codelineno-259-2" href="#__codelineno-259-2"></a>                        [6, 7, 8]])
<a id="__codelineno-259-3" name="__codelineno-259-3" href="#__codelineno-259-3"></a>&gt;&gt;&gt; src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))
<a id="__codelineno-259-4" name="__codelineno-259-4" href="#__codelineno-259-4"></a>tensor([[  4,   9,   5],
<a id="__codelineno-259-5" name="__codelineno-259-5" href="#__codelineno-259-5"></a>        [ 10,   7,   8]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-260-1" name="__codelineno-260-1" href="#__codelineno-260-1"></a>qr(some=True) -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.qr" title="torch.qr"><code>torch.qr()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-261-1" name="__codelineno-261-1" href="#__codelineno-261-1"></a>qscheme() → torch.qscheme
</code></pre></div>
<p>返回给定 QTensor 的量化方案。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-262-1" name="__codelineno-262-1" href="#__codelineno-262-1"></a>q_scale() → float
</code></pre></div>
<p>给定一个通过线性(仿射）量化量化的张量，返回基础量化器(）的比例尺。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-263-1" name="__codelineno-263-1" href="#__codelineno-263-1"></a>q_zero_point() → int
</code></pre></div>
<p>给定一个通过线性(仿射）量化量化的张量，返回基础量化器(）的 zero_point。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-264-1" name="__codelineno-264-1" href="#__codelineno-264-1"></a>q_per_channel_scales() → Tensor
</code></pre></div>
<p>给定通过线性(仿射）每通道量化进行量化的张量，返回基础量化器的比例的张量。 它具有与张量的相应尺寸(来自 q_per_channel_axis）匹配的元素数量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-265-1" name="__codelineno-265-1" href="#__codelineno-265-1"></a>q_per_channel_zero_points() → Tensor
</code></pre></div>
<p>给定一个通过线性(仿射）每通道量化量化的张量，返回基础量化器的 zero_points 张量。 它具有与张量的相应尺寸(来自 q_per_channel_axis）匹配的元素数量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-266-1" name="__codelineno-266-1" href="#__codelineno-266-1"></a>q_per_channel_axis() → int
</code></pre></div>
<p>给定通过线性(仿射）每通道量化量化的张量，返回在其上应用每通道量化的尺寸索引。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-267-1" name="__codelineno-267-1" href="#__codelineno-267-1"></a>random_(from=0, to=None, *, generator=None) → Tensor
</code></pre></div>
<p>用从<code>[from, to - 1]</code>上的离散均匀分布采样的数字填充<code>self</code>张量。 如果未指定，则这些值通常仅受<code>self</code>张量的数据类型限制。 但是，对于浮点类型，如果未指定，范围将为<code>[0, 2^mantissa]</code>以确保每个值都是可表示的。 例如， &lt;cite&gt;torch.tensor(1，dtype = torch.double）.random_(）&lt;/cite&gt;在<code>[0, 2^53]</code>中将是统一的。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-268-1" name="__codelineno-268-1" href="#__codelineno-268-1"></a>reciprocal() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.reciprocal" title="torch.reciprocal"><code>torch.reciprocal()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-269-1" name="__codelineno-269-1" href="#__codelineno-269-1"></a>reciprocal_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>reciprocal()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-270-1" name="__codelineno-270-1" href="#__codelineno-270-1"></a>record_stream(stream)
</code></pre></div>
<p>确保在<code>stream</code>上排队的所有当前工作完成之前，张量存储器不会被其他张量重用。</p>
<p>注意</p>
<p>缓存分配器仅知道分配张量的流。 由于有了这种认识，它已经可以仅在一个流上正确管理张量的生命周期。 但是，如果在与原始流不同的流上使用张量，则分配器可能会意外地重用内存。 调用此方法可让分配器知道哪些流使用了张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-271-1" name="__codelineno-271-1" href="#__codelineno-271-1"></a>register_hook(hook)
</code></pre></div>
<p>注册一个倒钩。</p>
<p>每当计算相对于张量的梯度时，都会调用该挂钩。 挂钩应具有以下签名：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-272-1" name="__codelineno-272-1" href="#__codelineno-272-1"></a>hook(grad) -&gt; Tensor or None
</code></pre></div>
<p>挂钩不应修改其自变量，但可以选择返回一个新的渐变，该渐变将代替 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> 使用。</p>
<p>此函数返回带有方法<code>handle.remove()</code>的句柄，该方法可将钩子从模块中移除。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-273-1" name="__codelineno-273-1" href="#__codelineno-273-1"></a>&gt;&gt;&gt; v = torch.tensor([0., 0., 0.], requires_grad=True)
<a id="__codelineno-273-2" name="__codelineno-273-2" href="#__codelineno-273-2"></a>&gt;&gt;&gt; h = v.register_hook(lambda grad: grad * 2)  # double the gradient
<a id="__codelineno-273-3" name="__codelineno-273-3" href="#__codelineno-273-3"></a>&gt;&gt;&gt; v.backward(torch.tensor([1., 2., 3.]))
<a id="__codelineno-273-4" name="__codelineno-273-4" href="#__codelineno-273-4"></a>&gt;&gt;&gt; v.grad
<a id="__codelineno-273-5" name="__codelineno-273-5" href="#__codelineno-273-5"></a>
<a id="__codelineno-273-6" name="__codelineno-273-6" href="#__codelineno-273-6"></a> 2
<a id="__codelineno-273-7" name="__codelineno-273-7" href="#__codelineno-273-7"></a> 4
<a id="__codelineno-273-8" name="__codelineno-273-8" href="#__codelineno-273-8"></a> 6
<a id="__codelineno-273-9" name="__codelineno-273-9" href="#__codelineno-273-9"></a>[torch.FloatTensor of size (3,)]
<a id="__codelineno-273-10" name="__codelineno-273-10" href="#__codelineno-273-10"></a>
<a id="__codelineno-273-11" name="__codelineno-273-11" href="#__codelineno-273-11"></a>&gt;&gt;&gt; h.remove()  # removes the hook
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-274-1" name="__codelineno-274-1" href="#__codelineno-274-1"></a>remainder(divisor) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-275-1" name="__codelineno-275-1" href="#__codelineno-275-1"></a>remainder_(divisor) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>remainder()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-276-1" name="__codelineno-276-1" href="#__codelineno-276-1"></a>real() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.real" title="torch.real"><code>torch.real()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-277-1" name="__codelineno-277-1" href="#__codelineno-277-1"></a>renorm(p, dim, maxnorm) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.renorm" title="torch.renorm"><code>torch.renorm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-278-1" name="__codelineno-278-1" href="#__codelineno-278-1"></a>renorm_(p, dim, maxnorm) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>renorm()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-279-1" name="__codelineno-279-1" href="#__codelineno-279-1"></a>repeat(*sizes) → Tensor
</code></pre></div>
<p>沿指定尺寸重复此张量。</p>
<p>与 <a href="#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand()</code></a> 不同，此功能复制张量的数据。</p>
<p>警告</p>
<p><code>torch.repeat()</code>的行为与 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html">numpy.repeat</a> 不同，但更类似于 <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html">numpy.tile</a> 。 对于类似于 &lt;cite&gt;numpy.repeat&lt;/cite&gt; 的运算符，请参见 <a href="torch.html#torch.repeat_interleave" title="torch.repeat_interleave"><code>torch.repeat_interleave()</code></a> 。</p>
<p>参数</p>
<p><strong>大小</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–在每个维度上重复此张量的次数</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-280-1" name="__codelineno-280-1" href="#__codelineno-280-1"></a>&gt;&gt;&gt; x = torch.tensor([1, 2, 3])
<a id="__codelineno-280-2" name="__codelineno-280-2" href="#__codelineno-280-2"></a>&gt;&gt;&gt; x.repeat(4, 2)
<a id="__codelineno-280-3" name="__codelineno-280-3" href="#__codelineno-280-3"></a>tensor([[ 1,  2,  3,  1,  2,  3],
<a id="__codelineno-280-4" name="__codelineno-280-4" href="#__codelineno-280-4"></a>        [ 1,  2,  3,  1,  2,  3],
<a id="__codelineno-280-5" name="__codelineno-280-5" href="#__codelineno-280-5"></a>        [ 1,  2,  3,  1,  2,  3],
<a id="__codelineno-280-6" name="__codelineno-280-6" href="#__codelineno-280-6"></a>        [ 1,  2,  3,  1,  2,  3]])
<a id="__codelineno-280-7" name="__codelineno-280-7" href="#__codelineno-280-7"></a>&gt;&gt;&gt; x.repeat(4, 2, 1).size()
<a id="__codelineno-280-8" name="__codelineno-280-8" href="#__codelineno-280-8"></a>torch.Size([4, 2, 3])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-281-1" name="__codelineno-281-1" href="#__codelineno-281-1"></a>repeat_interleave(repeats, dim=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.repeat_interleave" title="torch.repeat_interleave"><code>torch.repeat_interleave()</code></a> 。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-282-1" name="__codelineno-282-1" href="#__codelineno-282-1"></a>requires_grad
</code></pre></div>
<p>如果需要为此张量计算梯度，则为<code>True</code>，否则为<code>False</code>。</p>
<p>注意</p>
<p>需要为张量计算梯度的事实并不意味着将填充 <a href="autograd.html#torch.Tensor.grad" title="torch.Tensor.grad"><code>grad</code></a> 属性，有关更多详细信息，请参见 <a href="autograd.html#torch.Tensor.is_leaf" title="torch.Tensor.is_leaf"><code>is_leaf</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-283-1" name="__codelineno-283-1" href="#__codelineno-283-1"></a>requires_grad_(requires_grad=True) → Tensor
</code></pre></div>
<p>更改 autograd 是否应记录该张量上的操作：适当地设置此张量的 <a href="autograd.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> 属性。 返回此张量。</p>
<p><a href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> 的主要用例是告诉 autograd 在 Tensor <code>tensor</code>上开始记录操作。 如果<code>tensor</code>具有<code>requires_grad=False</code>(因为它是通过 DataLoader 获得的，或者需要进行预处理或初始化），则<code>tensor.requires_grad_()</code>将其设置为使 autograd 将开始在<code>tensor</code>上记录操作。</p>
<p>参数</p>
<p><strong>require_grad</strong>  (<em>bool</em> )–如果 autograd 应该在该张量上记录操作。 默认值：<code>True</code>。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-284-1" name="__codelineno-284-1" href="#__codelineno-284-1"></a>&gt;&gt;&gt; # Let&#39;s say we want to preprocess some saved weights and use
<a id="__codelineno-284-2" name="__codelineno-284-2" href="#__codelineno-284-2"></a>&gt;&gt;&gt; # the result as new weights.
<a id="__codelineno-284-3" name="__codelineno-284-3" href="#__codelineno-284-3"></a>&gt;&gt;&gt; saved_weights = [0.1, 0.2, 0.3, 0.25]
<a id="__codelineno-284-4" name="__codelineno-284-4" href="#__codelineno-284-4"></a>&gt;&gt;&gt; loaded_weights = torch.tensor(saved_weights)
<a id="__codelineno-284-5" name="__codelineno-284-5" href="#__codelineno-284-5"></a>&gt;&gt;&gt; weights = preprocess(loaded_weights)  # some function
<a id="__codelineno-284-6" name="__codelineno-284-6" href="#__codelineno-284-6"></a>&gt;&gt;&gt; weights
<a id="__codelineno-284-7" name="__codelineno-284-7" href="#__codelineno-284-7"></a>tensor([-0.5503,  0.4926, -2.1158, -0.8303])
<a id="__codelineno-284-8" name="__codelineno-284-8" href="#__codelineno-284-8"></a>
<a id="__codelineno-284-9" name="__codelineno-284-9" href="#__codelineno-284-9"></a>&gt;&gt;&gt; # Now, start to record operations done to weights
<a id="__codelineno-284-10" name="__codelineno-284-10" href="#__codelineno-284-10"></a>&gt;&gt;&gt; weights.requires_grad_()
<a id="__codelineno-284-11" name="__codelineno-284-11" href="#__codelineno-284-11"></a>&gt;&gt;&gt; out = weights.pow(2).sum()
<a id="__codelineno-284-12" name="__codelineno-284-12" href="#__codelineno-284-12"></a>&gt;&gt;&gt; out.backward()
<a id="__codelineno-284-13" name="__codelineno-284-13" href="#__codelineno-284-13"></a>&gt;&gt;&gt; weights.grad
<a id="__codelineno-284-14" name="__codelineno-284-14" href="#__codelineno-284-14"></a>tensor([-1.1007,  0.9853, -4.2316, -1.6606])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-285-1" name="__codelineno-285-1" href="#__codelineno-285-1"></a>reshape(*shape) → Tensor
</code></pre></div>
<p>返回具有与<code>self</code>相同的数据和元素数量但具有指定形状的张量。 如果<code>shape</code>与当前形状兼容，则此方法返回一个视图。 当可以返回视图时，请参见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 。</p>
<p>参见 <a href="torch.html#torch.reshape" title="torch.reshape"><code>torch.reshape()</code></a></p>
<p>参数</p>
<p><strong>形状</strong> (<em>python：ints 的元组</em> <em>或</em> <em>python：int ...</em> )–所需的形状</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-286-1" name="__codelineno-286-1" href="#__codelineno-286-1"></a>reshape_as(other) → Tensor
</code></pre></div>
<p>以与<code>other</code>相同的形状返回此张量。 <code>self.reshape_as(other)</code>等效于<code>self.reshape(other.sizes())</code>。 如果<code>other.sizes()</code>与当前形状兼容，则此方法返回视图。 何时可以返回视图，请参见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>torch.Tensor.view()</code></a> 。</p>
<p>有关<code>reshape</code>的更多信息，请参见 <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a> 。</p>
<p>参数</p>
<p><strong>其他</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>)–结果张量具有与<code>other</code>相同的形状。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-287-1" name="__codelineno-287-1" href="#__codelineno-287-1"></a>resize_(*sizes) → Tensor
</code></pre></div>
<p>将<code>self</code>张量调整为指定大小。 如果元素数量大于当前存储大小，那么将调整基础存储的大小以适合新的元素数量。 如果元素数较小，则基础存储不会更改。 现有元素将保留，但任何新内存均未初始化。</p>
<p>警告</p>
<p>这是一种底层方法。 将存储重新解释为 C 连续的，而忽略当前步幅(除非目标大小等于当前大小，在这种情况下，张量保持不变）。 对于大多数目的，您将改为使用 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a> (检查连续性），或使用 <a href="#torch.Tensor.reshape" title="torch.Tensor.reshape"><code>reshape()</code></a> (如果需要，可复制数据）。 要使用自定义步幅就地更改大小，请参见 <a href="#torch.Tensor.set_" title="torch.Tensor.set_"><code>set_()</code></a> 。</p>
<p>参数</p>
<p><strong>大小</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–所需大小</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-288-1" name="__codelineno-288-1" href="#__codelineno-288-1"></a>&gt;&gt;&gt; x = torch.tensor([[1, 2], [3, 4], [5, 6]])
<a id="__codelineno-288-2" name="__codelineno-288-2" href="#__codelineno-288-2"></a>&gt;&gt;&gt; x.resize_(2, 2)
<a id="__codelineno-288-3" name="__codelineno-288-3" href="#__codelineno-288-3"></a>tensor([[ 1,  2],
<a id="__codelineno-288-4" name="__codelineno-288-4" href="#__codelineno-288-4"></a>        [ 3,  4]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-289-1" name="__codelineno-289-1" href="#__codelineno-289-1"></a>resize_as_(tensor) → Tensor
</code></pre></div>
<p>将<code>self</code>张量调整为与指定的 <a href="torch.html#torch.tensor" title="torch.tensor"><code>tensor</code></a> 相同的大小。 这等效于<code>self.resize_(tensor.size())</code>。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-290-1" name="__codelineno-290-1" href="#__codelineno-290-1"></a>retain_grad()
</code></pre></div>
<p>为非叶张量启用.grad 属性。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-291-1" name="__codelineno-291-1" href="#__codelineno-291-1"></a>rfft(signal_ndim, normalized=False, onesided=True) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.rfft" title="torch.rfft"><code>torch.rfft()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-292-1" name="__codelineno-292-1" href="#__codelineno-292-1"></a>roll(shifts, dims) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.roll" title="torch.roll"><code>torch.roll()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-293-1" name="__codelineno-293-1" href="#__codelineno-293-1"></a>rot90(k, dims) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.rot90" title="torch.rot90"><code>torch.rot90()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-294-1" name="__codelineno-294-1" href="#__codelineno-294-1"></a>round() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.round" title="torch.round"><code>torch.round()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-295-1" name="__codelineno-295-1" href="#__codelineno-295-1"></a>round_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.round" title="torch.Tensor.round"><code>round()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-296-1" name="__codelineno-296-1" href="#__codelineno-296-1"></a>rsqrt() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.rsqrt" title="torch.rsqrt"><code>torch.rsqrt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-297-1" name="__codelineno-297-1" href="#__codelineno-297-1"></a>rsqrt_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>rsqrt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-298-1" name="__codelineno-298-1" href="#__codelineno-298-1"></a>scatter(dim, index, source) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>torch.Tensor.scatter_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-299-1" name="__codelineno-299-1" href="#__codelineno-299-1"></a>scatter_(dim, index, src) → Tensor
</code></pre></div>
<p>将张量<code>src</code>中的所有值写入<code>index</code>张量中指定的索引处的<code>self</code>中。 对于<code>src</code>中的每个值，其输出索引由<code>dimension != dim</code>的<code>src</code>中的索引以及<code>dimension = dim</code>的<code>index</code>中的相应值指定。</p>
<p>对于 3-D 张量，<code>self</code>更新为：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-300-1" name="__codelineno-300-1" href="#__codelineno-300-1"></a>self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0
<a id="__codelineno-300-2" name="__codelineno-300-2" href="#__codelineno-300-2"></a>self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1
<a id="__codelineno-300-3" name="__codelineno-300-3" href="#__codelineno-300-3"></a>self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2
</code></pre></div>
<p>这是 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a> 中描述的方式的相反操作。</p>
<p><code>self</code>，<code>index</code>和<code>src</code>(如果是张量）应具有相同数量的尺寸。 还要求对于所有尺寸<code>d</code>均为<code>index.size(d) &amp;lt;= src.size(d)</code>，并且对于所有尺寸<code>d != dim</code>均要求<code>index.size(d) &amp;lt;= self.size(d)</code>。</p>
<p>此外，对于 <a href="#torch.Tensor.gather" title="torch.Tensor.gather"><code>gather()</code></a> ，<code>index</code>的值必须介于<code>0</code>和<code>self.size(dim) - 1</code>之间，且沿指定尺寸 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 必须是唯一的。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> ) – 沿其索引的轴</p>
</li>
<li>
<p><strong>index</strong> (<em>LongTensor</em> ) – 要散布的元素的索引可以为空或 src 的大小相同。 如果为空，则操作返回标识</p>
</li>
<li>
<p><strong>src</strong>  (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>) – 要散布的源元素，如果未指定_值_</p>
</li>
<li>
<p><strong>value</strong> (<em>python：float</em> ) – 要分散的源元素，如果未指定_src_</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-301-1" name="__codelineno-301-1" href="#__codelineno-301-1"></a>&gt;&gt;&gt; x = torch.rand(2, 5)
<a id="__codelineno-301-2" name="__codelineno-301-2" href="#__codelineno-301-2"></a>&gt;&gt;&gt; x
<a id="__codelineno-301-3" name="__codelineno-301-3" href="#__codelineno-301-3"></a>tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],
<a id="__codelineno-301-4" name="__codelineno-301-4" href="#__codelineno-301-4"></a>        [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])
<a id="__codelineno-301-5" name="__codelineno-301-5" href="#__codelineno-301-5"></a>&gt;&gt;&gt; torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)
<a id="__codelineno-301-6" name="__codelineno-301-6" href="#__codelineno-301-6"></a>tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],
<a id="__codelineno-301-7" name="__codelineno-301-7" href="#__codelineno-301-7"></a>        [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],
<a id="__codelineno-301-8" name="__codelineno-301-8" href="#__codelineno-301-8"></a>        [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])
<a id="__codelineno-301-9" name="__codelineno-301-9" href="#__codelineno-301-9"></a>
<a id="__codelineno-301-10" name="__codelineno-301-10" href="#__codelineno-301-10"></a>&gt;&gt;&gt; z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)
<a id="__codelineno-301-11" name="__codelineno-301-11" href="#__codelineno-301-11"></a>&gt;&gt;&gt; z
<a id="__codelineno-301-12" name="__codelineno-301-12" href="#__codelineno-301-12"></a>tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],
<a id="__codelineno-301-13" name="__codelineno-301-13" href="#__codelineno-301-13"></a>        [ 0.0000,  0.0000,  0.0000,  1.2300]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-302-1" name="__codelineno-302-1" href="#__codelineno-302-1"></a>scatter_add_(dim, index, other) → Tensor
</code></pre></div>
<p>将张量<code>other</code>中的所有值添加到<code>index</code>张量中指定的索引处的<code>self</code>中，其方式与 <a href="#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>scatter_()</code></a> 相似。 对于<code>other</code>中的每个值，将其添加到<code>self</code>中的索引，该索引由<code>dimension != dim</code>中的<code>other</code>中的索引和<code>dimension = dim</code>中的<code>index</code>中的对应值指定。</p>
<p>For a 3-D tensor, <code>self</code> is updated as:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-303-1" name="__codelineno-303-1" href="#__codelineno-303-1"></a>self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0
<a id="__codelineno-303-2" name="__codelineno-303-2" href="#__codelineno-303-2"></a>self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1
<a id="__codelineno-303-3" name="__codelineno-303-3" href="#__codelineno-303-3"></a>self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2
</code></pre></div>
<p><code>self</code>，<code>index</code>和<code>other</code>应具有相同的尺寸数。 还要求对于所有尺寸<code>d</code>均为<code>index.size(d) &amp;lt;= other.size(d)</code>，并且对于所有尺寸<code>d != dim</code>均要求<code>index.size(d) &amp;lt;= self.size(d)</code>。</p>
<p>注意</p>
<p>When using the CUDA backend, this operation may induce nondeterministic behaviour that is not easily switched off. Please see the 注意s on <a href="注意s/randomness.html">Reproducibility</a> for background.</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – the axis along which to index</p>
</li>
<li>
<p><strong>index</strong> (<em>LongTensor</em> ) – 分散和添加元素的索引，可以为空或 src 大小相同。 为空时，该操作将返回标识。</p>
</li>
<li>
<p><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>) – 分散和添加的源元素</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-304-1" name="__codelineno-304-1" href="#__codelineno-304-1"></a>&gt;&gt;&gt; x = torch.rand(2, 5)
<a id="__codelineno-304-2" name="__codelineno-304-2" href="#__codelineno-304-2"></a>&gt;&gt;&gt; x
<a id="__codelineno-304-3" name="__codelineno-304-3" href="#__codelineno-304-3"></a>tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],
<a id="__codelineno-304-4" name="__codelineno-304-4" href="#__codelineno-304-4"></a>        [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])
<a id="__codelineno-304-5" name="__codelineno-304-5" href="#__codelineno-304-5"></a>&gt;&gt;&gt; torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)
<a id="__codelineno-304-6" name="__codelineno-304-6" href="#__codelineno-304-6"></a>tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],
<a id="__codelineno-304-7" name="__codelineno-304-7" href="#__codelineno-304-7"></a>        [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],
<a id="__codelineno-304-8" name="__codelineno-304-8" href="#__codelineno-304-8"></a>        [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-305-1" name="__codelineno-305-1" href="#__codelineno-305-1"></a>scatter_add(dim, index, source) → Tensor
</code></pre></div>
<p><a href="#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>torch.Tensor.scatter_add_()</code></a> 的替代版本</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-306-1" name="__codelineno-306-1" href="#__codelineno-306-1"></a>select(dim, index) → Tensor
</code></pre></div>
<p>沿选定维度在给定索引处切片<code>self</code>张量。 该函数返回一个张量，其中给定尺寸被移除。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> )–切片的尺寸</p>
</li>
<li>
<p><strong>索引</strong> (<em>python：int</em> )–要选择的索引</p>
</li>
</ul>
<p>注意</p>
<p><a href="#torch.Tensor.select" title="torch.Tensor.select"><code>select()</code></a> 相当于切片。 例如，<code>tensor.select(0, index)</code>等效于<code>tensor[index]</code>，<code>tensor.select(2, index)</code>等效于<code>tensor[:,:,index]</code>。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-307-1" name="__codelineno-307-1" href="#__codelineno-307-1"></a>set_(source=None, storage_offset=0, size=None, stride=None) → Tensor
</code></pre></div>
<p>设置基础存储空间，大小和跨度。 如果<code>source</code>是张量，则<code>self</code>张量将与<code>source</code>共享相同的存储空间并具有相同的大小和跨度。 一个张量中元素的变化将反映在另一个张量中。</p>
<p>如果<code>source</code>是<code>Storage</code>，则该方法设置基础存储，偏移，大小和跨度。</p>
<p>参数</p>
<ul>
<li>
<p><strong>源</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a> <em>或</em> <em>存储器</em>）–使用的张量或存储器</p>
</li>
<li>
<p><strong>storage_offset</strong>  (<em>python：int</em> <em>，</em> <em>可选</em>）–存储中的偏移量</p>
</li>
<li>
<p><strong>大小</strong>(<em>torch大小</em> <em>，</em> <em>可选</em>）–所需大小。 默认为源大小。</p>
</li>
<li>
<p><strong>步幅</strong>(<em>元组</em> <em>，</em> <em>可选</em>）–所需的步幅。 默认为 C 连续跨步。</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-308-1" name="__codelineno-308-1" href="#__codelineno-308-1"></a>share_memory_()
</code></pre></div>
<p>将基础存储移动到共享内存。</p>
<p>如果基础存储已经在共享内存中并且用于 CUDA 张量，则此操作不可操作。 共享内存中的张量无法调整大小。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-309-1" name="__codelineno-309-1" href="#__codelineno-309-1"></a>short() → Tensor
</code></pre></div>
<p><code>self.short()</code>等效于<code>self.to(torch.int16)</code>。 参见 <a href="#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-310-1" name="__codelineno-310-1" href="#__codelineno-310-1"></a>sigmoid() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.sigmoid" title="torch.sigmoid"><code>torch.sigmoid()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-311-1" name="__codelineno-311-1" href="#__codelineno-311-1"></a>sigmoid_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>sigmoid()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-312-1" name="__codelineno-312-1" href="#__codelineno-312-1"></a>sign() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.sign" title="torch.sign"><code>torch.sign()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-313-1" name="__codelineno-313-1" href="#__codelineno-313-1"></a>sign_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.sign" title="torch.Tensor.sign"><code>sign()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-314-1" name="__codelineno-314-1" href="#__codelineno-314-1"></a>sin() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.sin" title="torch.sin"><code>torch.sin()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-315-1" name="__codelineno-315-1" href="#__codelineno-315-1"></a>sin_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.sin" title="torch.Tensor.sin"><code>sin()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-316-1" name="__codelineno-316-1" href="#__codelineno-316-1"></a>sinh() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.sinh" title="torch.sinh"><code>torch.sinh()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-317-1" name="__codelineno-317-1" href="#__codelineno-317-1"></a>sinh_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>sinh()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-318-1" name="__codelineno-318-1" href="#__codelineno-318-1"></a>size() → torch.Size
</code></pre></div>
<p>返回<code>self</code>张量的大小。 返回的值是<code>tuple</code>的子类。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-319-1" name="__codelineno-319-1" href="#__codelineno-319-1"></a>&gt;&gt;&gt; torch.empty(3, 4, 5).size()
<a id="__codelineno-319-2" name="__codelineno-319-2" href="#__codelineno-319-2"></a>torch.Size([3, 4, 5])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-320-1" name="__codelineno-320-1" href="#__codelineno-320-1"></a>slogdet() -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-321-1" name="__codelineno-321-1" href="#__codelineno-321-1"></a>solve(A) → Tensor, Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.solve" title="torch.solve"><code>torch.solve()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-322-1" name="__codelineno-322-1" href="#__codelineno-322-1"></a>sort(dim=-1, descending=False) -&gt; (Tensor, LongTensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.sort" title="torch.sort"><code>torch.sort()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-323-1" name="__codelineno-323-1" href="#__codelineno-323-1"></a>split(split_size, dim=0)
</code></pre></div>
<p>参见 <a href="torch.html#torch.split" title="torch.split"><code>torch.split()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-324-1" name="__codelineno-324-1" href="#__codelineno-324-1"></a>sparse_mask(input, mask) → Tensor
</code></pre></div>
<p>返回一个新的 SparseTensor，其 Tensor <code>input</code>中的值被<code>mask</code>的索引过滤，并且值被忽略。 <code>input</code>和<code>mask</code>必须具有相同的形状。</p>
<p>参数</p>
<ul>
<li>
<p><strong>input</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–输入张量</p>
</li>
<li>
<p><strong>mask</strong> (<em>SparseTensor</em> )–我们根据其索引过滤<code>input</code>的 SparseTensor</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-325-1" name="__codelineno-325-1" href="#__codelineno-325-1"></a>&gt;&gt;&gt; nnz = 5
<a id="__codelineno-325-2" name="__codelineno-325-2" href="#__codelineno-325-2"></a>&gt;&gt;&gt; dims = [5, 5, 2, 2]
<a id="__codelineno-325-3" name="__codelineno-325-3" href="#__codelineno-325-3"></a>&gt;&gt;&gt; I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),
<a id="__codelineno-325-4" name="__codelineno-325-4" href="#__codelineno-325-4"></a>                   torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)
<a id="__codelineno-325-5" name="__codelineno-325-5" href="#__codelineno-325-5"></a>&gt;&gt;&gt; V = torch.randn(nnz, dims[2], dims[3])
<a id="__codelineno-325-6" name="__codelineno-325-6" href="#__codelineno-325-6"></a>&gt;&gt;&gt; size = torch.Size(dims)
<a id="__codelineno-325-7" name="__codelineno-325-7" href="#__codelineno-325-7"></a>&gt;&gt;&gt; S = torch.sparse_coo_tensor(I, V, size).coalesce()
<a id="__codelineno-325-8" name="__codelineno-325-8" href="#__codelineno-325-8"></a>&gt;&gt;&gt; D = torch.randn(dims)
<a id="__codelineno-325-9" name="__codelineno-325-9" href="#__codelineno-325-9"></a>&gt;&gt;&gt; D.sparse_mask(S)
<a id="__codelineno-325-10" name="__codelineno-325-10" href="#__codelineno-325-10"></a>tensor(indices=tensor([[0, 0, 0, 2],
<a id="__codelineno-325-11" name="__codelineno-325-11" href="#__codelineno-325-11"></a>                       [0, 1, 4, 3]]),
<a id="__codelineno-325-12" name="__codelineno-325-12" href="#__codelineno-325-12"></a>       values=tensor([[[ 1.6550,  0.2397],
<a id="__codelineno-325-13" name="__codelineno-325-13" href="#__codelineno-325-13"></a>                       [-0.1611, -0.0779]],
<a id="__codelineno-325-14" name="__codelineno-325-14" href="#__codelineno-325-14"></a>
<a id="__codelineno-325-15" name="__codelineno-325-15" href="#__codelineno-325-15"></a>                      [[ 0.2326, -1.0558],
<a id="__codelineno-325-16" name="__codelineno-325-16" href="#__codelineno-325-16"></a>                       [ 1.4711,  1.9678]],
<a id="__codelineno-325-17" name="__codelineno-325-17" href="#__codelineno-325-17"></a>
<a id="__codelineno-325-18" name="__codelineno-325-18" href="#__codelineno-325-18"></a>                      [[-0.5138, -0.0411],
<a id="__codelineno-325-19" name="__codelineno-325-19" href="#__codelineno-325-19"></a>                       [ 1.9417,  0.5158]],
<a id="__codelineno-325-20" name="__codelineno-325-20" href="#__codelineno-325-20"></a>
<a id="__codelineno-325-21" name="__codelineno-325-21" href="#__codelineno-325-21"></a>                      [[ 0.0793,  0.0036],
<a id="__codelineno-325-22" name="__codelineno-325-22" href="#__codelineno-325-22"></a>                       [-0.2569, -0.1055]]]),
<a id="__codelineno-325-23" name="__codelineno-325-23" href="#__codelineno-325-23"></a>       size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-326-1" name="__codelineno-326-1" href="#__codelineno-326-1"></a>sparse_dim() → int
</code></pre></div>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回稀疏维度的数量。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.dense_dim" title="torch.Tensor.dense_dim"><code>Tensor.dense_dim()</code></a> 。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-327-1" name="__codelineno-327-1" href="#__codelineno-327-1"></a>sqrt() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.sqrt" title="torch.sqrt"><code>torch.sqrt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-328-1" name="__codelineno-328-1" href="#__codelineno-328-1"></a>sqrt_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>sqrt()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-329-1" name="__codelineno-329-1" href="#__codelineno-329-1"></a>squeeze(dim=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-330-1" name="__codelineno-330-1" href="#__codelineno-330-1"></a>squeeze_(dim=None) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>squeeze()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-331-1" name="__codelineno-331-1" href="#__codelineno-331-1"></a>std(dim=None, unbiased=True, keepdim=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.std" title="torch.std"><code>torch.std()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-332-1" name="__codelineno-332-1" href="#__codelineno-332-1"></a>stft(n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode=&#39;reflect&#39;, normalized=False, onesided=True)
</code></pre></div>
<p>参见 <a href="torch.html#torch.stft" title="torch.stft"><code>torch.stft()</code></a></p>
<p>警告</p>
<p>此功能在版本 0.4.1 更改了签名。 使用前一个签名进行调用可能会导致错误或返回错误的结果。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-333-1" name="__codelineno-333-1" href="#__codelineno-333-1"></a>storage() → torch.Storage
</code></pre></div>
<p>返回基础存储。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-334-1" name="__codelineno-334-1" href="#__codelineno-334-1"></a>storage_offset() → int
</code></pre></div>
<p>根据存储元素的数量(不是字节），返回基础存储中的<code>self</code>张量偏移量。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-335-1" name="__codelineno-335-1" href="#__codelineno-335-1"></a>&gt;&gt;&gt; x = torch.tensor([1, 2, 3, 4, 5])
<a id="__codelineno-335-2" name="__codelineno-335-2" href="#__codelineno-335-2"></a>&gt;&gt;&gt; x.storage_offset()
<a id="__codelineno-335-3" name="__codelineno-335-3" href="#__codelineno-335-3"></a>0
<a id="__codelineno-335-4" name="__codelineno-335-4" href="#__codelineno-335-4"></a>&gt;&gt;&gt; x[3:].storage_offset()
<a id="__codelineno-335-5" name="__codelineno-335-5" href="#__codelineno-335-5"></a>3
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-336-1" name="__codelineno-336-1" href="#__codelineno-336-1"></a>storage_type() → type
</code></pre></div>
<p>返回基础存储的类型。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-337-1" name="__codelineno-337-1" href="#__codelineno-337-1"></a>stride(dim) → tuple or int
</code></pre></div>
<p>返回<code>self</code>张量的步幅。</p>
<p>跨度是在指定尺寸 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 中从一个元素跳至下一元素所需的跳跃。 当未传递任何参数时，将返回所有跨度的元组。否则，将返回整数值作为特定维度 <a href="#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a> 中的跨度。</p>
<p>参数</p>
<p><strong>dim</strong> (<em>python：int</em> <em>，</em> <em>可选</em>）– 需要跨度的所需尺寸</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-338-1" name="__codelineno-338-1" href="#__codelineno-338-1"></a>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
<a id="__codelineno-338-2" name="__codelineno-338-2" href="#__codelineno-338-2"></a>&gt;&gt;&gt; x.stride()
<a id="__codelineno-338-3" name="__codelineno-338-3" href="#__codelineno-338-3"></a>(5, 1)
<a id="__codelineno-338-4" name="__codelineno-338-4" href="#__codelineno-338-4"></a>&gt;&gt;&gt;x.stride(0)
<a id="__codelineno-338-5" name="__codelineno-338-5" href="#__codelineno-338-5"></a>5
<a id="__codelineno-338-6" name="__codelineno-338-6" href="#__codelineno-338-6"></a>&gt;&gt;&gt; x.stride(-1)
<a id="__codelineno-338-7" name="__codelineno-338-7" href="#__codelineno-338-7"></a>1
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-339-1" name="__codelineno-339-1" href="#__codelineno-339-1"></a>sub(value, other) → Tensor
</code></pre></div>
<p>从<code>self</code>张量中减去标量或张量。 如果同时指定了<code>value</code>和<code>other</code>，则在使用前<code>other</code>的每个元素都会按<code>value</code>缩放。</p>
<p>当<code>other</code>是张量时，<code>other</code>的形状必须是<a href="注意s/broadcasting.html#broadcasting-semantics">可广播的</a>，并具有基础张量的形状。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-340-1" name="__codelineno-340-1" href="#__codelineno-340-1"></a>sub_(x) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.sub" title="torch.Tensor.sub"><code>sub()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-341-1" name="__codelineno-341-1" href="#__codelineno-341-1"></a>sum(dim=None, keepdim=False, dtype=None) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.sum" title="torch.sum"><code>torch.sum()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-342-1" name="__codelineno-342-1" href="#__codelineno-342-1"></a>sum_to_size(*size) → Tensor
</code></pre></div>
<p>将<code>this</code>张量与 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 相加。 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 必须可广播到<code>this</code>张量大小。</p>
<p>参数</p>
<p><strong>大小</strong> (<em>python：int ...</em> )–定义输出张量形状的整数序列。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-343-1" name="__codelineno-343-1" href="#__codelineno-343-1"></a>svd(some=True, compute_uv=True) -&gt; (Tensor, Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.svd" title="torch.svd"><code>torch.svd()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-344-1" name="__codelineno-344-1" href="#__codelineno-344-1"></a>symeig(eigenvectors=False, upper=True) -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.symeig" title="torch.symeig"><code>torch.symeig()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-345-1" name="__codelineno-345-1" href="#__codelineno-345-1"></a>t() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.t" title="torch.t"><code>torch.t()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-346-1" name="__codelineno-346-1" href="#__codelineno-346-1"></a>t_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.t" title="torch.Tensor.t"><code>t()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-347-1" name="__codelineno-347-1" href="#__codelineno-347-1"></a>to(*args, **kwargs) → Tensor
</code></pre></div>
<p>执行 Tensor dtype 和/或设备转换。 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 是从<code>self.to(*args, **kwargs)</code>的论点推论出来的。</p>
<p>注意</p>
<p>如果<code>self</code>张量已经具有正确的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> ，则返回<code>self</code>。 否则，返回的张量是<code>self</code>与所需 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 的副本。</p>
<p>以下是调用<code>to</code>的方法：</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-348-1" name="__codelineno-348-1" href="#__codelineno-348-1"></a>to(dtype, non_blocking=False, copy=False) → Tensor
</code></pre></div>
<p>返回具有指定<code>dtype</code>的张量</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-349-1" name="__codelineno-349-1" href="#__codelineno-349-1"></a>to(device=None, dtype=None, non_blocking=False, copy=False) → Tensor
</code></pre></div>
<p>返回具有指定 <a href="#torch.Tensor.device" title="torch.Tensor.device"><code>device</code></a> 和(可选）<code>dtype</code>的张量。 如果<code>dtype</code>为<code>None</code>，则推断为<code>self.dtype</code>。 当<code>non_blocking</code>时，如果可能，尝试相对于主机进行异步转换，例如，将具有固定内存的 CPU 张量转换为 CUDA 张量。 设置<code>copy</code>时，即使张量已经匹配所需的转换，也会创建新的张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-350-1" name="__codelineno-350-1" href="#__codelineno-350-1"></a>to(other, non_blocking=False, copy=False) → Tensor
</code></pre></div>
<p>返回与张量<code>other</code>相同的 <a href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> 和 <a href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><code>torch.device</code></a> 的张量。 当<code>non_blocking</code>时，如果可能，尝试相对于主机进行异步转换，例如，将具有固定内存的 CPU 张量转换为 CUDA 张量。 设置<code>copy</code>时，即使张量已经与所需的转换匹配，也会创建新的张量。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-351-1" name="__codelineno-351-1" href="#__codelineno-351-1"></a>&gt;&gt;&gt; tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu
<a id="__codelineno-351-2" name="__codelineno-351-2" href="#__codelineno-351-2"></a>&gt;&gt;&gt; tensor.to(torch.float64)
<a id="__codelineno-351-3" name="__codelineno-351-3" href="#__codelineno-351-3"></a>tensor([[-0.5044,  0.0005],
<a id="__codelineno-351-4" name="__codelineno-351-4" href="#__codelineno-351-4"></a>        [ 0.3310, -0.0584]], dtype=torch.float64)
<a id="__codelineno-351-5" name="__codelineno-351-5" href="#__codelineno-351-5"></a>
<a id="__codelineno-351-6" name="__codelineno-351-6" href="#__codelineno-351-6"></a>&gt;&gt;&gt; cuda0 = torch.device(&#39;cuda:0&#39;)
<a id="__codelineno-351-7" name="__codelineno-351-7" href="#__codelineno-351-7"></a>&gt;&gt;&gt; tensor.to(cuda0)
<a id="__codelineno-351-8" name="__codelineno-351-8" href="#__codelineno-351-8"></a>tensor([[-0.5044,  0.0005],
<a id="__codelineno-351-9" name="__codelineno-351-9" href="#__codelineno-351-9"></a>        [ 0.3310, -0.0584]], device=&#39;cuda:0&#39;)
<a id="__codelineno-351-10" name="__codelineno-351-10" href="#__codelineno-351-10"></a>
<a id="__codelineno-351-11" name="__codelineno-351-11" href="#__codelineno-351-11"></a>&gt;&gt;&gt; tensor.to(cuda0, dtype=torch.float64)
<a id="__codelineno-351-12" name="__codelineno-351-12" href="#__codelineno-351-12"></a>tensor([[-0.5044,  0.0005],
<a id="__codelineno-351-13" name="__codelineno-351-13" href="#__codelineno-351-13"></a>        [ 0.3310, -0.0584]], dtype=torch.float64, device=&#39;cuda:0&#39;)
<a id="__codelineno-351-14" name="__codelineno-351-14" href="#__codelineno-351-14"></a>
<a id="__codelineno-351-15" name="__codelineno-351-15" href="#__codelineno-351-15"></a>&gt;&gt;&gt; other = torch.randn((), dtype=torch.float64, device=cuda0)
<a id="__codelineno-351-16" name="__codelineno-351-16" href="#__codelineno-351-16"></a>&gt;&gt;&gt; tensor.to(other, non_blocking=True)
<a id="__codelineno-351-17" name="__codelineno-351-17" href="#__codelineno-351-17"></a>tensor([[-0.5044,  0.0005],
<a id="__codelineno-351-18" name="__codelineno-351-18" href="#__codelineno-351-18"></a>        [ 0.3310, -0.0584]], dtype=torch.float64, device=&#39;cuda:0&#39;)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-352-1" name="__codelineno-352-1" href="#__codelineno-352-1"></a>to_mkldnn() → Tensor
</code></pre></div>
<p>返回<code>torch.mkldnn</code>布局中的张量的副本。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-353-1" name="__codelineno-353-1" href="#__codelineno-353-1"></a>take(indices) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.take" title="torch.take"><code>torch.take()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-354-1" name="__codelineno-354-1" href="#__codelineno-354-1"></a>tan() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.tan" title="torch.tan"><code>torch.tan()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-355-1" name="__codelineno-355-1" href="#__codelineno-355-1"></a>tan_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.tan" title="torch.Tensor.tan"><code>tan()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-356-1" name="__codelineno-356-1" href="#__codelineno-356-1"></a>tanh() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.tanh" title="torch.tanh"><code>torch.tanh()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-357-1" name="__codelineno-357-1" href="#__codelineno-357-1"></a>tanh_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>tanh()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-358-1" name="__codelineno-358-1" href="#__codelineno-358-1"></a>tolist()
</code></pre></div>
<p>” tolist(）-&gt;列表或编号</p>
<p>将张量作为(嵌套的）列表返回。 对于标量，将返回标准 Python 编号，就像 <a href="#torch.Tensor.item" title="torch.Tensor.item"><code>item()</code></a> 一样。 如有必要，张量会先自动移至 CPU。</p>
<p>This operation is not differentiable.</p>
<p>例子：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-359-1" name="__codelineno-359-1" href="#__codelineno-359-1"></a>&gt;&gt;&gt; a = torch.randn(2, 2)
<a id="__codelineno-359-2" name="__codelineno-359-2" href="#__codelineno-359-2"></a>&gt;&gt;&gt; a.tolist()
<a id="__codelineno-359-3" name="__codelineno-359-3" href="#__codelineno-359-3"></a>[[0.012766935862600803, 0.5415473580360413],
<a id="__codelineno-359-4" name="__codelineno-359-4" href="#__codelineno-359-4"></a> [-0.08909505605697632, 0.7729271650314331]]
<a id="__codelineno-359-5" name="__codelineno-359-5" href="#__codelineno-359-5"></a>&gt;&gt;&gt; a[0,0].tolist()
<a id="__codelineno-359-6" name="__codelineno-359-6" href="#__codelineno-359-6"></a>0.012766935862600803
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-360-1" name="__codelineno-360-1" href="#__codelineno-360-1"></a>topk(k, dim=None, largest=True, sorted=True) -&gt; (Tensor, LongTensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.topk" title="torch.topk"><code>torch.topk()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-361-1" name="__codelineno-361-1" href="#__codelineno-361-1"></a>to_sparse(sparseDims) → Tensor
</code></pre></div>
<p>返回张量的稀疏副本。 PyTorch 支持<a href="sparse.html#sparse-docs">坐标格式</a>的稀疏张量。</p>
<p>参数</p>
<p><strong>sparseDims</strong>  (<em>python：int</em> <em>，</em> <em>可选</em>）– 新稀疏张量中包含的稀疏维数</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-362-1" name="__codelineno-362-1" href="#__codelineno-362-1"></a>&gt;&gt;&gt; d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])
<a id="__codelineno-362-2" name="__codelineno-362-2" href="#__codelineno-362-2"></a>&gt;&gt;&gt; d
<a id="__codelineno-362-3" name="__codelineno-362-3" href="#__codelineno-362-3"></a>tensor([[ 0,  0,  0],
<a id="__codelineno-362-4" name="__codelineno-362-4" href="#__codelineno-362-4"></a>        [ 9,  0, 10],
<a id="__codelineno-362-5" name="__codelineno-362-5" href="#__codelineno-362-5"></a>        [ 0,  0,  0]])
<a id="__codelineno-362-6" name="__codelineno-362-6" href="#__codelineno-362-6"></a>&gt;&gt;&gt; d.to_sparse()
<a id="__codelineno-362-7" name="__codelineno-362-7" href="#__codelineno-362-7"></a>tensor(indices=tensor([[1, 1],
<a id="__codelineno-362-8" name="__codelineno-362-8" href="#__codelineno-362-8"></a>                       [0, 2]]),
<a id="__codelineno-362-9" name="__codelineno-362-9" href="#__codelineno-362-9"></a>       values=tensor([ 9, 10]),
<a id="__codelineno-362-10" name="__codelineno-362-10" href="#__codelineno-362-10"></a>       size=(3, 3), nnz=2, layout=torch.sparse_coo)
<a id="__codelineno-362-11" name="__codelineno-362-11" href="#__codelineno-362-11"></a>&gt;&gt;&gt; d.to_sparse(1)
<a id="__codelineno-362-12" name="__codelineno-362-12" href="#__codelineno-362-12"></a>tensor(indices=tensor([[1]]),
<a id="__codelineno-362-13" name="__codelineno-362-13" href="#__codelineno-362-13"></a>       values=tensor([[ 9,  0, 10]]),
<a id="__codelineno-362-14" name="__codelineno-362-14" href="#__codelineno-362-14"></a>       size=(3, 3), nnz=1, layout=torch.sparse_coo)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-363-1" name="__codelineno-363-1" href="#__codelineno-363-1"></a>trace() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.trace" title="torch.trace"><code>torch.trace()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-364-1" name="__codelineno-364-1" href="#__codelineno-364-1"></a>transpose(dim0, dim1) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-365-1" name="__codelineno-365-1" href="#__codelineno-365-1"></a>transpose_(dim0, dim1) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>transpose()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-366-1" name="__codelineno-366-1" href="#__codelineno-366-1"></a>triangular_solve(A, upper=True, transpose=False, unitriangular=False) -&gt; (Tensor, Tensor)
</code></pre></div>
<p>参见 <a href="torch.html#torch.triangular_solve" title="torch.triangular_solve"><code>torch.triangular_solve()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-367-1" name="__codelineno-367-1" href="#__codelineno-367-1"></a>tril(k=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.tril" title="torch.tril"><code>torch.tril()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-368-1" name="__codelineno-368-1" href="#__codelineno-368-1"></a>tril_(k=0) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.tril" title="torch.Tensor.tril"><code>tril()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-369-1" name="__codelineno-369-1" href="#__codelineno-369-1"></a>triu(k=0) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.triu" title="torch.triu"><code>torch.triu()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-370-1" name="__codelineno-370-1" href="#__codelineno-370-1"></a>triu_(k=0) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.triu" title="torch.Tensor.triu"><code>triu()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-371-1" name="__codelineno-371-1" href="#__codelineno-371-1"></a>trunc() → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-372-1" name="__codelineno-372-1" href="#__codelineno-372-1"></a>trunc_() → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>trunc()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-373-1" name="__codelineno-373-1" href="#__codelineno-373-1"></a>type(dtype=None, non_blocking=False, **kwargs) → str or Tensor
</code></pre></div>
<p>如果未提供_dtype_; ，则返回类型，否则将该对象强制转换为指定的类型。</p>
<p>如果它已经是正确的类型，则不执行任何复制，并返回原始对象。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dtype</strong>  (<em>python：type</em> <em>或</em> <em>字符串</em>）– 所需类型</p>
</li>
<li>
<p><strong>non_blocking</strong>  (<em>bool</em> ) – 如果<code>True</code>，并且源位于固定内存中，而目标位于 GPU 上，反之亦然，则相对于主机异步执行复制。 否则，该参数无效。</p>
</li>
<li>
<p><strong>**kwargs</strong> – 为兼容起见，可以包含键<code>async</code>来代替<code>non_blocking</code>参数。 不推荐使用<code>async</code> arg。</p>
</li>
</ul>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-374-1" name="__codelineno-374-1" href="#__codelineno-374-1"></a>type_as(tensor) → Tensor
</code></pre></div>
<p>将此张量转换为给定张量的类型。</p>
<p>如果张量已经是正确的类型，则这是无操作的。 相当于<code>self.type(tensor.type())</code></p>
<p>参数</p>
<p><strong>张量</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a>)–具有所需类型的张量</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-375-1" name="__codelineno-375-1" href="#__codelineno-375-1"></a>unbind(dim=0) → seq
</code></pre></div>
<p>参见 <a href="torch.html#torch.unbind" title="torch.unbind"><code>torch.unbind()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-376-1" name="__codelineno-376-1" href="#__codelineno-376-1"></a>unfold(dimension, size, step) → Tensor
</code></pre></div>
<p>返回一个张量，该张量包含<code>self</code>张量中尺寸为<code>dimension</code>的所有大小为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的切片。</p>
<p>两个切片之间的步长由<code>step</code>给出。</p>
<p>如果 <em>sizedim</em> 是<code>self</code>的尺寸<code>dimension</code>的大小，则返回张量中<code>dimension</code>的尺寸将是(<em>sizeim-size</em>）/<em>step</em>+ 1 。</p>
<p>在返回的张量中附加了尺寸为 <a href="#torch.Tensor.size" title="torch.Tensor.size"><code>size</code></a> 的附加尺寸。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dimension</strong> (<em>python：int</em> )–发生展开的尺寸</p>
</li>
<li>
<p><strong>size</strong> (<em>python：int</em> )–展开的每个切片的大小</p>
</li>
<li>
<p><strong>step</strong> (<em>python：int</em> )–每个切片之间的步骤</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-377-1" name="__codelineno-377-1" href="#__codelineno-377-1"></a>&gt;&gt;&gt; x = torch.arange(1., 8)
<a id="__codelineno-377-2" name="__codelineno-377-2" href="#__codelineno-377-2"></a>&gt;&gt;&gt; x
<a id="__codelineno-377-3" name="__codelineno-377-3" href="#__codelineno-377-3"></a>tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])
<a id="__codelineno-377-4" name="__codelineno-377-4" href="#__codelineno-377-4"></a>&gt;&gt;&gt; x.unfold(0, 2, 1)
<a id="__codelineno-377-5" name="__codelineno-377-5" href="#__codelineno-377-5"></a>tensor([[ 1.,  2.],
<a id="__codelineno-377-6" name="__codelineno-377-6" href="#__codelineno-377-6"></a>        [ 2.,  3.],
<a id="__codelineno-377-7" name="__codelineno-377-7" href="#__codelineno-377-7"></a>        [ 3.,  4.],
<a id="__codelineno-377-8" name="__codelineno-377-8" href="#__codelineno-377-8"></a>        [ 4.,  5.],
<a id="__codelineno-377-9" name="__codelineno-377-9" href="#__codelineno-377-9"></a>        [ 5.,  6.],
<a id="__codelineno-377-10" name="__codelineno-377-10" href="#__codelineno-377-10"></a>        [ 6.,  7.]])
<a id="__codelineno-377-11" name="__codelineno-377-11" href="#__codelineno-377-11"></a>&gt;&gt;&gt; x.unfold(0, 2, 2)
<a id="__codelineno-377-12" name="__codelineno-377-12" href="#__codelineno-377-12"></a>tensor([[ 1.,  2.],
<a id="__codelineno-377-13" name="__codelineno-377-13" href="#__codelineno-377-13"></a>        [ 3.,  4.],
<a id="__codelineno-377-14" name="__codelineno-377-14" href="#__codelineno-377-14"></a>        [ 5.,  6.]])
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-378-1" name="__codelineno-378-1" href="#__codelineno-378-1"></a>uniform_(from=0, to=1) → Tensor
</code></pre></div>
<p>用从连续均匀分布中采样的数字填充<code>self</code>张量：</p>
<p><img alt="" src="../img/14837c97b5055932ef86ad2cd89a50be.jpg" /></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-379-1" name="__codelineno-379-1" href="#__codelineno-379-1"></a>unique(sorted=True, return_inverse=False, return_counts=False, dim=None)
</code></pre></div>
<p>返回输入张量的唯一元素。</p>
<p>参见 <a href="torch.html#torch.unique" title="torch.unique"><code>torch.unique()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-380-1" name="__codelineno-380-1" href="#__codelineno-380-1"></a>unique_consecutive(return_inverse=False, return_counts=False, dim=None)
</code></pre></div>
<p>从每个连续的等效元素组中除去除第一个元素外的所有元素。</p>
<p>参见 <a href="torch.html#torch.unique_consecutive" title="torch.unique_consecutive"><code>torch.unique_consecutive()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-381-1" name="__codelineno-381-1" href="#__codelineno-381-1"></a>unsqueeze(dim) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.unsqueeze" title="torch.unsqueeze"><code>torch.unsqueeze()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-382-1" name="__codelineno-382-1" href="#__codelineno-382-1"></a>unsqueeze_(dim) → Tensor
</code></pre></div>
<p>就地版本的 <a href="#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>unsqueeze()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-383-1" name="__codelineno-383-1" href="#__codelineno-383-1"></a>values() → Tensor
</code></pre></div>
<p>如果<code>self</code>是稀疏的 COO 张量(即<code>torch.sparse_coo</code>布局），则返回包含值张量的视图。 否则，将引发错误。</p>
<p>另请参见 <a href="#torch.Tensor.indices" title="torch.Tensor.indices"><code>Tensor.indices()</code></a> 。</p>
<p>注意</p>
<p>This method can only be called on a coalesced sparse tensor. See <code>Tensor.coalesce()</code> for details.</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-384-1" name="__codelineno-384-1" href="#__codelineno-384-1"></a>var(dim=None, unbiased=True, keepdim=False) → Tensor
</code></pre></div>
<p>参见 <a href="torch.html#torch.var" title="torch.var"><code>torch.var()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-385-1" name="__codelineno-385-1" href="#__codelineno-385-1"></a>view(*shape) → Tensor
</code></pre></div>
<p>返回具有与<code>self</code>张量相同的数据但具有不同<code>shape</code>的新张量。</p>
<p>返回的张量共享相同的数据，并且必须具有相同数量的元素，但可能具有不同的大小。 要查看张量，新视图尺寸必须与其原始尺寸和步幅兼容，即每个新视图尺寸必须是原始尺寸的子空间，或者仅跨越满足以下条件的原始尺寸<img alt="" src="../img/8145d811599f1a90bcb673523825c2d2.jpg" /> <img alt="" src="../img/935124691142e85d6cbbdab3f68cc1df.jpg" />的连续性状</p>
<p><img alt="" src="../img/b828b01a8af080958cc82bcc339c033a.jpg" /></p>
<p>否则，需要先调用 <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a> 才能查看张量。 另请参见： <a href="torch.html#torch.reshape" title="torch.reshape"><code>reshape()</code></a> ，如果形状兼容则返回一个视图，否则复制(相当于调用 <a href="#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>contiguous()</code></a>)。</p>
<p>参数</p>
<p><strong>形状</strong>(<em>torch大小</em> <em>或</em> <em>python：int ...</em> )–所需大小</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-386-1" name="__codelineno-386-1" href="#__codelineno-386-1"></a>&gt;&gt;&gt; x = torch.randn(4, 4)
<a id="__codelineno-386-2" name="__codelineno-386-2" href="#__codelineno-386-2"></a>&gt;&gt;&gt; x.size()
<a id="__codelineno-386-3" name="__codelineno-386-3" href="#__codelineno-386-3"></a>torch.Size([4, 4])
<a id="__codelineno-386-4" name="__codelineno-386-4" href="#__codelineno-386-4"></a>&gt;&gt;&gt; y = x.view(16)
<a id="__codelineno-386-5" name="__codelineno-386-5" href="#__codelineno-386-5"></a>&gt;&gt;&gt; y.size()
<a id="__codelineno-386-6" name="__codelineno-386-6" href="#__codelineno-386-6"></a>torch.Size([16])
<a id="__codelineno-386-7" name="__codelineno-386-7" href="#__codelineno-386-7"></a>&gt;&gt;&gt; z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
<a id="__codelineno-386-8" name="__codelineno-386-8" href="#__codelineno-386-8"></a>&gt;&gt;&gt; z.size()
<a id="__codelineno-386-9" name="__codelineno-386-9" href="#__codelineno-386-9"></a>torch.Size([2, 8])
<a id="__codelineno-386-10" name="__codelineno-386-10" href="#__codelineno-386-10"></a>
<a id="__codelineno-386-11" name="__codelineno-386-11" href="#__codelineno-386-11"></a>&gt;&gt;&gt; a = torch.randn(1, 2, 3, 4)
<a id="__codelineno-386-12" name="__codelineno-386-12" href="#__codelineno-386-12"></a>&gt;&gt;&gt; a.size()
<a id="__codelineno-386-13" name="__codelineno-386-13" href="#__codelineno-386-13"></a>torch.Size([1, 2, 3, 4])
<a id="__codelineno-386-14" name="__codelineno-386-14" href="#__codelineno-386-14"></a>&gt;&gt;&gt; b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension
<a id="__codelineno-386-15" name="__codelineno-386-15" href="#__codelineno-386-15"></a>&gt;&gt;&gt; b.size()
<a id="__codelineno-386-16" name="__codelineno-386-16" href="#__codelineno-386-16"></a>torch.Size([1, 3, 2, 4])
<a id="__codelineno-386-17" name="__codelineno-386-17" href="#__codelineno-386-17"></a>&gt;&gt;&gt; c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory
<a id="__codelineno-386-18" name="__codelineno-386-18" href="#__codelineno-386-18"></a>&gt;&gt;&gt; c.size()
<a id="__codelineno-386-19" name="__codelineno-386-19" href="#__codelineno-386-19"></a>torch.Size([1, 3, 2, 4])
<a id="__codelineno-386-20" name="__codelineno-386-20" href="#__codelineno-386-20"></a>&gt;&gt;&gt; torch.equal(b, c)
<a id="__codelineno-386-21" name="__codelineno-386-21" href="#__codelineno-386-21"></a>False
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-387-1" name="__codelineno-387-1" href="#__codelineno-387-1"></a>view_as(other) → Tensor
</code></pre></div>
<p>将此张量查看为与<code>other</code>相同的大小。 <code>self.view_as(other)</code>等效于<code>self.view(other.size())</code>。</p>
<p>有关<code>view</code>的更多信息，请参见 <a href="#torch.Tensor.view" title="torch.Tensor.view"><code>view()</code></a> 。</p>
<p>参数</p>
<p><strong>other</strong> (<a href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>) – The result tensor has the same size as <code>other</code>.</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-388-1" name="__codelineno-388-1" href="#__codelineno-388-1"></a>where(condition, y) → Tensor
</code></pre></div>
<p><code>self.where(condition, y)</code>等效于<code>torch.where(condition, self, y)</code>。 参见 <a href="torch.html#torch.where" title="torch.where"><code>torch.where()</code></a></p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-389-1" name="__codelineno-389-1" href="#__codelineno-389-1"></a>zero_() → Tensor
</code></pre></div>
<p>用零填充<code>self</code>张量。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-390-1" name="__codelineno-390-1" href="#__codelineno-390-1"></a>class torch.BoolTensor
</code></pre></div>
<p>以下方法是 <a href="#torch.BoolTensor" title="torch.BoolTensor"><code>torch.BoolTensor</code></a> 独有的。</p>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-391-1" name="__codelineno-391-1" href="#__codelineno-391-1"></a>all()
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-392-1" name="__codelineno-392-1" href="#__codelineno-392-1"></a>all() → bool
</code></pre></div>
<p>如果张量中的所有元素均为 True，则返回 True，否则返回 False。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-393-1" name="__codelineno-393-1" href="#__codelineno-393-1"></a>&gt;&gt;&gt; a = torch.rand(1, 2).bool()
<a id="__codelineno-393-2" name="__codelineno-393-2" href="#__codelineno-393-2"></a>&gt;&gt;&gt; a
<a id="__codelineno-393-3" name="__codelineno-393-3" href="#__codelineno-393-3"></a>tensor([[False, True]], dtype=torch.bool)
<a id="__codelineno-393-4" name="__codelineno-393-4" href="#__codelineno-393-4"></a>&gt;&gt;&gt; a.all()
<a id="__codelineno-393-5" name="__codelineno-393-5" href="#__codelineno-393-5"></a>tensor(False, dtype=torch.bool)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-394-1" name="__codelineno-394-1" href="#__codelineno-394-1"></a>all(dim, keepdim=False, out=None) → Tensor
</code></pre></div>
<p>如果张量的每一行中给定维度<code>dim</code>中的所有元素均为 True，则返回 True，否则返回 False。</p>
<p>如果<code>keepdim</code>为<code>True</code>，则输出张量的大小与<code>input</code>相同，但尺寸为<code>dim</code>的大小为 1。否则，将压缩<code>dim</code>(请参见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>)，导致输出张量的尺寸比<code>input</code>小 1。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python：int</em> ) – 缩小的尺寸</p>
</li>
<li>
<p><strong>keepdim</strong>  (<em>bool</em> ) – 输出张量是否保留<code>dim</code></p>
</li>
<li>
<p><strong>out</strong>  (<a href="#torch.Tensor" title="torch.Tensor"><em>tensor</em></a> <em>，</em> <em>可选</em>）– 输出的张量</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-395-1" name="__codelineno-395-1" href="#__codelineno-395-1"></a>&gt;&gt;&gt; a = torch.rand(4, 2).bool()
<a id="__codelineno-395-2" name="__codelineno-395-2" href="#__codelineno-395-2"></a>&gt;&gt;&gt; a
<a id="__codelineno-395-3" name="__codelineno-395-3" href="#__codelineno-395-3"></a>tensor([[True, True],
<a id="__codelineno-395-4" name="__codelineno-395-4" href="#__codelineno-395-4"></a>        [True, False],
<a id="__codelineno-395-5" name="__codelineno-395-5" href="#__codelineno-395-5"></a>        [True, True],
<a id="__codelineno-395-6" name="__codelineno-395-6" href="#__codelineno-395-6"></a>        [True, True]], dtype=torch.bool)
<a id="__codelineno-395-7" name="__codelineno-395-7" href="#__codelineno-395-7"></a>&gt;&gt;&gt; a.all(dim=1)
<a id="__codelineno-395-8" name="__codelineno-395-8" href="#__codelineno-395-8"></a>tensor([ True, False,  True,  True], dtype=torch.bool)
<a id="__codelineno-395-9" name="__codelineno-395-9" href="#__codelineno-395-9"></a>&gt;&gt;&gt; a.all(dim=0)
<a id="__codelineno-395-10" name="__codelineno-395-10" href="#__codelineno-395-10"></a>tensor([ True, False], dtype=torch.bool)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-396-1" name="__codelineno-396-1" href="#__codelineno-396-1"></a>any()
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-397-1" name="__codelineno-397-1" href="#__codelineno-397-1"></a>any() → bool
</code></pre></div>
<p>如果张量中的任何元素为 True，则返回 True，否则为 False。</p>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-398-1" name="__codelineno-398-1" href="#__codelineno-398-1"></a>&gt;&gt;&gt; a = torch.rand(1, 2).bool()
<a id="__codelineno-398-2" name="__codelineno-398-2" href="#__codelineno-398-2"></a>&gt;&gt;&gt; a
<a id="__codelineno-398-3" name="__codelineno-398-3" href="#__codelineno-398-3"></a>tensor([[False, True]], dtype=torch.bool)
<a id="__codelineno-398-4" name="__codelineno-398-4" href="#__codelineno-398-4"></a>&gt;&gt;&gt; a.any()
<a id="__codelineno-398-5" name="__codelineno-398-5" href="#__codelineno-398-5"></a>tensor(True, dtype=torch.bool)
</code></pre></div>
<hr />
<div class="highlight"><pre><span></span><code><a id="__codelineno-399-1" name="__codelineno-399-1" href="#__codelineno-399-1"></a>any(dim, keepdim=False, out=None) → Tensor
</code></pre></div>
<p>如果张量的每一行中给定维度<code>dim</code>中的任何元素为 True，则返回 True，否则为 False。</p>
<p>如果<code>keepdim</code>为<code>True</code>，则输出张量的大小与<code>input</code>相同，但尺寸为<code>dim</code>的大小为 1。否则，将压缩<code>dim</code>(请参见 <a href="torch.html#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>)，导致输出张量的尺寸比<code>input</code>小 1。</p>
<p>参数</p>
<ul>
<li>
<p><strong>dim</strong> (<em>python:int</em>) – 缩小的尺寸</p>
</li>
<li>
<p><strong>keepdim</strong> (<em>bool</em>) – 输出张量是否保留<code>dim</code></p>
</li>
<li>
<p><strong>out</strong> (<a href="#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>,</em> <em>optional</em>) – 输出的张量</p>
</li>
</ul>
<p>例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-400-1" name="__codelineno-400-1" href="#__codelineno-400-1"></a>&gt;&gt;&gt; a = torch.randn(4, 2) &lt; 0
<a id="__codelineno-400-2" name="__codelineno-400-2" href="#__codelineno-400-2"></a>&gt;&gt;&gt; a
<a id="__codelineno-400-3" name="__codelineno-400-3" href="#__codelineno-400-3"></a>tensor([[ True,  True],
<a id="__codelineno-400-4" name="__codelineno-400-4" href="#__codelineno-400-4"></a>        [False,  True],
<a id="__codelineno-400-5" name="__codelineno-400-5" href="#__codelineno-400-5"></a>        [ True,  True],
<a id="__codelineno-400-6" name="__codelineno-400-6" href="#__codelineno-400-6"></a>        [False, False]])
<a id="__codelineno-400-7" name="__codelineno-400-7" href="#__codelineno-400-7"></a>&gt;&gt;&gt; a.any(1)
<a id="__codelineno-400-8" name="__codelineno-400-8" href="#__codelineno-400-8"></a>tensor([ True,  True,  True, False])
<a id="__codelineno-400-9" name="__codelineno-400-9" href="#__codelineno-400-9"></a>&gt;&gt;&gt; a.any(0)
<a id="__codelineno-400-10" name="__codelineno-400-10" href="#__codelineno-400-10"></a>tensor([True, True])
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../76/" class="md-footer__link md-footer__link--prev" aria-label="Previous: torch功能">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                torch功能
              </div>
            </div>
          </a>
        
        
          
          <a href="../78/" class="md-footer__link md-footer__link--next" aria-label="Next: 张量属性">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                张量属性
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>